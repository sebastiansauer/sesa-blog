<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.101.0" />


<title>When adding variable hurts – The collider bias - sesa blog</title>
<meta property="og:title" content="When adding variable hurts – The collider bias - sesa blog">


  <link href='https://data-se.netlify.app/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo-data-se.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/privacy/">Data privacy</a></li>
    
    <li><a href="/tags/">Tags</a></li>
    
  </ul>
</nav>

      </header>



<main class="content" role="main">

    <h1 class="article-title">When adding variable hurts – The collider bias</h1>


    <span class="article-meta">
      Sebastian Sauer / 8 mins read <br>
    </span>



    
    <span class="article-date">2020-06-04</span>
    

    <div class="article-content">
      
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="load-packages" class="section level1">
<h1>Load packages</h1>
<pre class="r"><code>library(tidyverse)
library(conflicted)
library(ggdag)
library(broom)
library(GGally)</code></pre>
</div>
<div id="motivation" class="section level1">
<h1>Motivation</h1>
<p>Assume there is some scientist with some theory. Her theory holds that X and Z are causes of Y. <code>dag1</code> shows her DAG (ie., her theory depicted as a causal diagram). Our scientist is concerned with the causal effect of X on Y, where X is a treatment variable (exposure) and Y is the dependent variable under scrutiny (outcome).</p>
<p>See e.g,. <a href="https://journals.sagepub.com/doi/full/10.1177/2515245917745629">here</a> or <a href="https://amstat.tandfonline.com/doi/full/10.1080/10691898.2020.1752859">here</a> for intros to DAGs and causality.</p>
</div>
<div id="dags" class="section level1">
<h1>DAGs</h1>
<p>Let’s define this DAG, first as a plain string (text):</p>
<pre class="r"><code>dag1_txt &lt;- &quot;dag {
X -&gt; Y
Z -&gt; Y
X [exposure]
Y [outcome]
}&quot;</code></pre>
<p>Define a DAG representation:</p>
<pre class="r"><code>dag1 &lt;- dagitty::dagitty(dag1_txt)
dag1
#&gt; dag {
#&gt; X [exposure]
#&gt; Y [outcome]
#&gt; Z
#&gt; X -&gt; Y
#&gt; Z -&gt; Y
#&gt; }</code></pre>
<p>Make it tidy:</p>
<pre class="r"><code>dag1_tidy &lt;- tidy_dagitty(dag1)
dag1_tidy
#&gt; # A DAG with 3 nodes and 2 edges
#&gt; #
#&gt; # Exposure: X
#&gt; # Outcome: Y
#&gt; #
#&gt; # A tibble: 3 x 8
#&gt;   name      x     y direction to     xend  yend circular
#&gt;   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;     &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;   
#&gt; 1 X      33.4  30.2 -&gt;        Y      34.3  29.5 FALSE   
#&gt; 2 Z      35.3  28.9 -&gt;        Y      34.3  29.5 FALSE   
#&gt; 3 Y      34.3  29.5 &lt;NA&gt;      &lt;NA&gt;   NA    NA   FALSE</code></pre>
<p>And plot it:</p>
<pre class="r"><code>ggdag(dag1_tidy) + theme_dag()</code></pre>
<p><img src="/post/2020-06-04-when-adding-variables-hurt_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>So far, so good. Now, sadly, unbeknownst to our scientist, her theory is actually <em>wrong</em>. Wrong as in wrong. The true theory – only known by Paul Meehl – is depicted by the following dag:</p>
<pre class="r"><code>dag2_txt &lt;- &quot;dag {
X -&gt; Z
Y -&gt; Z
X [exposure]
Y [outcome]
}&quot;

dag2_txt
#&gt; [1] &quot;dag {\nX -&gt; Z\nY -&gt; Z\nX [exposure]\nY [outcome]\n}&quot;</code></pre>
<pre class="r"><code>dag2_tidy &lt;- dag2_txt %&gt;% dagitty::dagitty() %&gt;% tidy_dagitty()</code></pre>
<pre class="r"><code>ggdag(dag2_tidy) + theme_dag()</code></pre>
<p><img src="/post/2020-06-04-when-adding-variables-hurt_files/figure-html/unnamed-chunk-7-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="simulate-some-data" class="section level1">
<h1>Simulate some data</h1>
<p>To make it more concrete, let’s come up with some simulated data according to the true model as depicted in DAG2.</p>
<p>Let’s define this <em>structural causal model</em> as follows.</p>
<p><span class="math display">\[
X \sim Norm(0, 1)\\
Y \sim Norm(0, 1)\\
e \sim Norm(0,0.5)\\
Z = 0.5 X + 0.5Y + e
\]</span></p>
<p>Here <code>Norm</code> means the Normal distribution.</p>
<p>Now let’s draw say <span class="math inline">\(n=1000\)</span> observations from these distributions:</p>
<pre class="r"><code>n &lt;- 1000
X &lt;- rnorm(n, mean = 0, sd = 1)
Y &lt;- rnorm(n, mean = 0, sd = 1)
e &lt;- rnorm(n, mean = 0, sd = 0.5)
Z = 0.5*X + 0.5*Y + e

d &lt;- tibble(X = X, 
            Y = Y, 
            e = e, 
            Z = Z)
glimpse(d)
#&gt; Rows: 1,000
#&gt; Columns: 4
#&gt; $ X &lt;dbl&gt; 0.04256036, -2.51827371, 0.70285885, -0.12464830, -1.61776654, -0.2…
#&gt; $ Y &lt;dbl&gt; -0.07430878, -0.85320737, 0.03305014, 2.66740399, 0.32557657, 0.793…
#&gt; $ e &lt;dbl&gt; 0.661375970, -0.519174385, 0.428588030, 0.186427092, -1.036197797, …
#&gt; $ Z &lt;dbl&gt; 0.64550176, -2.20491492, 0.79654252, 1.45780494, -1.68229278, 0.198…</code></pre>
</div>
<div id="regression-time" class="section level1">
<h1>Regression time</h1>
<p>Our scientist has proudly finished her data collection. Now, analysis time, here favorite passe temps.</p>
<p>First, she checks the zero-order (marginal) correlations, ’cause we can:</p>
<pre class="r"><code>cor(d)
#&gt;             X            Y            e         Z
#&gt; X  1.00000000 -0.062874185  0.033431583 0.5639263
#&gt; Y -0.06287419  1.000000000 -0.009696558 0.5485886
#&gt; e  0.03343158 -0.009696558  1.000000000 0.5967447
#&gt; Z  0.56392634  0.548588574  0.596744684 1.0000000</code></pre>
<pre class="r"><code>ggpairs(d)</code></pre>
<p><img src="/post/2020-06-04-when-adding-variables-hurt_files/figure-html/unnamed-chunk-10-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Oh no - bad news. X and Y are not correlated. But, being a well trained data analyst, our scientist keeps the spirits up. She knows that a different way of analysis may well turn a previous result inside out (although sometimes you better not tell what you did in the first place, her supervisor kept on saying, behind closed doors at least).</p>
<p>Here’s the regression of Y back on X:</p>
<pre class="r"><code>lm0 &lt;- lm(Y ~ X, data = d)

tidy(lm0)
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 (Intercept)   0.0189    0.0317     0.594  0.553 
#&gt; 2 X            -0.0639    0.0321    -1.99   0.0468</code></pre>
<p>Same story as with the marginal correlation above: No association of X and Y.</p>
</div>
<div id="now-stay-tuned-lm1" class="section level1">
<h1>Now stay tuned: lm1</h1>
<p>Here’s the regression according to her model:</p>
<pre class="r"><code>lm1 &lt;- lm(Y ~ X + Z, data = d)

tidy(lm1)
#&gt; # A tibble: 3 x 5
#&gt;   term         estimate std.error statistic   p.value
#&gt;   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
#&gt; 1 (Intercept)  0.000193    0.0224   0.00862 9.93e-  1
#&gt; 2 X           -0.554       0.0274 -20.2     2.12e- 76
#&gt; 3 Z            1.01        0.0319  31.7     3.58e-153</code></pre>
<p>Yeah! There <em>is</em> a significant effect of X on Y! Success! Smelling tenure. Now she’ll write up the paper stating that there is “presumably” and “well supported by the data” an “effect” of X on Y. (She doesn’t explicitly calls it a “causal” effect, but hey, what’s an effect if not causal? Ask the next person you happen to run into on the street.)</p>
</div>
<div id="stop-for-a-while" class="section level1">
<h1>Stop for a while</h1>
<p>The story could be finished here. Alas, in most real cases the story <em>is</em> finished here: manuscript drafted, paper published, sometines tenured.</p>
<p>However, as we know - because we defined it above - her model is wrong. So let’s pause for a while to reflect what happened.</p>
<div id="take-home-message-1" class="section level2">
<h2>Take home message 1</h2>
<p>Don’t believe the results of <code>lm1</code>. They are wrong (by definition, or by verdict of Paul Meehl). See above.</p>
<p>But how come that the association of X and Y did change so dramatically? The problem is that she included a <em>collider</em> in her regression. A collider is a variable where two (or more) arrows point to in a given path.</p>
</div>
<div id="take-home-message-2" class="section level2">
<h2>Take home message 2</h2>
<p>Do NOT include a collider Z in your regression if you are planning to estimate the causal effect of X on Y.</p>
</div>
</div>
<div id="correct-regression" class="section level1">
<h1>Correct regression</h1>
<p>Here’s a (more) correct regression model:</p>
<pre class="r"><code>lm2 &lt;- lm(Z ~ X + Y, data = d)

tidy(lm2)
#&gt; # A tibble: 3 x 5
#&gt;   term        estimate std.error statistic   p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
#&gt; 1 (Intercept)  0.00909    0.0157     0.579 5.63e-  1
#&gt; 2 X            0.517      0.0159    32.5   1.58e-158
#&gt; 3 Y            0.496      0.0156    31.7   3.58e-153</code></pre>
<p>The coefficients in our sample turn out nicely just like we had defined the parameters before hand. As we know that DAG2 is true we can have confidence in this present regression model, lm2.</p>
<p>That’s also a valid model:</p>
<pre class="r"><code>lm3 &lt;- lm(Z ~ X, data = d)

tidy(lm3)
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic  p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
#&gt; 1 (Intercept)   0.0184    0.0222     0.830 4.07e- 1
#&gt; 2 X             0.485     0.0225    21.6   5.06e-85</code></pre>
<p>As can be seen, the coefficient of X did not change (substantially) in comparison to lm2.</p>
<p>Similarly:</p>
<pre class="r"><code>lm4 &lt;- lm(Z ~ Y, data = d)

tidy(lm4)
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic  p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
#&gt; 1 (Intercept)  0.00784    0.0225     0.349 7.27e- 1
#&gt; 2 Y            0.464      0.0224    20.7   1.18e-79</code></pre>
</div>
<div id="take-home-message-3" class="section level1">
<h1>Take home message 3</h1>
<p>Sometimes adding a predictor to a regression model hurts. Learn to let go.</p>
</div>
<div id="what-about-this-regression-model" class="section level1">
<h1>What about this regression model?</h1>
<pre class="r"><code>lm5 &lt;- lm(Y ~ X, data = d)

tidy(lm5)
#&gt; # A tibble: 2 x 5
#&gt;   term        estimate std.error statistic p.value
#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
#&gt; 1 (Intercept)   0.0189    0.0317     0.594  0.553 
#&gt; 2 X            -0.0639    0.0321    -1.99   0.0468</code></pre>
<p>This model is O.K. too. Check the DAG: The DAG tells us that there’s no causal effect from X onto Y. The regression model supports that notion.</p>
</div>
<div id="debrief" class="section level1">
<h1>Debrief</h1>
<p>The story above only holds if one tries to estimate a <em>causal</em> effect. It’s a completely different story if someone “only” would like to predict some variable, say Y.</p>
<p>Prediction has its value, of course. Call me if you are able to predict tomorrows DAX value.</p>
<p>For science however, prediction is of little value in many times. Rather, we would like to understand <em>why</em> a correlation takes place. What do we learn by knowing that babies and storks are correlated? Nothing. Why not? And why is it easy to accept? Because we intuitively know that there’s no causation going on here. That’s the crucial point. Absent causal information, we do not learn much or maybe nothing from a correlation.</p>
</div>
<div id="a-last-example" class="section level1">
<h1>A last example</h1>
<p>Say you learn that chocolate consumption and (number of) Nobel laureates (per country) is correlated (see <a href="https://fabiandablander.com/r/Causal-Inference.html">this source</a> by Fabian Dablander). Interesting?! Of course, that’s again an example of “too strange to be true”. As a rule of thumb, if it’s too strange to be true it’s probably not true. One explanation could be that in “developed” countries (whatever that is) there’s a high chocolate consumption and a (relatively) high number of Nobel laureates. In not-so-developed countries the reverse is true. Hence, there’s a correlation of development status and chocolate consumption. And a correlation of development status and Nobel laureates. In fact, not only correlation but causation by virtue of this example. Now, as we are aware of the true “background” – the development status – as the driver of the “unreal” (spurious) correlation between chocolate and Nobel stuff, we know that this spurious correlation is of <em>ZERO</em> value (for understanding what’s going on). How do we know? Because we now know that there’s no causal association between chocolate and Nobel stuff. But there <em>is</em> a causal association between development status and the other two variables.</p>
</div>

    </div>


  </article>




  
<section id="comments">
  <div id="disqus_thread"></div>
  <script>
  var disqus_config = function () {
  
  };
  (function() {
    var inIFrame = function() {
      var iframe = true;
      try { iframe = window.self !== window.top; } catch (e) {}
      return iframe;
    };
    if (inIFrame()) return;
    var d = document, s = d.createElement('script');
    s.src = '//https-data-se-netlify-com.disqus.com/embed.js'; s.async = true;
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>




</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

