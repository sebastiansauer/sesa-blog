<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Psychology on sesa blog</title>
    <link>https://data-se.netlify.app/tags/psychology/</link>
    <description>Recent content in Psychology on sesa blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://data-se.netlify.app/tags/psychology/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to convert raw scores to different types of standardized scores</title>
      <link>https://data-se.netlify.app/2019/04/11/how-to-convert-raw-scores-to-different-types-of-standardized-scores/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2019/04/11/how-to-convert-raw-scores-to-different-types-of-standardized-scores/</guid>
      <description>&lt;p&gt;A common undertaking in applied research settings such as in some areas of psychology is to convert a raw score into some type of standardized score such as z-scores.&lt;/p&gt;&#xD;&#xA;&lt;p&gt;This post shows a way how to accomplish that.&lt;/p&gt;&#xD;&#xA;&lt;div id=&#34;load-packages&#34; class=&#34;section level1&#34;&gt;&#xD;&#xA;&lt;h1&gt;Load packages&lt;/h1&gt;&#xD;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;div id=&#34;load-some-psychometric-data&#34; class=&#34;section level1&#34;&gt;&#xD;&#xA;&lt;h1&gt;Load some psychometric data&lt;/h1&gt;&#xD;&#xA;&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;extra&amp;quot;, package = &amp;quot;pradadata&amp;quot;)&lt;/code&gt;&lt;/pre&gt;&#xD;&#xA;&lt;p&gt;The data can be downloaded &lt;a href=&#34;https://github.com/sebastiansauer/pradadata&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&#xD;&#xA;&lt;p&gt;The dataset shows some data on extraversion (the personality trait) items along with some correlates of extraversion.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Online reaction time experiments using lab.js</title>
      <link>https://data-se.netlify.app/2019/01/29/online-reaction-time-experiments-using-lab-js/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2019/01/29/online-reaction-time-experiments-using-lab-js/</guid>
      <description>&lt;p&gt;Collecting data over the internet used to be fancy, some twenty years or so ago. Nowadays it can be considered standard, if not old school (collecting data using mobile apps is where the cool kids go at the moment). However, thereâ€™s one noteable exception: Collecting reaction time data over the internet remained a challenge. The reason is simply a technological artefact in that an html response time may vary, vary too much as to invalidate the signal from some behavorial reaction time research study.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some intriguing psychology papers (open access)</title>
      <link>https://data-se.netlify.app/2017/09/26/psy-paper-suggestions/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2017/09/26/psy-paper-suggestions/</guid>
      <description>&lt;p&gt;This post presents a compilation of links to psychology papers; I have chosen papers I find intriguing particularly for working in class. All papers are open access (or a from open access repositories) which renders classroom work easier. The papers are collected from a broad range of topics but mostly with focus on general interest. The perspective is an applied one; I have not tried to select based on methodological rigor.  The collection is structured along the well-known classification of psychological work: social, personality, cognitive. I have added &amp;lsquo;social media/ psychoinformatics&amp;rsquo; as this reflects a topic I am quite interested in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Review of &#34;The 7 Deadly Sins of Psychology&#34; by Chris Chambers</title>
      <link>https://data-se.netlify.app/2017/06/22/seven-sins/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2017/06/22/seven-sins/</guid>
      <description>&lt;p&gt;tl;dr: great book. Read.&lt;/p&gt;&#xA;&lt;p&gt;The &amp;ldquo;Seven Sins&amp;rdquo; is concerned about the validity of psychological research. Can we at all, or to what degree, be certain about the conclusions reached in psychological research? More recently, replications efforts have cast doubt on our confidence in psychological research (1). In a similar vein, a recent papers states that in many research areas, researchers mostly report &amp;ldquo;successes&amp;rdquo; in the sense of that they report that their studies confirm their hypotheses - with Psychology leading in the proportion of supported hypotheses (2). To good to be true? In the light of all this unbehagen, Chambers&amp;rsquo; book addresses some of the (possible) roots of the problem of (un)reliability of psychological science. Precisely, Chambers mentions seven &amp;ldquo;sins&amp;rdquo; that the psychological research community appears to be guilty of: confirmation bias, data tuning (&amp;ldquo;hidden flexibility&amp;rdquo;), disregard of direct replications (and related problems), failure to share data (&amp;ldquo;data hoarding&amp;rdquo;), fraud, lack of open access publishing, and fixation on impact factors.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
