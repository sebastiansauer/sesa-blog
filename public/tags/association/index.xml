<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Association on sesa blog</title>
    <link>https://data-se.netlify.app/tags/association/</link>
    <description>Recent content in Association on sesa blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Apr 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://data-se.netlify.app/tags/association/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Covariance as correlation</title>
      <link>https://data-se.netlify.app/2017/04/25/cor_as_cov/</link>
      <pubDate>Tue, 25 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2017/04/25/cor_as_cov/</guid>
      <description>&lt;p&gt;Correlation is one of the most widely used and a well-known measure of the assocation (&lt;em&gt;linear&lt;/em&gt; association, that is) of two variables.&lt;/p&gt;&#xA;&lt;p&gt;Perhaps less well-known is that the correlation is in principle &lt;em&gt;analoguous to the covariation&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;To see this, consider &lt;del&gt;the&lt;/del&gt; a formula of the covariance of two empirical datasets, $X$ and $Y$:&lt;/p&gt;&#xA;&lt;p&gt;$$COV(X,Y) = \frac{1}{n} \cdot \big( \sum (X_i -\bar{X}) \cdot (Y_i - \bar{Y}) \big) $$&lt;/p&gt;&#xA;&lt;p&gt;In other words, the covariance of $X$ and $Y$ $COV(X,Y)$ is the average of difference of some value to its mean.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some reflections on stochastic independence</title>
      <link>https://data-se.netlify.app/2016/11/08/stochastic_independence/</link>
      <pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2016/11/08/stochastic_independence/</guid>
      <description>&lt;script src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34; type=&#34;text/javascript&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;We are often interested in the question whether two variables are &amp;ldquo;associated&amp;rdquo;, &amp;ldquo;correlated&amp;rdquo; (I mean the normal English term) or &amp;ldquo;dependent&amp;rdquo;. What exactly, or rather in normal words, does that mean? Let&amp;rsquo;s look at some easy case.&lt;/p&gt;&#xA;&lt;p&gt;NOTE: The example has been updated to reflect a more tangible and sensible scenario (find the old one in the previous commit at Github).&lt;/p&gt;&#xA;&lt;h1 id=&#34;titanic-data&#34;&gt;Titanic data&lt;/h1&gt;&#xA;&lt;p&gt;For example, let&amp;rsquo;s look at survival rates of the Titanic disaster, to see whether the probability of survival (event A) depends on the whether you embarked for 1st class (event B).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why absolute correlation value (r) cannot exceed 1. An intuition.</title>
      <link>https://data-se.netlify.app/2016/08/28/why-abs-correlation-is-max-1/</link>
      <pubDate>Sun, 28 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2016/08/28/why-abs-correlation-is-max-1/</guid>
      <description>&lt;script src=&#34;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34; type=&#34;text/javascript&#34;&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient&#34;&gt;Pearson&amp;rsquo;s correlation&lt;/a&gt; is a well-known and widely used instrument to gauge the degree of linear association of two variables (see &lt;a href=&#34;https://sebastiansauer.github.io/correlation-intuition/&#34;&gt;this post&lt;/a&gt; for an intuition on correlation).&lt;/p&gt;&#xA;&lt;p&gt;There a many formulas for correlation, but a short and easy one is this one:&lt;/p&gt;&#xA;&lt;p&gt;$$r = \varnothing(z_x z_y)$$.&lt;/p&gt;&#xA;&lt;p&gt;In words, $$r$$ can be seen as the average product of z-scores.&lt;/p&gt;&#xA;&lt;p&gt;In &amp;ldquo;raw values&amp;rdquo;, r is given by&lt;/p&gt;&#xA;&lt;p&gt;$$ r = \frac{\frac{1}{n}\sum{\Delta X \Delta Y}}{\sqrt{\frac{1}{n}\sum{\Delta X^2}} \sqrt{\frac{1}{n}\sum{\Delta Y^2}}} $$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Intuition on correlation</title>
      <link>https://data-se.netlify.app/2016/07/25/correlation-intuition/</link>
      <pubDate>Mon, 25 Jul 2016 00:00:00 +0000</pubDate>
      <guid>https://data-se.netlify.app/2016/07/25/correlation-intuition/</guid>
      <description>&lt;p&gt;&lt;em&gt;reading time: 10 min.&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Pearson’s correlation (short: correlation) is one of statistics’ all time classics. With an age of about a century, it is some kind of grand dad of analytic tools – but an oldie who is still very busy!&lt;/p&gt;&#xA;&lt;p&gt;Formula, interpretation and application of correlation is well known.&lt;/p&gt;&#xA;&lt;p&gt;In some non-technical lay terms, correlation captures the (linear) degree of co-variation of two linear variables. For example: if tall people have large feet (and small people small feet), on average, we say that height and foot size are correlated.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
