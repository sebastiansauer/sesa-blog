<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rstats on sesa blog</title>
    <link>https://data-se.netlify.app/categories/rstats/</link>
    <description>Recent content in rstats on sesa blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Feb 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://data-se.netlify.app/categories/rstats/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tables, plotted as ggplot objects</title>
      <link>https://data-se.netlify.app/2023/02/03/tables-plotted-as-ggplot-objects/</link>
      <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2023/02/03/tables-plotted-as-ggplot-objects/</guid>
      <description>1 Load packages 2 Show case 1: grid.table 3 Show case 2: tableGrob 4 Show case 3: Reduce whitespace 5 Show case 4: ggpubr 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(gridExtra) library(grid) library(gt) 2 Show case 1: grid.table d &amp;lt;- head(iris[,1:3]) grid.table(d) grid.table does the job nicely.
Just plotting give a somewhat too raw object:
plot(tableGrob(d)) 3 Show case 2: tableGrob The following R code is taken from this source:</description>
    </item>
    
    <item>
      <title>Playing around with spirographs</title>
      <link>https://data-se.netlify.app/2023/01/30/playing-around-with-spirographs/</link>
      <pubDate>Mon, 30 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2023/01/30/playing-around-with-spirographs/</guid>
      <description>1 Load packages 2 Spiro 3 You’re my favorite 4 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(spiro) library(viridisLite) 2 Spiro These images and their code are taken from the phantastic Spiro R package bei W. J. Schneider.
3 You’re my favorite k &amp;lt;- 36 files &amp;lt;- paste0(&amp;quot;s&amp;quot;, 1:k, &amp;quot;.svg&amp;quot;) pen_radii &amp;lt;- seq(3.8, 1.5, length.out = k) alphas &amp;lt;- rep_len(c(0.85, rep(0.2, 4)), k) colors &amp;lt;- rep_len(viridis(6, alpha = alphas, begin = 0, end = 1, direction = 1, option = &amp;quot;D&amp;quot;), k) #colors &amp;lt;- rep_len(scico(6, palette = &amp;quot;devon&amp;quot;), k) %&amp;gt;% # alpha(.</description>
    </item>
    
    <item>
      <title>Differences according to importing CSV using different functions</title>
      <link>https://data-se.netlify.app/2023/01/19/differences-according-to-importing-csv-using-different-functions/</link>
      <pubDate>Thu, 19 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2023/01/19/differences-according-to-importing-csv-using-different-functions/</guid>
      <description>1 Load packages 2 Motivation 3 Data 4 Method 1: read.csv 5 Method 2: read_csv 6 Method 3: data_read 7 First glimpse 8 Hashes 9 Not exactly identical 10 Data comparison 11 Conclusion 12 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(easystats) library(digest) # hashes 2 Motivation Importing a CSV file can yield to - slightly - different results, according to which functions are used for importing the file.</description>
    </item>
    
    <item>
      <title>A quick demo how to compute rowwise means with the tidyverse</title>
      <link>https://data-se.netlify.app/2023/01/16/a-quick-demo-how-to-compute-rowwise-means-with-the-tidyverse/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2023/01/16/a-quick-demo-how-to-compute-rowwise-means-with-the-tidyverse/</guid>
      <description>1 Load packages 2 Motivation 3 Minimal example 4 See also 5 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Motivation Sometimes is is neccessary to compute functions, such as mean values, rowwise, ie., summing the values for multiple variables (my_vars) for each observation.
3 Minimal example For the sake of simplicity, we’ll make use of the mtcars dataset.
data(mtcars) my_vars &amp;lt;- c(&amp;quot;mpg&amp;quot;, &amp;quot;cyl&amp;quot;, &amp;quot;hp&amp;quot;) mtcars &amp;lt;- mtcars |&amp;gt; select(all_of(my_vars)) |&amp;gt; rowwise() |&amp;gt; mutate(mtcars_score = mean(c_across(all_of(my_vars)), na.</description>
    </item>
    
    <item>
      <title>Consistency of set.seed across different systems</title>
      <link>https://data-se.netlify.app/2022/12/13/consistency-of-set-seed-across-different-systems/</link>
      <pubDate>Tue, 13 Dec 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/12/13/consistency-of-set-seed-across-different-systems/</guid>
      <description>1 Load packages 2 Motivation 3 User error 4 Your help needed 5 Same random numbers 5.1 Without seed 5.2 With seed 5.3 Using a hash 6 Seeds in regression models 6.1 lm 6.2 Stan mtcars 6.3 Stan penguins 7 Session info 1 Load packages library(tidyverse) # data wrangling library(digest) library(rstanarm) 2 Motivation Reproducibility of results is a major concern in science and industry alike. However, there are numerous pitfalls which may threaten reproducibility.</description>
    </item>
    
    <item>
      <title>Plot timelines using ggplot</title>
      <link>https://data-se.netlify.app/2022/11/30/plot-timelines-using-ggplot/</link>
      <pubDate>Wed, 30 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/11/30/plot-timelines-using-ggplot/</guid>
      <description>1 Load packages 2 Motivation 3 Sample data 4 Visualization 5 Debrief 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(vistime) # time line 2 Motivation For project planing, a visualization of some time line is often useful. If it’s not the dates but rather the steps of a process, a graph of steps is more appropriate. However, if the sequence of steps is simple and rather linear, and the dates are the important piece of information to be transmitted, a kind of timeline graph is warranted.</description>
    </item>
    
    <item>
      <title>Accessing Google Trends</title>
      <link>https://data-se.netlify.app/2022/11/04/accessing-google-trends/</link>
      <pubDate>Fri, 04 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/11/04/accessing-google-trends/</guid>
      <description>1 Load packages 2 Motivation 3 Restrictions and quotas 4 Access via R 5 Options 6 Get data 7 Plot it 8 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Motivation Google Trends is, according to Wikipedia:
Google Trends is a website by Google that analyzes the popularity of top search queries in Google Search across various regions and languages. The website uses graphs to compare the search volume of different queries over time.</description>
    </item>
    
    <item>
      <title>Programmatically plotting with ggplot2</title>
      <link>https://data-se.netlify.app/2022/09/28/programmatically-plotting-with-ggplot2/</link>
      <pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/09/28/programmatically-plotting-with-ggplot2/</guid>
      <description>1 Setup 2 Let’s go 2.1 Way 1 2.2 Way 2 2.3 Way 2 2.4 Way 3 2.5 Way 4 3 Further reading 4 Reproducibility 1 Setup library(tidyverse) # data wrangling library(easystats) # comfort in stats data(mtcars) In essence, we want to build this kind of plot programmatically:
mtcars %&amp;gt;% ggplot(aes(x=hp)) + geom_histogram() 2 Let’s go 2.1 Way 1 Let’s use unquoted variable names.
plot_descriptives0 &amp;lt;- function(data, var) { data %&amp;gt;% ggplot(aes(x = {{var}})) + geom_histogram() } plot_descriptives0(mtcars, hp) 2.</description>
    </item>
    
    <item>
      <title>Some ways to plot the distribution of each variable of a data frame</title>
      <link>https://data-se.netlify.app/2022/09/26/some-ways-to-plot-the-distribution-of-each-variable-of-a-data-frame/</link>
      <pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/09/26/some-ways-to-plot-the-distribution-of-each-variable-of-a-data-frame/</guid>
      <description>1 Motivation 2 Load packages 3 Load data 4 Let’s plot 4.1 Way 1 4.2 Way 2 4.3 Way 3 4.4 Way 4 5 Reproducibility 1 Motivation Often times, in explorative data analysis, one would like to plot the distribution of the relevant variables. Whereas ggplot provides handy tools to plot one variable after each other, it would come handy to plot ’em all in one go.
Of course, there are many ways to achieve this comfort.</description>
    </item>
    
    <item>
      <title>FontAwesome in ggplot</title>
      <link>https://data-se.netlify.app/2022/07/27/fontawesome-in-ggplot/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/07/27/fontawesome-in-ggplot/</guid>
      <description>1 Load packages 2 Reproducibility 1 Load packages library(tidyverse) # data wrangling Use Case
Sometimes it is nice to decorate your posts with some FontAwesome Icons.
The easiest way is to use {fontawesome} with the fa() functin.
However, to get images instead of a font, try the following appraoch:
library(emojifont) library(patchwork) p1 &amp;lt;- ggplot() + geom_fontawesome(&amp;quot;fa-bolt&amp;quot;, color=&amp;#39;steelblue&amp;#39;) + theme_void() p2 &amp;lt;- ggplot() + geom_fontawesome(&amp;quot;fa-rocket&amp;quot;, color = &amp;quot;steelblue&amp;quot;) + theme_void() p1 + p2 Alternatively: to p1 + p2:</description>
    </item>
    
    <item>
      <title>FontAwesome in R and R Markdown</title>
      <link>https://data-se.netlify.app/2022/07/27/fontawesome-in-r-and-r-markdown/</link>
      <pubDate>Wed, 27 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/07/27/fontawesome-in-r-and-r-markdown/</guid>
      <description>1 Load packages 2 Use Case 3 Way 4 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Use Case Some times some nice emojis or icons are of benefit for your new post, right?
But, what’s a useful way to implement icons?
3 Way Here’s a quick way of incorporating FontAwesome icons to your RMarkdown document:
&amp;lt;center&amp;gt; &amp;lt;font size=&amp;quot;15&amp;quot;&amp;gt; ```r library(fontawesome) fa(&amp;quot;r-project&amp;quot;, fill = &amp;quot;steelblue&amp;quot;) fa(&amp;quot;bolt-lightning&amp;quot;, fill = &amp;quot;steelblue&amp;quot;) fa(&amp;quot;discourse&amp;quot;, fill = &amp;quot;steelblue&amp;quot;) fa(&amp;quot;rocket&amp;quot;, fill = &amp;quot;steelblue&amp;quot;) ``` &amp;lt;/font&amp;gt; &amp;lt;/center&amp;gt; Which renders as:</description>
    </item>
    
    <item>
      <title>German weather</title>
      <link>https://data-se.netlify.app/2022/07/24/german-weather/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/07/24/german-weather/</guid>
      <description>1 Load packages 2 Motivation 3 Load data 4 Main temperature trajectory over time 4.1 Visualization 4.2 Linear model 5 Temperature change per month 5.1 Vis 1: Change per Month for whole of Germany 5.2 Linear model 5.3 Vis 2: Trend by Bundesland 6 Change per decade 6.1 Vis 1 6.2 Vis 2: Temperature change per decade 7 Change in variability 7.1 Vis 8 Debrief 9 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(easystats) library(ggplot2); theme_set(theme_minimal()) # ggplot theme 2 Motivation Let’s explore the change over time in German weather.</description>
    </item>
    
    <item>
      <title>Penguins Lasso with Tidymodels</title>
      <link>https://data-se.netlify.app/2022/07/24/penguins-lasso-with-tidymodels/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/07/24/penguins-lasso-with-tidymodels/</guid>
      <description>1 Load packages 2 Data 3 A bit more than minimal 4 Results 5 Extract fit 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) 2 Data data(&amp;quot;penguins&amp;quot;, package = &amp;quot;modeldata&amp;quot;) 3 A bit more than minimal rec1 &amp;lt;- recipe(body_mass_g ~ ., data = penguins) %&amp;gt;% step_dummy(all_nominal()) %&amp;gt;% step_normalize(all_numeric_predictors()) %&amp;gt;% step_nzv(all_numeric_predictors()) %&amp;gt;% step_naomit(all_predictors()) Checks:
summary(rec1) #&amp;gt; # A tibble: 7 × 4 #&amp;gt; variable type role source #&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; #&amp;gt; 1 species nominal predictor original #&amp;gt; 2 island nominal predictor original #&amp;gt; 3 bill_length_mm numeric predictor original #&amp;gt; 4 bill_depth_mm numeric predictor original #&amp;gt; 5 flipper_length_mm numeric predictor original #&amp;gt; 6 sex nominal predictor original #&amp;gt; 7 body_mass_g numeric outcome original tidy(rec1) #&amp;gt; # A tibble: 5 × 6 #&amp;gt; number operation type trained skip id #&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt; #&amp;gt; 1 1 step dummy FALSE FALSE dummy_rc5a2 #&amp;gt; 2 2 step normalize FALSE FALSE normalize_U3yg4 #&amp;gt; 3 3 step nzv FALSE FALSE nzv_vruQ8 #&amp;gt; 4 4 step naomit FALSE TRUE naomit_PqP3J #&amp;gt; 5 5 step novel FALSE FALSE novel_6pjBL rec1 %&amp;gt;% prep() %&amp;gt;% bake(new_data = NULL) %&amp;gt;% head() #&amp;gt; # A tibble: 6 × 9 #&amp;gt; bill_length_mm bill_depth_mm flipper_length_mm body_mass_g species_Chinstrap #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 -0.</description>
    </item>
    
    <item>
      <title>Preparing German weather data</title>
      <link>https://data-se.netlify.app/2022/07/24/preparing-german-weather-data/</link>
      <pubDate>Sun, 24 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/07/24/preparing-german-weather-data/</guid>
      <description>1 Load packages 2 Motivation 3 Licence 4 It’s a playful approach 5 Download data 5.1 Air temperature means 6 Download multiple files and bind them together rowwise 7 Format to long 8 More post-processing 9 Save to disk 10 Precipitation 11 Debrief 12 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(glue) 2 Motivation In this post, we’ll prepare official German weather data. All data are accessed from DWD.</description>
    </item>
    
    <item>
      <title>Free resources for aspiring data adepts</title>
      <link>https://data-se.netlify.app/2022/06/13/free-resources-for-aspiring-data-adepts/</link>
      <pubDate>Mon, 13 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/06/13/free-resources-for-aspiring-data-adepts/</guid>
      <description>1 Why data science? 2 Free resources overview 2.1 Machine learning conceps 2.2 Math basics 2.3 R basics 2.4 Machine learning framework with R 2.5 R online environment 2.6 Online course 2.7 Beautiful intuition 2.8 Blogs 2.9 Help 2.10 YouTube channels 1 Why data science? Data science is of of the most vibrating fields of research and industries at present. Its ubiquity and importance is likely on the rise. Due to its importance, it’s a great place for vivid minds to contribute and to develop.</description>
    </item>
    
    <item>
      <title>Vorher-Nachher-Messung und Vergleich zwischen Gruppen</title>
      <link>https://data-se.netlify.app/2022/06/04/vorher-nachher-messung-und-vergleich-zwischen-gruppen/</link>
      <pubDate>Sat, 04 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/06/04/vorher-nachher-messung-und-vergleich-zwischen-gruppen/</guid>
      <description>1 Load packages 2 Forschungsfrage 3 Simulierte Daten 4 Differenzwert berechnen 5 Visualisieren 6 Deskriptive Statistik 7 Deskriptive Statistik als schöne Tabelle 8 Cohens d 9 Inferenzstatistik 10 Parameter (Koeffizienten des Modells) plotten 11 Ja, ist der Effekt jetzt groß oder nicht? 12 ROPE 13 Was ist mit R-Quadrat? 14 Fazit 15 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(easystats) # make stasts easy again library(rstanarm) # Bayes library(gt) # schöne Tabellen 2 Forschungsfrage Stellen Sie sich vor, Sie haben ein Experiment durchgeführt.</description>
    </item>
    
    <item>
      <title>Importing data into R</title>
      <link>https://data-se.netlify.app/2022/05/11/importing-data-into-r/</link>
      <pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/05/11/importing-data-into-r/</guid>
      <description>1 Load packages 2 Motivation: Get your data into R, different ways 3 Pragmatic goal 4 Approach 1: Quick and easy 5 Approach 2: Start an RStudio project 6 Approach 3: Import from an online source 7 Approach 4: Learn what a path means 8 Example time – dataset tips 1 Load packages library(tidyverse) 2 Motivation: Get your data into R, different ways Importing data into R can cause headaches for newbies.</description>
    </item>
    
    <item>
      <title>Comparing Jamovi and rstanarm</title>
      <link>https://data-se.netlify.app/2022/05/09/comparing-jamovi-and-rstanarm/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/05/09/comparing-jamovi-and-rstanarm/</guid>
      <description>1 Load packages 2 Motivation 3 data 4 Model 1 4.1 rstanarm 4.2 Jamovi 5 Model 2 5.1 rstanarm 5.2 Jamovi 5.3 Interim conclusion 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Motivation Let’s try to see how much the results of Jamovi (2.2.5) and rstanarm (2.21.1) converge. It’s probably difficult to say because the defaults are different, and it may not be straight forward to translate back and forth.</description>
    </item>
    
    <item>
      <title>Rowwise NA</title>
      <link>https://data-se.netlify.app/2022/05/09/rowwise-na/</link>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/05/09/rowwise-na/</guid>
      <description>1 Load packages 2 Sample data 3 Count NA rowwise 4 Way 1: rowwise sum with mutate and c_across 5 Way 2: apply() with margin 1 6 Way 3: rowSums 7 Way 4: cur_data() 8 Why not map()? 9 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Sample data data(&amp;quot;mtcars&amp;quot;) Create some NA:
mtcars$mpg[c(1,2,3)] &amp;lt;- NA mtcars$hp[c(1,2,3)] &amp;lt;- NA 3 Count NA rowwise What we would like to achieve is to comfortable count the missing values per row.</description>
    </item>
    
    <item>
      <title>Empirische Verteilungsfunktion</title>
      <link>https://data-se.netlify.app/2022/05/02/empirische-verteilungsfunktion/</link>
      <pubDate>Mon, 02 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/05/02/empirische-verteilungsfunktion/</guid>
      <description>1 R-Pakete 2 Hintergrund 3 Verteilungsfunktion der Normalverteilung 4 Empirische Verteilungsfunktion 4.1 Tidyverse 4.1.1 Tidyverse 1 4.1.2 Tidyverse 2 4.1.3 Plotten der ECDF 4.1.4 Quantile 4.2 Base R 4.2.1 Quantile 4.2.2 ECDF 4.2.3 Plot 4.3 Mosaic 4.3.1 ECDF 4.3.2 Quantile 5 Reproducibility 1 R-Pakete library(tidyverse) # data wrangling theme_set(theme_minimal()) # Stylesheet für ggplot2 2 Hintergrund Will man eine Verteilung untersuchen, sind Verteilungsfunktion \(F\) und Quantilsfunktion \(F^{-1}\) wichtige Größen. Nicht nur für theoretische, sondern auch für empirische Verteilungen kann man diese Funktionen anwenden.</description>
    </item>
    
    <item>
      <title>3D Regression plane with scatter plot</title>
      <link>https://data-se.netlify.app/2022/04/19/3d-regression-plane-with-scatter-plot/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/19/3d-regression-plane-with-scatter-plot/</guid>
      <description>1 Load packages 2 Define model 3 Define grid for regression plane 4 Scatter Plot 5 Scatter plot with 3D surface 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(plotly) # 3D plot interactive 2 Define model Here’s the linear model with 2 predictors, giving us a model that can be visualized in 3D:
lm1 &amp;lt;- lm(mpg ~ hp + disp, data = mtcars) As is standard, we’ll predict mpg.</description>
    </item>
    
    <item>
      <title>Das arithmetische Mittel minimiert die Abweichungsquadrate</title>
      <link>https://data-se.netlify.app/2022/04/08/mittelwert-minimiert-abweichungsquadrate/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/08/mittelwert-minimiert-abweichungsquadrate/</guid>
      <description>1 Behauptung 2 Beweis 3 Quellen 1 Behauptung Das arithmetische Mittel \(\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i\) minimiert die Abweichungsquadrate der \(x_i\) zu einem Wert \(c\), eben der ist das arithmetische Mittel:
\(\text{arg min}_c \sum_{i=1}^n(x_i - c)^2\).
Mit anderen Worten: Es gibt keine andere Zahl, für die obige Summe einen kleineren Wert liefert, so die Behauptung.
Nennen wir die Summe der Abweichungsquadrate \(s(c) = \sum_{i=1}^n(x_i -c)^2\).
2 Beweis \[ \begin{aligned} s(c) &amp;amp;= \sum_{i=1}^n (x_i -c)^2 \\ &amp;amp;= \sum_{i=1}^n (x_i^2 - 2x_ic + c^2) \\ &amp;amp;= \sum_{i=1}^n x_i^2 - \sum_{i=1}^n 2x_ic + \sum_{i=1}^n c^2 \\ &amp;amp;= \sum_{i=1}^n x_i^2 - 2c \sum_{i=1}^n x_i + n c^2 \end{aligned} \]</description>
    </item>
    
    <item>
      <title>Median minimiert Absolutabweichungen</title>
      <link>https://data-se.netlify.app/2022/04/08/median-minimiert-absolutabweichungen/</link>
      <pubDate>Fri, 08 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/08/median-minimiert-absolutabweichungen/</guid>
      <description>1 Behauptung 2 Beweis 1 3 Beweis 2 4 Quellen 5 Reproducibility library(tidyverse) 1 Behauptung Der Median \(md\) minimiert die Absolutabweichungen der \(x_i\) zu einem Wert \(c\), eben der ist Median:
\(\text{arg min}_c \sum_{i=1}^n|(x_i - c)|\).
Mit anderen Worten: Es gibt keine andere Zahl, für die obige Summe einen kleineren Wert liefert, so die Behauptung.
Nennen wir die Summe der Absolutabweichungen \(e(c) = \sum_{i=1}^n|(x_i - c)|\).
2 Beweis 1 Betrachten wir zwei reelle Zahlen, \(a &amp;lt; b\).</description>
    </item>
    
    <item>
      <title>How to import GoogleSheets into R</title>
      <link>https://data-se.netlify.app/2022/04/02/how-to-import-googlesheets-into-r/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/02/how-to-import-googlesheets-into-r/</guid>
      <description>1 Load packages 2 Motivation 3 Find your GoogleSheets File 4 Authentificate 5 Read it 6 Check 7 Rename 8 Some caveats 9 Further reading 10 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(googlesheets4) # GSheets API library(gt) # html tables 2 Motivation Data sharing is of primary concern for science and, increasingly, technology. Whereas there are specialized repositories for data storage and exchange (which are very useful), at times more quick and dirty solutions are desirable.</description>
    </item>
    
    <item>
      <title>Simple nomnoml in R examples</title>
      <link>https://data-se.netlify.app/2022/04/02/simple-nomnoml-in-r-examples/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/02/simple-nomnoml-in-r-examples/</guid>
      <description>1 Load packages 2 Motivation 3 Introducing Nomnoml 4 R API 5 Adjust the size 6 Change the direction 7 Size of the HTML container 8 Save to disk 9 Load from SVG 10 Caveats 11 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(nomnoml) # graphs library(magick) # render SVG image 2 Motivation Sketching diagrams such as flow charts is a useful thing. There exist a number of well-known (command line) engine for that purpose, such as</description>
    </item>
    
    <item>
      <title>Visualizing variation in data, simple ideas</title>
      <link>https://data-se.netlify.app/2022/04/02/visualizing-variation-in-data-simple-ideas/</link>
      <pubDate>Sat, 02 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/04/02/visualizing-variation-in-data-simple-ideas/</guid>
      <description>1 Load packages 2 Simulate data 3 Plot 1 4 Plot 2 5 Plot 3 6 Plot 4 7 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Simulate data low_spread &amp;lt;- tibble(var = rnorm(n = 100), id = 1:100, type = &amp;quot;low spread&amp;quot;) high_spread &amp;lt;- tibble(var= rnorm(n = 100, sd = 10), id = 1:100, type = &amp;quot;high spread&amp;quot;) d &amp;lt;- low_spread %&amp;gt;% bind_rows(high_spread) 3 Plot 1 ggplot(d) + aes(x = id, y = var) + facet_wrap(~ type) + geom_hline(yintercept = 0, color = &amp;quot;grey40&amp;quot;) + geom_point() + theme_minimal() 4 Plot 2 ggplot(d) + aes(x = type, y = var) + geom_boxplot() 5 Plot 3 ggplot(d) + aes(x = var, fill = type) + geom_density(alpha = .</description>
    </item>
    
    <item>
      <title>Programming the tidyverse: quoted and unqouted parameters</title>
      <link>https://data-se.netlify.app/2022/03/11/programming-the-tidyverse-quoted-and-unqouted-parameters/</link>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/03/11/programming-the-tidyverse-quoted-and-unqouted-parameters/</guid>
      <description>1 Load packages 2 Motivation 3 First: Quoted (string) parameter 4 Second: Unquoted parameter 5 Check 6 Bonus 1 Load packages library(tidyverse) # data wrangling 2 Motivation If a project reaches some level of complexity, sooner or later, more systematical meausures of coding need to be employed.
Using the tidyverse ecosystem, programming - instead of interactive use - may be something different or unusual and it may take some time to wrap your head around it.</description>
    </item>
    
    <item>
      <title>Data sets for for teaching</title>
      <link>https://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/</link>
      <pubDate>Wed, 23 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/02/23/data-sets-for-for-teaching/</guid>
      <description>1 Load packages 2 Data 3 Data repositories 4 How to import into R 5 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Data Here’s a opionated list of data sets useful for teaching purposes:
mtcars csv doc tips csv doc flights (NYCflights13) csv doc Saratoga houses csv doc diamonds csv doc wo_men csv OECD well-being source penguins csv doc Ames housing source on Kaggle, login needed teacher rating csv doc Note that the data sets are provided as standard CSV files (comma separeted, dots as delimiters).</description>
    </item>
    
    <item>
      <title>tidyeval, some musings on dplyr::filter</title>
      <link>https://data-se.netlify.app/2022/02/09/tidyeval-some-musings-on-dplyr-filter/</link>
      <pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/02/09/tidyeval-some-musings-on-dplyr-filter/</guid>
      <description>Programming with the tidyverse … Is not exactly self-evident. It actually requires some head wrapping, at least in my experience. In this post, we are exploring some aspects on programming when filtering rows. Let’s see.
Setup library(tidyverse) Some filtering chunk Let’s say we would like to filter observations according to some variable and a given threshold in some data set:
mtcars %&amp;gt;% filter(hp &amp;gt; 200) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Duster 360 14.</description>
    </item>
    
    <item>
      <title>Checking Moodle test log data</title>
      <link>https://data-se.netlify.app/2022/02/08/checking-moodle-test-log-data/</link>
      <pubDate>Tue, 08 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/02/08/checking-moodle-test-log-data/</guid>
      <description>Motivation: Let’s check whether server blackouts seem probable After one particular exam, a student complaint that Moodle was not reacting during some specified time period.
In this post, we’ll check whether we find evidence in favor or against a failout of the server.
Setup library(&amp;quot;tidyverse&amp;quot;) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.7 ## ✓ tidyr 1.</description>
    </item>
    
    <item>
      <title>Erbie: Einfache, reproduzierbare Beispiele Ihres Problems mit (R-)Syntax</title>
      <link>https://data-se.netlify.app/2022/01/31/erbie-einfache-reproduzierbare-beispiele-ihres-problems-mit-r-syntax/</link>
      <pubDate>Mon, 31 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/31/erbie-einfache-reproduzierbare-beispiele-ihres-problems-mit-r-syntax/</guid>
      <description>Hilfe, mein R läuft nicht? Was soll ich tun? Angenommen, Sie haben ein Problem mit R … Oder präzisieren wir, Sie haben ein Problem mit einer bestimmten R-Syntax (ob R auch ein Problem mit uns haben kann, ist nicht bekannt).
Jedenfall wollen Sie, dass R etwas bestimmtes tut. Macht es aber nicht. Jetzt könnte man es mit anschreien versuchen; Maschinen lassen das geduldig über sich ergehen. Man könnte den Computer zum Fenster rausschmeißen, das könnte auch Erleichterung bringen … Dem hab ich’s jetzt mal richtig gezeigt.</description>
    </item>
    
    <item>
      <title>Bayes in fünf Minuten, für Fortgeschrittene</title>
      <link>https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/28/bayes-in-f%C3%BCnf-minuten-f%C3%BCr-fortgeschrittene/</guid>
      <description>Das ist wieder ein Fünf-Minuten-Bayes-Kurs Sie würden gerne Bayes lernen und dafür zwischen 1-3 Wochen Zeit investieren? Dann sind Sie hier falsch. Dieser Post zeigt einen Kurzüberblick in leicht fortgechrittenen Bayes-Statistik in fünf Minuten. Naja, ich probiere es jedenfalls.
Forschungsfrage Sagen wir, uns interessiert folgende Forschungsfrage, die mit Methoden der Inferenz-Statistik untersucht werden soll. In diesem Fall Bayes-Inferenz (nicht Frequentistische Statistik).
Verbrauchen Autos mit Automatik-Getriebe im Durchschnitt mehr Sprit als Autos mit manuellem Getriebe?</description>
    </item>
    
    <item>
      <title>Bayes-Software installieren für R</title>
      <link>https://data-se.netlify.app/2022/01/28/bayes-software-installieren-f%C3%BCr-r/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/28/bayes-software-installieren-f%C3%BCr-r/</guid>
      <description>R und seine Freunde installieren. Schauen Sie, dass Sie zuerst R und seine Freunde installiert haben.
Bayes-Software Bayes-Inferenz kann rechenintensiv sein. Daher braucht’s Software, die schnell rechnen kann. Außerdem sollte die Software sich gut mit Wahrscheinlichkeitsrechnung auskennen, denn Bayes ist nichts anderes als angewandte Wahrscheinlichkeitsrechnung.
Aktuell ist die Software Stan die führende Software für diesen Zweck.
Bevor Sie aber Stan installieren können, brauchen Sie eine (Software für eine) “schnelle Rechenmaschine” auf Ihrem Computer installiert.</description>
    </item>
    
    <item>
      <title>Kurs &#34;Bayes:Start&#34;</title>
      <link>https://data-se.netlify.app/2022/01/28/kurs-bayes-start/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/28/kurs-bayes-start/</guid>
      <description>Bayes lernen Sie möchten (oder müssen) Bayes lernen? Hier ist ein Kurs dazu.
Alle Materialien des Kurses sind frei verfügbar, können kostenfrei genutzt werden und sind quelloffen.</description>
    </item>
    
    <item>
      <title>Kurs: &#34;Vorhersage-Modellierung&#34;</title>
      <link>https://data-se.netlify.app/2022/01/28/kurs-vorhersage-modellierung/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/28/kurs-vorhersage-modellierung/</guid>
      <description>Einführung in die Vorhersage-Modellierung 🔮 Ein Kurs zur Grundlagen der Datenanalyse und der Vorhersage-Modellierung mit R.
Hier geht es zum Kurs.
Alle Materialien des Kurses sind frei verfügbar, können kostenfrei genutzt werden und sind quelloffen.</description>
    </item>
    
    <item>
      <title>Wissenschaftliche Notation in R an und ausstellen</title>
      <link>https://data-se.netlify.app/2022/01/28/wissenschaftliche-notation-in-r-an-und-ausstellen/</link>
      <pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/28/wissenschaftliche-notation-in-r-an-und-ausstellen/</guid>
      <description>Wissenschaftliche Notation, was is das? Zahlen können in der “fixierten” oder normalen Notation geschrieben sein:
1 ## [1] 1 oder
10 ## [1] 10 und so weiter.
Die sog. wissenschaftliche Notation von Zahlen sieht so aus:
## [1] 1e+15 Die wissenschaftliche Notation dieser großen Zahl sagt uns: “Das ist eine Zahl, die mit der Ziffer 1 beginnt und dann folgen 15 Nullen”.
Das e steht für Exponent. Eigentlich nutzt der Computer die typische Taschenrechner-Schreibweise, von dem, was in der Mathe so geschrieben würde:</description>
    </item>
    
    <item>
      <title>Bayes in fünf Minuten</title>
      <link>https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/27/bayes-in-f%C3%BCnf-minuten/</guid>
      <description>Das ist ein Fünf-Minuten-Bayes-Kurs Sie würden gerne Bayes lernen und dafür zwischen 1-3 Wochen Zeit investieren? Dann sind Sie hier falsch. Dieser Post zeigt einen Kurzüberblick in Bayes-Statistik in fünf Minuten. Naja, ich probiere es jedenfalls.
Forschungsfrage Sagen wir, uns interessiert folgende Forschungsfrage, die mit Methoden der Inferenz-Statistik untersucht werden soll. In diesem Fall Bayes-Inferenz (nicht Frequentistische Statistik).
Verbrauchen Autos mit Automatik-Getriebe im Durchschnitt mehr Sprit als Autos mit manuellem Getriebe?</description>
    </item>
    
    <item>
      <title>Visualizing error distribution in regression analysis</title>
      <link>https://data-se.netlify.app/2022/01/27/visualizing-residual-distribution-in-regression-analysis/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/27/visualizing-residual-distribution-in-regression-analysis/</guid>
      <description>Errors and residuals in Regression A residual is defined as
\(r_i = y_i - X_i \hat{\beta}\).
That is, a residual is a tangible thing in the sense that it describes observables (cf. Gelman 2021, chap. 11.3, p. 161). That is, the residuals are the difference between observed and predicted values.
In contrast, the error term is defined as the difference between the observed value and the true (unobserved) value:</description>
    </item>
    
    <item>
      <title>Warum Bayes anstelle von Frequentismus?</title>
      <link>https://data-se.netlify.app/2022/01/27/warum-bayes/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/27/warum-bayes/</guid>
      <description>Plädoyer pro Bayes Dieser Post ist ein Plädoyer, Bayes-Statistik in der Statistikausbildung und in der praktischen Forschung zu nutzen. Keines der hier vorgetragenen Argumente ist neu. Die Thematik ist schon 1000 Mal diskutiert worden und oft umfangreicher und systematischer, ja besser, als in diesem Post. Ich schreibe hier kurz meine Sichtweise zusammen und verweise auf weitere Liteatur.
Bayes-Inferenz kenn ich nicht! Die klassische Statistikausbildung in den Sozialwissenschaften beinhaltet meist kein oder kaum Bayes.</description>
    </item>
    
    <item>
      <title>Visualizing a log-y regression model</title>
      <link>https://data-se.netlify.app/2022/01/14/visualizing-a-log-y-regression-model/</link>
      <pubDate>Fri, 14 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2022/01/14/visualizing-a-log-y-regression-model/</guid>
      <description>Setup library(tidyverse) data(mtcars) Using a log-Y regression Gelman et al., in “Regression and other stories” are stating that “when additivity and linearity are not reasonable assumptions” it may sense to “take the logarithms of outcomes that are all positive” (p. 189).
A log-y regression can be defined as follows, in the simplest case:
\[\text{log} \, y = b_0 + b_1X_1 + \ldots + \epsilon\] Exponentiating both sides yields
\[y = e^{b_0 + b_1X_1 + \ldots + \epsilon}\]</description>
    </item>
    
    <item>
      <title>Simulation on controlling confounders</title>
      <link>https://data-se.netlify.app/2021/12/01/simulation-on-controlling-confounders/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/12/01/simulation-on-controlling-confounders/</guid>
      <description>Confounder A confounder is on of the few (maybe three) “atoms” of causality, following the framework of Judea Parl and others.
A confounder can be depicted like this:
Following a study that reported a strong correlation between chocolate consumption and Nobel prices.
Simulating a confounder structure Now let’s simulate a simple confounder structure.
Here’s some code that will help us:
Let’s have a look at the code:
## ## n &amp;lt;- 100 ## ## set.</description>
    </item>
    
    <item>
      <title>Installation von R und seiner Freunde</title>
      <link>https://data-se.netlify.app/2021/11/30/installation-von-r-und-seiner-freunde/</link>
      <pubDate>Tue, 30 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/11/30/installation-von-r-und-seiner-freunde/</guid>
      <description>1 Überblick 2 Versions-Infos und Update 3 Installation 3.1 R 3.2 RStudio 3.3 RStudio Cloud 3.3.1 Konto anlegen 3.3.2 Projekte 3.4 R-Pakete 3.4.1 Was sind R-Pakete? 3.4.2 Welche R-Pakete brauche ich? 3.5 Hinweise 4 Wenn nichts mehr hilft … 1 Überblick Wir wollen uns hier nicht mit Fragen beschäftigen Warum R? (und auch nicht mit Warum, R?). Stattdessen soll Ihnen diese Seite helfen, R und was sonst noch so dazu gehört, zu installieren.</description>
    </item>
    
    <item>
      <title>Analyse einiger RKI-Coronadaten: Eine reproduzierbare Fallstudie</title>
      <link>https://data-se.netlify.app/2021/11/27/analyse-der-rki-coronadaten/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/11/27/analyse-der-rki-coronadaten/</guid>
      <description>1 R-Pakete 2 Hintergrund 3 Inzidenzen in Deutschland - Daten vom RKI 4 Hospitalisierungen in Deutschland 4.1 Adjustierte Daten 4.1.1 Daten importieren 4.1.2 EDA 4.2 Unadjustierte Daten 4.2.1 Daten importieren 4.2.2 EDA 5 Impfungen in Deutschland 5.1 Neueste Daten 5.1.1 Daten laden 5.1.2 EDA 5.2 Impfquoten im Zeitverlauf 5.2.1 Daten laden 1 5.2.2 Daten laden 2 5.3 EDA 5.3.1 Impfquote Deutschland im Zeitverlauf 5.3.2 Impfquote der Bundesländer im Zeitverlauf 6 Daten joinen 7 Zusammenhangsanalysen 7.</description>
    </item>
    
    <item>
      <title>Jedes dritte Corona-Tote ist geimpft, also bringt Impfen nix? Falsch.</title>
      <link>https://data-se.netlify.app/2021/11/15/jedes-dritte-intensivbett-mit-geimpften-belegt-also-bringt-impfen-nix-falsch/</link>
      <pubDate>Mon, 15 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/11/15/jedes-dritte-intensivbett-mit-geimpften-belegt-also-bringt-impfen-nix-falsch/</guid>
      <description>1 Der dritte Corona-Tote geimpft?! 2 tl;dr 3 Frage: Wie viele Menschen mit Corona wurden ins Krankenhaus eingeliefert? 4 Antwort: Hospitalisierungsquoten lagen jüngst zwischen 1% und 15% 5 Frage: Ist jede Dritte Corona-Tote geimpft? 6 Antwort: Ja, diese Zahl stimmt oder ist höher 7 Frage: Wenn es so viele geimpfte Corona-Opfer gibt, dann ist die Impfung also kaum wirksam? 8 Antwort: Der Anteil der Impfdurchbrüche ist abhängig von der Impfquote 9 Frage: Wie hoch ist die Impfquote unter den Coronatoten?</description>
    </item>
    
    <item>
      <title>Simulation sample and interval sizes for proportions</title>
      <link>https://data-se.netlify.app/2021/09/16/simulation-sample-and-interval-sizes-for-proportions/</link>
      <pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/09/16/simulation-sample-and-interval-sizes-for-proportions/</guid>
      <description>1 Exemplary Research question 2 Task definition 3 Technical setup 4 Define constants 5 Prepare data frame for the simulation 6 Simulation 7 Check some distributions 8 Minimum sample size 9 Plot results 10 Summary 11 Discussion 12 Suggested reading Bibliography 1 Exemplary Research question What is the sample size needed to estimate the proportion of the event “high quality study” with an error margin of ±5%, and a confidence level of 99%?</description>
    </item>
    
    <item>
      <title>MAD SD und 1.483</title>
      <link>https://data-se.netlify.app/2021/08/11/mad-sd-und-1-483/</link>
      <pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/08/11/mad-sd-und-1-483/</guid>
      <description>Setup library(tidyverse) library(mosaic) Sind wir nicht alle ein bisschen MAD? Der MAD oder Median Absolute Deviation ist eine robuste Kennzahl der Variabilität (eines quantitativen Merkmals).
Definition MAD Seien \(X_1, X_2, ..., X_n\) die Beobachtungen einer Stichprobe zu einem Merkmal \(X\).
Dann ist der MAD so definiert:
\(\text {MAD} =\operatorname{median} (|X_{i}-{\tilde {X}}|)\).
Anders gesagt, der MAD ist der Median der Absolutwerte der Residuen.
Robust? Robust heißt kurz (und vereinfacht) gesagt, dass der Kennwert nicht (zu sehr) von Extremwerten beeinflusst wird.</description>
    </item>
    
    <item>
      <title>Metadaten von Forschungsartikeln herunterladen</title>
      <link>https://data-se.netlify.app/2021/07/08/metadaten-von-forschungsartikeln-herunterladen/</link>
      <pubDate>Thu, 08 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/07/08/metadaten-von-forschungsartikeln-herunterladen/</guid>
      <description>1 Vorbereitung 2 Via Crossref 2.1 Abfragen, einfach 3 Filter 3.1 Anzahl 4 Dois rausziehen 5 Zitationen herunterladen 6 Abstracts herunterladen 6.1 “Safely” Abstracts herunterladen 6.2 Artikel nur mit Abstracts 6.3 Abstract mit cr_abstract 6.4 Check 6.5 Auf einen Haps 7 Andere APIs 7.1 Google Scholar hat keine API, wie es aussieht 7.1.1 Weitere API 1 Vorbereitung library(tidyverse) library(printr) library(rcrossref) library(gt) 2 Via Crossref Von der Crossref-Webseite:
Crossref makes research outputs easy to find, cite, link, assess, and reuse.</description>
    </item>
    
    <item>
      <title>Zeitungsartikel per API herunterladen</title>
      <link>https://data-se.netlify.app/2021/07/07/zeitungsartikel-per-api-herunterladen/</link>
      <pubDate>Wed, 07 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/07/07/zeitungsartikel-per-api-herunterladen/</guid>
      <description>library(tidyverse) library(newsanchor) library(printr) library(httr) library(jsonlite) News API Es gibt eine Seite News API, die es erlaubt, per API News (Artikel, Schlagzeilen) von weltweiten Quellen herunterzuladen, per JSON API.
Gibt’s da auch ein R-Paket? Ja - NewsAnchor.
Setup Zuerst muss man sich bei der Seite eine API Key holen, für Entwicklerzwecke kostenlos. Komfortabel ist, sich den Schlüssel in die R-environment-Datei (.Renviron) zu schreiben, s. hier für mehr Infos.
Das kann man z.</description>
    </item>
    
    <item>
      <title>Vorhersage-Modellierung des Diamantenpreises</title>
      <link>https://data-se.netlify.app/2021/07/06/diamantenpreis-vorhersagen/</link>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/07/06/diamantenpreis-vorhersagen/</guid>
      <description>1 Vorbereitung 1.1 Forschungsfrage 1.2 Aufgabe 1.3 Pakete laden 1.4 Daten laden 1.5 ID-Spalte ergänzen 2 Vorwissen 3 Woran erkennt man einen “starken Haupteffekt”? 4 Wichtige Prädiktoren 4.1 train2 4.2 test2 5 Feature Engineering 5.1 train3/test3 5.2 Korrelation 5.3 preds_important 6 Funktionale Form der Zusammenhänge 7 Filtern 7.1 train4 8 Transformationen 8.1 Log-Transformation (train5) 8.2 z-Transformation (train6) 9 Vorhersage-Modellierung 9.1 lm1 9.2 lm2 9.3 lm3 9.4 lm4 9.5 lm5 9.</description>
    </item>
    
    <item>
      <title>Diagrams with mermaid</title>
      <link>https://data-se.netlify.app/2021/07/01/diagrams-with-mermaid/</link>
      <pubDate>Thu, 01 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/07/01/diagrams-with-mermaid/</guid>
      <description>Setup library(tidyverse) library(DiagrammeR) Separating concept and appeal It can be useful to separate the content or concept from its graphical/visual implementation. For this reasons, slide shows have disadvantages: You spend a lot of time dragging arrows and boxes. This time would be better spend in thinking about why and where to move your arrows and boxes.
In addition, software that intermingles concept and representation typically is a vendor lock: You cannot (easily) get out if you find some more useful softare.</description>
    </item>
    
    <item>
      <title>Talent and Looks -- Collider bias</title>
      <link>https://data-se.netlify.app/2021/06/24/talent-and-looks-collider-bias/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/06/24/talent-and-looks-collider-bias/</guid>
      <description>Background Some musing on the collider bias.
Let’s try to reverse engineer this image
Setup library(tidyverse) library(ggdag) Simulate some data n &amp;lt;- 1000 d &amp;lt;- tibble( x = rnorm(n, mean = 0, sd = 1), y = rnorm(n, mean = 0, sd = 1), e = rnorm(n, mean = 0, sd = 0.3), z = abs(x) * abs(y)) d: Uncorrelated data The farer from the centroid the lighter the color.</description>
    </item>
    
    <item>
      <title>Overlaying facetted histograms with normal curve using ggplot2</title>
      <link>https://data-se.netlify.app/2021/06/23/overlaying-facetted-histograms-with-normal-curve-using-ggplot2/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/06/23/overlaying-facetted-histograms-with-normal-curve-using-ggplot2/</guid>
      <description>Overlaying histograms with a normal curve Overlaying a histogram (possibly facetted) is not something far fetched when analyzing data. Surprisingly, it appears (to the best of my knowledge) that there’s no comfortable out-of-the-box solution in ggplot2, although it can be of course achieved with some lines of code. Here’s my take.
Setup library(tidyverse) Some data d &amp;lt;- read_csv(&amp;quot;https://vincentarelbundock.github.io/Rdatasets/csv/openintro/speed_gender_height.csv&amp;quot;) ## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1] ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## X1 = col_double(), ## speed = col_double(), ## gender = col_character(), ## height = col_double() ## ) glimpse(d) ## Rows: 1,325 ## Columns: 4 ## $ X1 &amp;lt;dbl&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, … ## $ speed &amp;lt;dbl&amp;gt; 85, 40, 87, 110, 110, 120, 90, 90, 80, 95, 110, 90, 110, 70, 10… ## $ gender &amp;lt;chr&amp;gt; &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;male&amp;quot;, &amp;quot;female&amp;quot;, &amp;quot;female… ## $ height &amp;lt;dbl&amp;gt; 69, 71, 64, 60, 70, 61, 65, 65, 61, 69, 63, 72, 70, 68, 63, 78,… d %&amp;gt;% slice_head(n = 5) ## # A tibble: 5 x 4 ## X1 speed gender height ## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; ## 1 1 85 female 69 ## 2 2 40 male 71 ## 3 3 87 female 64 ## 4 4 110 female 60 ## 5 5 110 male 70 Preparing data We’ll use a “total” histogram for the whole sample, to that end, we’ll need to remove the grouping information from the data.</description>
    </item>
    
    <item>
      <title>Rücktransformation logarithmierter y-Werte</title>
      <link>https://data-se.netlify.app/2021/06/18/r%C3%BCcktransformation-logarithmierter-y-werte/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/06/18/r%C3%BCcktransformation-logarithmierter-y-werte/</guid>
      <description>1 Kontext 2 Vorbereitung 3 LogY-LogX-Modell 4 Modell 1 5 Vorhersage zum Beispiel aus der Fallstudie 6 Vorhersagen wie im Prognose-Wettbewerb 7 Check 1 Kontext Dieser Post bezieht sich auf diese Fallstudie.
2 Vorbereitung library(tidyverse) # Datenjudo ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.4 ✓ purrr 0.3.4 ## ✓ tibble 3.1.2 ✓ dplyr 1.0.6 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 1.</description>
    </item>
    
    <item>
      <title>Beispiel zur Interpretation des Interaktionseffekts</title>
      <link>https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/</guid>
      <description>1 Der Interaktionseffekt in der Regressionsanalyse 2 Vorbereitung 3 Regression mit Interaktionseffekt, die Erste 3.1 z-Transformation des Prädiktors hp 3.2 lm1 4 Regression mit Interaktionseffekt, die Zweite 4.1 Daten 4.2 Ohne z-Transformation 4.3 Mit z-Transformation 4.4 Visualisierung 4.5 Interpretation zum Vorhandensein eines Interpretationseffekts 4.6 Interpretation der Koeffizienten 4.7 Viel besser mit z-Transformation 4.8 Berechnen eines vorhergesagten Wertes mit der Hand 5 Fazit 1 Der Interaktionseffekt in der Regressionsanalyse Der Interaktionseffekt in der Regressionsanalyse ist nicht einfach zu interpretieren.</description>
    </item>
    
    <item>
      <title>Vektorisierter Mittelwert in R</title>
      <link>https://data-se.netlify.app/2021/06/15/vektorisierter-mittelwert-in-r/</link>
      <pubDate>Tue, 15 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/06/15/vektorisierter-mittelwert-in-r/</guid>
      <description>Setup library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.3 ✓ purrr 0.3.4 ## ✓ tibble 3.1.2 ✓ dplyr 1.0.6 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 1.4.0 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Einige Funktionen in R sind vektorisiert, andere nicht Einige Funktionen in R sind vektorisiert: sie führen ihren Dienst für jedes Element eines Vektors aus.</description>
    </item>
    
    <item>
      <title>Logarithmen und Exponenten in Regressionen: Wer braucht sowas?</title>
      <link>https://data-se.netlify.app/2021/05/31/logarithmen-und-exponenten-in-regressionen-wer-braucht-sowas/</link>
      <pubDate>Mon, 31 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/31/logarithmen-und-exponenten-in-regressionen-wer-braucht-sowas/</guid>
      <description>Die Folien des Vortrags (HTML-Version) liegen hier. Eine Internetverbindung ist nötig, um die Folien zu betrachten.
Die Rmd-Quelldatei liegt hier.
Lizenz: CC-BY</description>
    </item>
    
    <item>
      <title>Analyse der Impfbereitschaft von Studentis</title>
      <link>https://data-se.netlify.app/2021/05/30/analyse-der-impfbereitschaft-von-studentis/</link>
      <pubDate>Sun, 30 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/30/analyse-der-impfbereitschaft-von-studentis/</guid>
      <description>1 Analyse der Impfbereitschaft 2 Vorbereitung 2.1 Pakete laden 2.2 Daten laden 2.3 Daten und Variablen 2.4 Sind die Items schon umgepolt? 2.5 Liegen Mittelwerte für die Persönlichkeits-Dimensionen vor? 3 Daten verstehen 3.1 Fehlende Werte 3.2 Nominal skalierte Variablen in numerische umwandeln 3.3 Welche Variablen korrelieren mit der Impfbereitschaft? 3.4 Korrelation der Items pro Big-Five-Dimension 4 Modell mit den Big-Five-Dimensionen als Prädiktoren 5 Zur Datenqualität 6 Visualisierung 1 6.1 Median-Aufteilung 6.</description>
    </item>
    
    <item>
      <title>YACSDA Seitensprünge</title>
      <link>https://data-se.netlify.app/2021/05/28/yacsda-seitenspr%C3%BCnge/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/28/yacsda-seitenspr%C3%BCnge/</guid>
      <description>1 Setup 2 Forschungsfrage und Hintergrund 3 ACHTUNG 4 Daten laden 5 Aufgaben 6 Los geht’s 6.1 Geben Sie zentrale deskriptive Statistiken an für Affärenhäufigkeit und Ehezufriedenheit! 6.2 Visualisieren Sie zentrale Variablen! 6.2.1 affairs 6.2.2 rating 6.3 Wer ist zufriedener mit der Partnerschaft: Personen mit Kindern oder ohne? 6.4 Wie viele fehlende Werte gibt es? Was machen wir am besten damit? 6.5 Wer ist glücklicher in der Partnerschaft: Männer oder Frauen?</description>
    </item>
    
    <item>
      <title>Beispiel für pivot_longer()</title>
      <link>https://data-se.netlify.app/2021/05/27/beispiel-f%C3%BCr-pivot-longer/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/27/beispiel-f%C3%BCr-pivot-longer/</guid>
      <description>1 Setup 2 Daten laden 3 Von lang nach breit 4 Plotten 5 Kommentar 1 Setup library(tidyverse) 2 Daten laden d &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/sebastiansauer/2021-sose/master/data/Impfbereitschaft/d3.csv&amp;quot;) 3 Von lang nach breit d2 &amp;lt;- d %&amp;gt;% select(willingness:open2) %&amp;gt;% pivot_longer(extra1:open2) d2 %&amp;gt;% slice_head(n = 7) #&amp;gt; # A tibble: 7 x 6 #&amp;gt; willingness health fear cases name value #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 10 9 5 1 extra1 2 #&amp;gt; 2 10 9 5 1 agree1 2 #&amp;gt; 3 10 9 5 1 cons1 3 #&amp;gt; 4 10 9 5 1 neuro1 2 #&amp;gt; 5 10 9 5 1 open1 4 #&amp;gt; 6 10 9 5 1 extra2 1 #&amp;gt; 7 10 9 5 1 agree2 4 4 Plotten d2 %&amp;gt;% ggplot() + aes(x = willingness, y = value) + facet_wrap(~ name) + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;) Jedes Diagramm zeigt den Zusammenhang von Impfbereitschaft mit einem Big-Five-Item.</description>
    </item>
    
    <item>
      <title>Datensatz flights: Finde den Tag mit den meisten Abflügen</title>
      <link>https://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/27/datensatz-flights-finde-den-tag-mit-den-meisten-abfl%C3%BCgen/</guid>
      <description>1 Aufgabe: Finde den Tag mit den meisten Abflügen (flights)! 2 Setup 3 Daten laden 4 Spalte mit Datum ergänzen 5 Datensatz zusammenfassen 6 Maximalwert der Spalte n 1 Aufgabe: Finde den Tag mit den meisten Abflügen (flights)! An welchem Tag im Jahr 2013 sind die meisten Flüge aus NYC gestartet?
2 Setup library(tidyverse) # Datenjudo library(nycflights13) # Daten library(lubridate) # Datumsangaben 3 Daten laden data(flights) 4 Spalte mit Datum ergänzen flights &amp;lt;- flights %&amp;gt;% mutate(date = date(time_hour)) 5 Datensatz zusammenfassen flights2 &amp;lt;- flights %&amp;gt;% group_by(date) %&amp;gt;% summarise(n = n()) Synonym:</description>
    </item>
    
    <item>
      <title>Zeilenweise Operationen (tidyverse-Stil)</title>
      <link>https://data-se.netlify.app/2021/05/27/zeilenweise-operationen-tidyverse-stil/</link>
      <pubDate>Thu, 27 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/27/zeilenweise-operationen-tidyverse-stil/</guid>
      <description>1 Aufgabe 2 Setup 3 Daten erzeugen 4 Spalten addieren, die Erste 5 Spalten addieren, die Zweite 6 Spalten addieren, die Dritte 7 Von erster Spalte bis zu letzter Spalte 8 Fazit 1 Aufgabe Berechnen Sie Zeilensummen! … Oder Zeilen-Mittelwerte oder eine andere zeilenbasierte Funktion.
2 Setup library(tidyverse) # Datenjudo 3 Daten erzeugen d &amp;lt;- tribble( ~&amp;quot;x1&amp;quot;, ~&amp;quot;x2&amp;quot;, ~&amp;quot;x3&amp;quot;, 1, 2, 3, 4, 5, 6, 7, 8, 9 ) d #&amp;gt; # A tibble: 3 x 3 #&amp;gt; x1 x2 x3 #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 1 2 3 #&amp;gt; 2 4 5 6 #&amp;gt; 3 7 8 9 4 Spalten addieren, die Erste d %&amp;gt;% mutate(summe = x1 + x2 + x3) %&amp;gt;% mutate(mw = (x1 + x2 + x3)/3) #&amp;gt; # A tibble: 3 x 5 #&amp;gt; x1 x2 x3 summe mw #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 1 2 3 6 2 #&amp;gt; 2 4 5 6 15 5 #&amp;gt; 3 7 8 9 24 8 Läuft!</description>
    </item>
    
    <item>
      <title>Modellierung Diamantenpreis 2</title>
      <link>https://data-se.netlify.app/2021/05/25/modellierung-diamantenpreis-2/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/25/modellierung-diamantenpreis-2/</guid>
      <description>1 Modellierung des Preises von Diamanten 2 Pakete laden 3 Daten laden 4 Datensatz verstehen 5 Modellierung 5.1 Modell 1 5.1.1 Modellgüte 5.1.2 Überprüfung der Annahmen 5.2 Modell 2 5.2.1 Genauerer Blick auf den Zusammenhang 5.2.2 Log-Modell 5.3 Modell 3 5.3.1 Modellgüte 5.3.2 Voraussetzungen prüfen 5.4 Modell 3a und 4 5.4.1 Konfundierung von Schliff und Karat 5.4.2 lm3a 5.4.3 lm4: Schliff als Prädiktor 5.4.4 Modellkoeffizienten 5.4.5 \(R^2\) zur Beurteilung der Relevanz von Prädiktoren 6 Fazit: “Händische” Modellierung 6.</description>
    </item>
    
    <item>
      <title>Vorhersage-Modellierung des Preises von Diamanten</title>
      <link>https://data-se.netlify.app/2021/05/19/vohrersgage-modellierung-des-preises-von-diamanten/</link>
      <pubDate>Wed, 19 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/05/19/vohrersgage-modellierung-des-preises-von-diamanten/</guid>
      <description>1 Hintergrund und Ziel 2 Pakete laden 3 Daten laden 4 Aufteilen in Train- und Test-Datensatz 5 EDA 6 Modellierung 6.1 Modell 1 6.2 Modell 2 7 Vorhersage im Test-Datensatz 8 R-Quadrat im Test-Datensatz 9 Weitere Überlegungen 10 Einreichen 1 Hintergrund und Ziel In diesem Post sagen wir den Preis von Diamanten vorher. Nehmen wir an, Sie hätten bei einem großen Online-Kaufhaus angeheuert und ihre Chefin möchte gerne wissen, welchen Preis sie wohl für bestimmte Diamanten erzielen kann.</description>
    </item>
    
    <item>
      <title>Deutschlandkarten zeichnen mit R, für Anfänger</title>
      <link>https://data-se.netlify.app/2021/04/19/deutschlandkarten-zeichnen-mit-r-f%C3%BCr-anf%C3%A4nger/</link>
      <pubDate>Mon, 19 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/04/19/deutschlandkarten-zeichnen-mit-r-f%C3%BCr-anf%C3%A4nger/</guid>
      <description>1 Pakete laden 2 Welktarte zeichnen 3 Deutschlandkarte zeichnen 4 Mehr 5 Reproducibility 1 Pakete laden library(tidyverse) # data wrangling library(maps) Ggplot-Theme anpassen:
theme_set( theme_void() ) 2 Welktarte zeichnen world &amp;lt;- map_data(&amp;quot;world&amp;quot;) ggplot(world) + aes(x = long, y = lat, group = group) %&amp;gt;% geom_polygon(color = &amp;quot;white&amp;quot;, fill = &amp;quot;lightgray&amp;quot;) 3 Deutschlandkarte zeichnen Deutschland aus der Liste der Länder auswählen:
de &amp;lt;- map_data(&amp;quot;world&amp;quot;, region = &amp;quot;Germany&amp;quot;) ggplot(de, aes(x= long, y= lat)) + geom_polygon(aes(group = group), fill = &amp;quot;lightgray&amp;quot;, color = &amp;quot;white&amp;quot;) + geom_polygon(aes(group = group), color = &amp;quot;black&amp;quot;, fill = NA) 4 Mehr Mehr Hinweise zu Karten, insbesondere Choroplethenkarten, findet sich z.</description>
    </item>
    
    <item>
      <title>Fallstudie: Modellierung von Flugverspätungen</title>
      <link>https://data-se.netlify.app/2021/03/10/fallstudie-modellierung-von-flugversp%C3%A4tungen/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/03/10/fallstudie-modellierung-von-flugversp%C3%A4tungen/</guid>
      <description>1 Hintergrund und Forschungsfrage 2 Pakete laden 3 Daten laden 4 flights2: Nicht benötigte Variablen entfernen und ID hinzufügen 5 Aufteilung in Train- und Testsample 6 flights_train2, flights_test2 7 lm0: Nullmodell 8 lm1: origin 9 lm2: All in 10 flights_train3: Textvariablen in Faktorvariablen umwandeln 10.1 flights_test3 11 flights_train4: Faktorstufen zusammenfassen 11.1 flights_test4 12 lm3: Alle zusammengefassten Faktorvariablen 13 lm4: Alle metrischen Variablen 14 lm5: Alle metrischen und alle (zusammengefassten) nominalen Variablen 15 Wetter-Daten ergänzen 15.</description>
    </item>
    
    <item>
      <title>EDA zu Flugverspätungen</title>
      <link>https://data-se.netlify.app/2021/03/08/eda-zu-flugversp%C3%A4tungen/</link>
      <pubDate>Mon, 08 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/03/08/eda-zu-flugversp%C3%A4tungen/</guid>
      <description>1 Pakete laden 2 Hintergrund und Ziel 3 Daten laden 4 Was ist Verspätung? 4.1 Wie ähnlich sind Ankunfts- und Abflugsverspätung? 5 Verteilung der Verspätung 5.1 flights2: Extremwerte (der Verspätung) definieren 5.1.1 Boxplot-Methode 5.2 Fehlende Werte berechnen 5.3 flights3 6 Deskriptive Statistiken 6.1 Mit summarise 6.2 Mit skimr 7 Korrelate von Verspätung 7.1 Metrische Prädiktoren 7.1.1 Nur mit cor 7.1.2 Mit across 7.1.3 Mit correlate 7.2 Nominale Prädiktoren 7.2.1 Carrier 7.</description>
    </item>
    
    <item>
      <title>Estimating population effect size, some thoughts</title>
      <link>https://data-se.netlify.app/2021/03/04/estimating-population-effect-size-some-thoughts/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/03/04/estimating-population-effect-size-some-thoughts/</guid>
      <description>1 Load packages 2 Motivation 3 True value of the parameter 4 Drawing samples 5 Define some constants 6 Simulating samples 6.1 SummayFunction to compute sample statistics 6.2 Run the function multiple (\(k\)) times 6.3 Run the summary function \(k\) times for all sample sizes 7 Plot the results 7.1 Estimated population mean 7.2 Width of the CI 8 Summarise the results 8.1 Compute summaries per sample size 8.2 Plot the (summarized) results 9 Conclusions 9.</description>
    </item>
    
    <item>
      <title>How to standardize variables in R</title>
      <link>https://data-se.netlify.app/2021/02/26/how-to-standardize-variables-in-r/</link>
      <pubDate>Fri, 26 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/26/how-to-standardize-variables-in-r/</guid>
      <description>1 Motivation 2 Load packages 3 Some data 4 Research question 5 Regression with unstandardized input variables 6 Standardize input variables 7 Regression with standardized input variables 8 The models (lm1 and lm2) are identical 9 Interpretation of a standardized regression coefficient 10 Reproducibility 1 Motivation Running a regression in R yields unstandardized coefficients, not standardized ones. However, as is spelled out by eg., Gelman and Hill (2007), standardizing values is of advantages in many situations.</description>
    </item>
    
    <item>
      <title>Case study: data vizualization on flight delays using tidyverse tools</title>
      <link>https://data-se.netlify.app/2021/02/24/case-study-data-vizualization-on-flight-delays-using-tidyverse-tools/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/24/case-study-data-vizualization-on-flight-delays-using-tidyverse-tools/</guid>
      <description>1 Load packages 2 Load data 3 Exercises/questions 4 Solutions 4.1 Plot the distribution of the delays. Describe your insights. 4.2 Plot the distribution of the delays per origin airport. 4.3 Visualize the assocation of delay and time of the day. Find a way to reduce overplotting. 4.4 Visualize the assocation of delay and distance to destination. Separate by origin and month. 4.5 Visualize the assocation of delay and time of the day.</description>
    </item>
    
    <item>
      <title>Exercises (no solutions): data vizualization on flight delays using tidyverse tools</title>
      <link>https://data-se.netlify.app/2021/02/24/exercises-no-solutions-data-vizualization-on-flight-delays-using-tidyverse-tools/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/24/exercises-no-solutions-data-vizualization-on-flight-delays-using-tidyverse-tools/</guid>
      <description>1 Load packages 2 Get the data 2.1 Alternative way to get the data 2.2 Code book 3 Exercises 4 Solutions 5 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Get the data We’ll be analyzing the data set flights, describing the flights which started from NYC in 2013.
Here’s how to get the data set:
library(tidyverse) library(nycflights13) data(&amp;quot;flights&amp;quot;) 2.1 Alternative way to get the data Alternatively, import the data from a csv file:</description>
    </item>
    
    <item>
      <title>Exercises to data wrangling with the tidyverse</title>
      <link>https://data-se.netlify.app/2021/02/24/exercises-to-data-wrangling-with-the-tidyverse/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/24/exercises-to-data-wrangling-with-the-tidyverse/</guid>
      <description>1 Exercise collection: Life exptectancy 2 Disclosure 3 Research questions 4 First steps 5 Getting help 6 Exercises 6.1 Data Wrangling 6.2 Data Visualization 7 Solutions 8 Reproducibility library(tidyverse) 1 Exercise collection: Life exptectancy Get the data from this source.
gapminder_raw &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder-FiveYearData.csv&amp;quot;) 2 Disclosure This exercises are based on a tutorial by Rebekka Barter. Great work!
3 Research questions How did life expectancy change in the course of the last decades?</description>
    </item>
    
    <item>
      <title>Modelling movie successes: linear regression</title>
      <link>https://data-se.netlify.app/2021/02/24/modelling-movie-successes-linear-regression/</link>
      <pubDate>Wed, 24 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/24/modelling-movie-successes-linear-regression/</guid>
      <description>1 Load packages 2 Load data 3 Research question 4 Disclaimer 5 Get overview 5.1 Descriptive statistics 5.2 Missing values 5.3 Distribution of the output variable 5.4 Distribution of the predictors 5.5 Transform budget (via logarithm) 5.6 ggscatterstats 5.7 Pivot data set 5.8 Drop unused variables 5.9 Drop cases with missing values 6 Model 0 7 Model 1: budget_log10 8 Model 2: Adding number of votes 9 Model 3: Number of votes, quadratic 10 Model 4: Number of votes, 3rd degree 11 Model 5: Multiple regression 12 Model 6: Interaction 13 Model selection: ANOVA 14 Regression diagnostics: testing the assumptions 15 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(broom) # nice formatting of output library(skimr) # gives overview on descriptives library(ggfortify) # plotting regression diagnostics library(ggstatsplot) # fancy scatter plot 2 Load data Load this package to access the data set:</description>
    </item>
    
    <item>
      <title>Scraping Cochrane Reviews, some trials</title>
      <link>https://data-se.netlify.app/2021/02/19/scraping-cochrane-reviews/</link>
      <pubDate>Fri, 19 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/19/scraping-cochrane-reviews/</guid>
      <description>1 Load packages 2 Parse one review 3 Parse the title 4 Parse the abstract 5 Segment the abstract 5.1 Background 5.2 Objectives 5.3 And so forth 6 Summary of Findings table 6.1 Parse node of class ‘summaryOfFindings’ 6.2 Table by ID 6.3 Looking for tables 7 Extract (Primary) Outcomes with the GRADE 7.1 Get column with outcomes 7.2 Delete non-data rows 8 Delete footer 8.1 Get columns with GRADE information 8.</description>
    </item>
    
    <item>
      <title>Explorative Datenanalyse zum Datensatz &#34;OECD Wellbeing&#34;</title>
      <link>https://data-se.netlify.app/2021/02/11/explorative-datenanalyse-zum-datensatz-oecd-wellbeing/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/11/explorative-datenanalyse-zum-datensatz-oecd-wellbeing/</guid>
      <description>1 Load packages 2 Benötigte Pakete 3 Datensatz laden 4 Erster Blick 5 Metrische Variablen einzeln (univariat) 5.1 Histogramm nach Gruppen 5.2 VERTIEFUNG: Histogramm für alle Variablen 6 Forschungsfrage 7 Datensatz filtern - nur Länder, keine Landesteile 8 Vergleich der Lebenszufriedenheit der Länder 8.1 Umwandling in eine Faktor-Variable 8.2 Ranking und Top-10-Prozent der Zufriedenheit 8.3 Vertiefung 8.4 Vertiefung 8.5 Vertiefung 9 Zusammenhang zweier metrischer Variablen – Punktediagramm 9.0.1 Und so weiter 9.</description>
    </item>
    
    <item>
      <title>YACSDA: Topgear</title>
      <link>https://data-se.netlify.app/2021/02/11/yacda-topgear/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/02/11/yacda-topgear/</guid>
      <description>1 Load packages 1.1 Numerischer Überblick 1.2 Wie verteilen sich die Preise? 1.3 Wie ist der Zusammenhang von Preis und Beurteilung des Autos? 2 Wie verteilt sich das Gewicht der Autos? 3 Hängt Gewicht mit Preis zusammen? 4 Wie verteilt sich die Geschwindigkeit der Autos? 5 Hängt Preis mit Geschwindigkeit zusammen? 5.1 Wie hängt Geschwindigkeit mit Beurteilung zusammen? 5.2 Welche Hersteller hat die meisten Autotypen? 5.3 Die 10% größten Hersteller 5.</description>
    </item>
    
    <item>
      <title>Grading a prediction contest</title>
      <link>https://data-se.netlify.app/2021/01/20/grading-a-prediction-contest/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2021/01/20/grading-a-prediction-contest/</guid>
      <description>1 Motivation 2 Setup 3 Helper functions 3.1 Function to parse data 3.2 Function to compute \(R^2\) 3.3 Function to compute \(MSE\) 3.4 Function to compute generalized error function 4 Import solution (true) data (ie., solution) 5 Parse the data 6 Build master data frame 6.1 List df where each submission is one row 6.2 Change character to numeric 6.3 Add observed (true) values 6.4 Check lengths of submissions 7 Compute accuracy (\(R^2\) etc.</description>
    </item>
    
    <item>
      <title>Vorhersagen mit lm</title>
      <link>https://data-se.netlify.app/2020/12/15/vorhersagen-mit-lm/</link>
      <pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/15/vorhersagen-mit-lm/</guid>
      <description>1 Pakete laden 2 Daten laden 3 Forschungsfrage 3.1 Daten aufbereiten 3.2 Modell schätzen 4 Vorhersage mit predict() – ohne Schätzbereich 5 Vorhersage mit predict() – mit Schätzbereich 6 Reproducibility 1 Pakete laden library(tidyverse) # data wrangling library(moderndive) 2 Daten laden data(movies, package = &amp;quot;ggplot2movies&amp;quot;) 3 Forschungsfrage Wie beliebt ist erwartungsgemäß ein Actionfilm nach dem Jahr 2000, der zu den Top-10-Prozent der Budgetverteilung gehört?
3.1 Daten aufbereiten movies &amp;lt;- movies %&amp;gt;% mutate(year_after_2000 = case_when( year &amp;gt;= 2000 ~ &amp;quot;yes&amp;quot;, TRUE ~ &amp;quot;no&amp;quot; )) %&amp;gt;% mutate(is_top10percent_budget = case_when( percent_rank(budget) &amp;gt; 0.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: boost</title>
      <link>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-boost/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-boost/</guid>
      <description>1 Objective 2 Detect available cores 3 Load and prepare data 3.1 Hide details in a function 4 Split data into train and test 5 Define recipe 6 Define model 7 Define cross validation scheme 8 Define workflow 9 Define analysis and validation (oob) set 10 Fit the grid 11 View results 12 Get best model 13 Final fit (on train data) 13.1 Fit final workflow (on test data) 14 Predict test data 15 Save predictions to disk 16 Reproducibility library(tidyverse) # data wrangling library(tidymodels) # modelling library(broom) # tidy model output library(skimr) # overview on descriptives library(parallel) # multiple cores -- unix only 1 Objective Predicting the survival in the Titanic disaster.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: boost simple</title>
      <link>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-boost-simple/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-boost-simple/</guid>
      <description>1 Load packages 2 Objective 3 Load and prepare data 3.1 Hide details in a function 4 Split data into train and test 5 Define recipe 6 Define model 7 Define workflow 8 Fit the model 9 Predict the test data 10 Save csv file to disk 11 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling 2 Objective Predicting the survival in the Titanic disaster. We’ll be using a tidymodels approach.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: glm1</title>
      <link>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-glm1/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-glm1/</guid>
      <description>1 Load packages 2 Objective 3 Load and prepare data 3.1 Hide details in a function 4 Split data into train and test 5 Define recipe 6 Define model 7 Define workflow 8 Fit the model 9 Predict the test data 10 Save csv file to disk 11 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling library(broom) # tidy model output library(skimr) # overview on descriptives library(testthat) # unit testing 2 Objective Predicting the survival in the Titanic disaster.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: rf1</title>
      <link>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-rf1/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titanic-tidymodels-rf1/</guid>
      <description>1 Load packages 2 Objective 3 Load and prepare data 3.1 Hide details in a function 4 Split data into train and test 5 Define recipe 6 Define model 7 Define workflow 8 Fit the model 9 Predict the test data 10 Save csv file to disk 11 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling 2 Objective Predicting the survival in the Titanic disaster. We’ll be using a tidymodels approach.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: rf2</title>
      <link>https://data-se.netlify.app/2020/12/14/titanic-itdymodels-rf2/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titanic-itdymodels-rf2/</guid>
      <description>1 Load packages 2 Objective 3 Setup 4 Load and prepare data 4.1 Hide details in a function 5 Split data into train and test 6 Define recipe 7 Define model 8 Define cross validation scheme 9 Define workflow 10 Fit the grid 11 View results 12 Get best model 13 Final fit (on train data) 13.1 Fit final workflow (on test data) 14 Predict test data 15 Save predictions to disk 16 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling library(broom) # tidy model output library(skimr) # overview on descriptives library(parallel) # multiple cores -- unix only 2 Objective Predicting the survival in the Titanic disaster.</description>
    </item>
    
    <item>
      <title>titanic-tidymodels: tree</title>
      <link>https://data-se.netlify.app/2020/12/14/titani-tidymodels-tree/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/14/titani-tidymodels-tree/</guid>
      <description>1 Load packages 2 Objective 3 Load and prepare data 3.1 Hide details in a function 4 Split data into train and test 5 Define recipe 6 Define model 7 Define workflow 8 Fit the model 9 Predict the test data 10 Save csv file to disk 11 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling 2 Objective Predicting the survival in the Titanic disaster. We’ll be using a tidymodels approach.</description>
    </item>
    
    <item>
      <title>Kaggle Notebook on the Titanic competition using tidymodels</title>
      <link>https://data-se.netlify.app/2020/12/12/kaggle-notebook-on-the-titanic-competition-using-tidymodels/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/12/kaggle-notebook-on-the-titanic-competition-using-tidymodels/</guid>
      <description>Here is a Kaggle notebook on the Titanic prediction (ie., classifiactio) competition.</description>
    </item>
    
    <item>
      <title>Trying tidymodels: step_num2factor</title>
      <link>https://data-se.netlify.app/2020/12/12/trying-tidymodels-step-num2factor/</link>
      <pubDate>Sat, 12 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/12/trying-tidymodels-step-num2factor/</guid>
      <description>1 Load packages 2 Understanding recipes and preprocessing 3 Load data 4 Define recipe 5 Prepare (prep()) the recipe 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(tidymodels) # modelling 2 Understanding recipes and preprocessing Having defined a recipe in this Kaggle competition, I was left wondering about some details of the recipe definition. Let’s explore that.
3 Load data traindata_url &amp;lt;- &amp;quot;https://raw.githubusercontent.com/sebastiansauer/Statistiklehre/main/data/titanic/train.csv&amp;quot; train &amp;lt;- read_csv(traindata_url) 4 Define recipe titanic_recipe &amp;lt;- # define model formula: recipe(Survived ~ Pclass, data = train) %&amp;gt;% # convert numeric outcome to nominal (factor): step_num2factor(Survived, levels = c(&amp;quot;dead&amp;quot;, &amp;quot;alive&amp;quot;)) # not working, #todo 5 Prepare (prep()) the recipe { error = TRUE} titanic_recipe_prepped &amp;lt;- titanic_recipe %&amp;gt;% prep(verbose = TRUE)</description>
    </item>
    
    <item>
      <title>Beispiel für eine Vorwärts-schrittweise-Regression</title>
      <link>https://data-se.netlify.app/2020/12/10/beispiel-f%C3%BCr-eine-vorw%C3%A4rts-schrittweise-regression/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/10/beispiel-f%C3%BCr-eine-vorw%C3%A4rts-schrittweise-regression/</guid>
      <description>1 Hintergrund 2 Achtung 3 Pakete 4 Daten laden 5 Fehlende Werte 6 Modell 0 7 Modelle mit einer Variablen (lm1) 7.1 lm1a 7.2 lm1b 7.3 lm1c 7.4 Moment mal… 8 Automatisiertes Vorwärts-Regression 9 Modellgüten der Modelle mit einem Prädiktor 10 Reproduzierbarkeit 1 Hintergrund Diese Übung bezieht sich auf ISRS, Kap. 6.2.
2 Achtung Gelman hasst schrittweise Regression …
3 Pakete library(tidyverse) # data wrangling library(broom) # tidy Regressionsoutput library(skimr) # EDA library(moderndive) # Komfort library(olsrr) # Schrittweise Regression 4 Daten laden Auf dieser Seite sind die Daten zu finden.</description>
    </item>
    
    <item>
      <title>Modellannahmen grafisch überprüfen</title>
      <link>https://data-se.netlify.app/2020/12/10/modellannahmen-grafisch-%C3%BCberpr%C3%BCfen/</link>
      <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/10/modellannahmen-grafisch-%C3%BCberpr%C3%BCfen/</guid>
      <description>1 Hintergrund 2 Pakete 3 Daten laden 4 Fehlende Werte 5 Modell 1 6 Überprüfen der Annahmen 6.1 Linearität 6.2 Varianzgleichheit der Residuen 6.3 Normalverteilung der Residuen 7 Reproducibility 1 Hintergrund Diese Übung bezieht sich auf ISRS, Kap. 6.3.
2 Pakete library(tidyverse) # data wrangling #library(broom) # tidy Regressionsoutput library(skimr) # EDA library(moderndive) # Komfort 3 Daten laden Auf dieser Seite sind die Daten zu finden.
d &amp;lt;- read_csv(&amp;quot;https://www.openintro.org/data/csv/mariokart.csv&amp;quot;) (“d” wie Daten.</description>
    </item>
    
    <item>
      <title>Example for Meng&#39;s 2018 article on big data bias</title>
      <link>https://data-se.netlify.app/2020/12/09/example-for-meng-s-2018-article-on-big-data-bias/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/09/example-for-meng-s-2018-article-on-big-data-bias/</guid>
      <description>1 Load packages 2 Motivation 3 Computing the effective sample size in the 2016’ US federal elections 4 Conclusion 5 Further reading 6 Reproducibility 1 Load packages library(tidyverse) # data wrangling 2 Motivation My colleague, Karsten Lübke, first grade statistician, pointed me out to a paper …
In 2018, the statistican Meng wrote a paper about biases in big data see here. In a nutshell, he argues that non-random samples will be worse when data is larger.</description>
    </item>
    
    <item>
      <title>Plotting a regression surface (3D)</title>
      <link>https://data-se.netlify.app/2020/12/08/plotting-a-regression-surface-3d/</link>
      <pubDate>Tue, 08 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/08/plotting-a-regression-surface-3d/</guid>
      <description>Load packages library(tidyverse) library(plotly) Data Some sample data
data(tips, package= &amp;quot;reshape2&amp;quot;) Regression model lm1 &amp;lt;- lm(tip ~ total_bill + size, data = tips) lm1_coef &amp;lt;- coef(lm1) Sequence x1_seq &amp;lt;- seq(min(tips$total_bill), max(tips$total_bill), length.out = 25) x2_seq &amp;lt;- seq(min(tips$size), max(tips$size), length.out = 6) Compute grid z2 &amp;lt;- t(outer(x1_seq, x2_seq, function(x,y) lm1_coef[1]+lm1_coef[2]*x+lm1_coef[3]*y)) z2 #&amp;gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] #&amp;gt; [1,] 1.146172 1.330595 1.515017 1.699439 1.883862 2.068284 2.252706 2.437128 #&amp;gt; [2,] 1.</description>
    </item>
    
    <item>
      <title>Ex: Visualizing diamonds</title>
      <link>https://data-se.netlify.app/2020/12/07/ex-visualizing-diamonds/</link>
      <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/07/ex-visualizing-diamonds/</guid>
      <description>1 Load packages 2 Load data 3 Objective 4 Plot 1 5 Plot 2 6 Plot 3: Interactive plot 7 Reproducibility 1 Load packages library(tidyverse) # data wrangling library(plotly) # make interactive JS plots library(printr) # print dataframes as tables 2 Load data data_url &amp;lt;- &amp;quot;https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv&amp;quot; diamonds &amp;lt;- read_csv(data_url) glimpse(diamonds) #&amp;gt; Rows: 53,940 #&amp;gt; Columns: 11 #&amp;gt; $ X1 &amp;lt;dbl&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18… #&amp;gt; $ carat &amp;lt;dbl&amp;gt; 0.</description>
    </item>
    
    <item>
      <title>Execution time for largish data</title>
      <link>https://data-se.netlify.app/2020/12/05/execution-time-for-largish-data/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/05/execution-time-for-largish-data/</guid>
      <description>1 Motivation 2 Setup 3 Data set 1 3.1 Import data 3.1.1 Download from website 3.1.2 Import from local disk 3.1.3 using read_csv() 3.1.4 Using fread() 3.2 Data set size 3.3 Typical data wrangling 4 Data Set 2 4.1 Import data 4.1.1 using read_csv() 4.1.2 Using fread() 4.2 Data set size 4.3 Typical data wrangling 4.4 Data viz 5 Reproducibility 1 Motivation In this post, we play around with some largish data set, approx.</description>
    </item>
    
    <item>
      <title>Simple Knime workflow for the Titanic Kaggle competition using a random forest model</title>
      <link>https://data-se.netlify.app/2020/12/05/simple-knime-workflow-for-the-titanic-kaggle-competation-using-a-random-forest-model/</link>
      <pubDate>Sat, 05 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/05/simple-knime-workflow-for-the-titanic-kaggle-competation-using-a-random-forest-model/</guid>
      <description>1 Kaggle Competition: Titanic Disaster 2 Simple Random Forest model 3 Enjoy! 4 Reproducibility 1 Kaggle Competition: Titanic Disaster The Titanic disaster Kaggle Competition is well-known, beginner friendly playground for predictive modelling.
2 Simple Random Forest model Here, I present a simple Random Forest model for predicting Survival:
The respective workflow can be found here.
3 Enjoy! 4 Reproducibility #&amp;gt; ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────── #&amp;gt; setting value #&amp;gt; version R version 4.</description>
    </item>
    
    <item>
      <title>ModernDive, Chapter 05 - Exercises/Aufgaben (in Deutsch)</title>
      <link>https://data-se.netlify.app/2020/12/02/moderndive-chapter-05-exercises-aufgaben-in-deutsch/</link>
      <pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/12/02/moderndive-chapter-05-exercises-aufgaben-in-deutsch/</guid>
      <description>0.1 Überblick 1 Stärkster univariater Prädiktor der Dozentenbeurteilung 1.1 Aufgabe 1.2 Hilfe 1.3 Hinweise 1.4 Lösung 1.5 Für Fortgeschrittene 2 \(R^2\) für univariate Regression von score auf den stärksten Prädiktor 2.1 Aufgabe 2.2 Lösung 3 Visualisieren Sie die univariate Regression 3.1 Aufgabe 3.2 Lösung 3.3 Variante 4 Vergleich zur Korrelation 4.1 Aufgabe 4.2 Lösung 5 Standardisierte Prädiktoren 5.1 Aufgabe 5.2 Lösung 6 Lebenserwartung nach Kontinent berechnen 6.1 Aufgabe 6.2 Lösung 6.</description>
    </item>
    
    <item>
      <title>Comparing Knime and R: ETL_Basics</title>
      <link>https://data-se.netlify.app/2020/11/28/comparing-knime-and-r-etl-basics/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/28/comparing-knime-and-r-etl-basics/</guid>
      <description>Knime workflow R translation Setup Chunk 1: Read, sort, filter Chunk 2: group and aggregate Chunk 3: filter Chunk 4: concatenate Chunk 5: join Chuunk 6: write to csv Knime workflow Consider this Knime workflow:
R translation Setup library(tidyverse) library(lubridate) library(knitr) Chunk 1: Read, sort, filter datafile &amp;lt;- &amp;quot;https://raw.githubusercontent.com/sebastiansauer/sesa-blog/main/static/datasets/sales_2008-2011.csv&amp;quot; d &amp;lt;- read_csv(datafile) ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## product = col_character(), ## country = col_character(), ## date = col_date(format = &amp;quot;&amp;quot;), ## quantity = col_double(), ## amount = col_double(), ## card = col_character(), ## Cust_ID = col_character() ## ) glimpse(d) ## Rows: 47 ## Columns: 7 ## $ product &amp;lt;chr&amp;gt; &amp;quot;prod_4&amp;quot;, &amp;quot;prod_3&amp;quot;, &amp;quot;prod_3&amp;quot;, &amp;quot;prod_3&amp;quot;, &amp;quot;prod_3&amp;quot;, &amp;quot;prod_3&amp;quot;, … ## $ country &amp;lt;chr&amp;gt; &amp;quot;unknown&amp;quot;, &amp;quot;China&amp;quot;, &amp;quot;China&amp;quot;, &amp;quot;China&amp;quot;, &amp;quot;USA&amp;quot;, &amp;quot;Brazil&amp;quot;, &amp;quot;USA&amp;quot;… ## $ date &amp;lt;date&amp;gt; 2008-12-12, 2009-04-10, 2009-04-10, 2009-05-10, 2009-05-20,… ## $ quantity &amp;lt;dbl&amp;gt; 1, 2, 2, 2, 20, 15, 2, 2, 20, 15, 15, 1, 1, 20, 1, 1, 25, 2,… ## $ amount &amp;lt;dbl&amp;gt; 3, 160, 160, 160, 1600, 1200, 70, 70, 1600, 600, 600, 35, 35… ## $ card &amp;lt;chr&amp;gt; NA, &amp;quot;N&amp;quot;, &amp;quot;Y&amp;quot;, NA, NA, NA, &amp;quot;Y&amp;quot;, NA, NA, NA, &amp;quot;N&amp;quot;, &amp;quot;Y&amp;quot;, &amp;quot;Y&amp;quot;, NA… ## $ Cust_ID &amp;lt;chr&amp;gt; &amp;quot;Cust_8&amp;quot;, &amp;quot;Cust_2&amp;quot;, &amp;quot;Cust_5&amp;quot;, &amp;quot;Cust_2&amp;quot;, &amp;quot;Cust_3&amp;quot;, &amp;quot;Cust_7&amp;quot;, … The data is already recognized as date; no need for transformation.</description>
    </item>
    
    <item>
      <title>Comparing Knime and R: Simple Random Forest</title>
      <link>https://data-se.netlify.app/2020/11/28/comparing-knime-and-r-simple-random-forest/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/28/comparing-knime-and-r-simple-random-forest/</guid>
      <description>Knime Workflow Translate it to R! Load Packages Load Data Stratified sampling Random Forest classification model in R Define and run Random Forest classification model Define learner (model) Define recipe Put workflow together Fit the model to the train data OOB results Model results in test data Multiclass accuracy ROC Confusion Matrix Random Forest regression model in R Define and run the model Update model to regression Define recipe Put workflow together OOB results Model results in test data Variabble importance Collect performance metrics Knime Workflow Consider this Knime workflow:</description>
    </item>
    
    <item>
      <title>derivation-of-the-logistic-regression</title>
      <link>https://data-se.netlify.app/2020/11/28/derivation-of-the-logistic-regression/</link>
      <pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/28/derivation-of-the-logistic-regression/</guid>
      <description>The logistic regression is an incredible useful tool, partly because binary outcomes are so frequent in live (“she loves me - she doesn’t love me”). In parts because we can make use of well-known “normal” regression instruments.
But the formula of logistic regression appears opaque to many (beginners or those with not so much math background).
Let’s try to shed some light on the formula by discussing some accessible explanation on how to derive the formula.</description>
    </item>
    
    <item>
      <title>Simple derivation of linear regression coefficients</title>
      <link>https://data-se.netlify.app/2020/11/18/simple-derivation-of-linear-regression-coefficients2/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/18/simple-derivation-of-linear-regression-coefficients2/</guid>
      <description>Load packages library(tidyverse) Motivation The (simple) linear regression is a standard tool in data analysis and statistics. Its properties are well-known but sometimes not known in details to the applied analyst; which is ok. However, if one wishes to understand deeper the internals of the system, the question may arise how to derive the coefficients of the linear regression. Here’s one way.
This approach focuses on simple calculus and derivatives; no matrix algebra, and only the simple case for one predictor.</description>
    </item>
    
    <item>
      <title>The mean minimizes the sum of squares</title>
      <link>https://data-se.netlify.app/2020/11/18/the-mean-minimizes-the-sum-of-squares/</link>
      <pubDate>Wed, 18 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/18/the-mean-minimizes-the-sum-of-squares/</guid>
      <description>Load packages library(tidyverse) Properties of the arithmetic mean The stuff presented here is far from new, that’s all well-known and basic. See here for a source.
The arithmetic mean has a number of properties …
Residuals cancel out … such as that the residuals cancel out, i.e, the sum of the deviations from the mean (the residuals) sum up to zero:
\[\sum (x_i - \bar{x}) = \sum x_i - \sum \bar{x} = n \cdot \bar{x} - n \cdot \bar{x} = 0\]</description>
    </item>
    
    <item>
      <title>Fallstudie zur Regressionsanalyse -- ggplot2movies</title>
      <link>https://data-se.netlify.app/2020/11/13/fallstudie-zur-regressionsanalyse-ggplot2movies/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/13/fallstudie-zur-regressionsanalyse-ggplot2movies/</guid>
      <description>1 Pakete laden 2 Daten laden 3 Forschungsfrage 4 Ihre salvatorische Klausel 5 Überblick über die Kennzahlen 6 Fehlende Werte 7 Verteilung der Output-Variablen 8 Verteilung der Input-Variablen 9 Explorative Analyse 10 Budget logarithmieren 11 Datensatz umbauen (pivotieren): Moderierender Effekt von Genre 12 Korrelation zwischen den Gruppen 13 Einfluss von Genre 14 Datensatz vereinfachen 15 Datensatz aufteilen (Train- und Test) 16 Modell 0 (“Nullmodell”) 17 Modell 1: budget_log10 18 Unendliche Werte entfernen 19 Model 1 Ergebnisse 20 Anzahl der Stimmen (votes) 21 Modell 2: Anzahl der Stimmen, linear 22 Modell 3: Anzahl der Stimmen als Polynomialmodell, quadratisch 23 Modell 4: Anzahl der Stimmen als Polynomialmodell, 3.</description>
    </item>
    
    <item>
      <title>Fallstudie zur Datenvisualisierung -- Datensatz &#34;flights&#34;</title>
      <link>https://data-se.netlify.app/2020/11/12/fallstudie-zur-datenvisualisierung-datensatz-flights/</link>
      <pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/12/fallstudie-zur-datenvisualisierung-datensatz-flights/</guid>
      <description>1 Vorbereitung 2 Aufgaben zur Datenvisualisierung 3 Hinweise 4 Lösungen 4.1 1. Visualisieren Sie die Verteilung der Verspätungen der Flüge. 4.2 2. Visualisieren Sie die Verteilung der Verspätung der Flüge pro Abflugsort. 4.3 3. Visualisieren Sie den Zusammenhang von Verspätung und Tageszeit. Reduzieren Sie dabei Overplotting. 4.4 4. Visualisieren Sie den Zusammenhang von Verspätung und Flugstrecke (distance) – aufgeteilt nach Abflugsort und nach Monat! 4.5 5. Visualisieren Sie den Zusammenhang von Verspätung und Tageszeit – für die drei Airlines mit der höchsten Durchschnittsverspätung.</description>
    </item>
    
    <item>
      <title>On a popular confidence interval myth</title>
      <link>https://data-se.netlify.app/2020/11/04/on-a-popular-confidence-interval-myth/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/04/on-a-popular-confidence-interval-myth/</guid>
      <description>Load packages Setup A story about data Confidence interval around the mean Plot the CI CI using simulation Myth time Draw many samples from the population Myth is wrong What is actually true Does this information help? Now what? UPDATE 2020-11-30 based on discussion with Norman Markgraf, see disqus below.
Load packages library(tidyverse) library(mosaic) Setup data(flights, package = &amp;quot;nycflights13&amp;quot;) A story about data Say we have a decent sample of \(n=100\), and we would like to compute a standard, plain vanilla confidence interval (95% CI).</description>
    </item>
    
    <item>
      <title>Prove of a local optimum of k-means (exercise in Witten et al., 2013)</title>
      <link>https://data-se.netlify.app/2020/11/02/prove-of-a-local-optimum-of-k-means-exercise-in-witten-et-al-2013/</link>
      <pubDate>Mon, 02 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/11/02/prove-of-a-local-optimum-of-k-means-exercise-in-witten-et-al-2013/</guid>
      <description>Load packages library(tidyverse) The K-Means optimization reduces the variance in each iteration. To illuminate on that Witten et al. in An Introduction to Statistical Learning (2013) present the following entity (p. 388, chap. 10):
\[\frac{1}{|C_k|} \sum\limits_{i,i^{\prime} \in C_k} \sum\limits_{j=1}^p (x_{ij} - x_{i^\prime j})^2 = 2 \sum\limits_{i \in C_k} \sum\limits_{j=1}^{p} (x_{ij} - \bar{x}_{kj})^2\]
A proof can be found here; I’ll add some explanations.
Note 1. Note that \(\sum\limits_{i,i^{\prime} \in C_k}(\dots)\) essentially amounts to \(\sum\limits_{i \in C_k}\sum\limits_{i^{\prime} \in C_k}(\dots)\), when the order of summation does not matter.</description>
    </item>
    
    <item>
      <title>A simple solution to ditch the question &#34;what&#39;s the path of my data?&#34; when importing data to R</title>
      <link>https://data-se.netlify.app/2020/10/19/what-s-my-path/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/10/19/what-s-my-path/</guid>
      <description>Load packages library(tidyverse) Motivation Importing data to R can cause headaches for newbies. For some, the concept of relative and absolute paths is new. That’s why I compiled here some recommendations on how to important data into R and on how to ditch the “what’s my path” problem.
Approach 1: Start an RStudio project That’s an approach I generally recommend.
Start an RStudio project. Put your code files and your data files in this very folder that you just defined as your RStudio project folder.</description>
    </item>
    
    <item>
      <title>How to import data without whats-the-path-pain</title>
      <link>https://data-se.netlify.app/2020/10/19/how-to-import-data-without-whats-the-path-pain/</link>
      <pubDate>Mon, 19 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/10/19/how-to-import-data-without-whats-the-path-pain/</guid>
      <description> Load packages library(tidyverse) </description>
    </item>
    
    <item>
      <title>Visualizing decision trees</title>
      <link>https://data-se.netlify.app/2020/10/17/visualizing-decision-trees/</link>
      <pubDate>Sat, 17 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/10/17/visualizing-decision-trees/</guid>
      <description>Load packages library(tidyverse) #remotes::install_github(&amp;quot;grantmcdermott/parttree&amp;quot;) library(parttree) library(rpart) library(rpart.plot) library(parsnip) library(titanic) library(tidyverse) Train learner Build the tree using parsnip with rpart as the model engine:
set.seed(123) titanic_train$Survived = as.factor(titanic_train$Survived) ti_tree = decision_tree() %&amp;gt;% set_engine(&amp;quot;rpart&amp;quot;) %&amp;gt;% set_mode(&amp;quot;classification&amp;quot;) %&amp;gt;% fit(Survived ~ Pclass + Age, data = titanic_train) Plot the model partitions titanic_train %&amp;gt;% ggplot(aes(x=Pclass, y=Age)) + geom_jitter(aes(col=Survived), alpha=0.7) + geom_parttree(data = ti_tree, aes(fill=Survived), alpha = 0.1) + theme_minimal() Plot the tree
rpart.plot(ti_tree[[&amp;quot;fit&amp;quot;]], box.palette=&amp;quot;RdBu&amp;quot;, shadow.</description>
    </item>
    
    <item>
      <title>Help me help you: Wie man ein R-Problem so formuliert, dass einem geholfen werden kann</title>
      <link>https://data-se.netlify.app/2020/09/23/help-me-help-you-wie-man-ein-r-problem-so-formuliert-dass-einem-geholfen-werden-kann/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/09/23/help-me-help-you-wie-man-ein-r-problem-so-formuliert-dass-einem-geholfen-werden-kann/</guid>
      <description>Hier werden Sie geholfen – oder doch nicht? Die Hausarbeit zur Datenanalyse mit R muss morgen Abend abgegeben werden – und nichts läuft! Wer kennt das nicht?! Der knurrige Dozent hat die Abgabefrist wieder viel zu knapp bemessen, warum auch immer. Was ist jetzt zu tun? Nach 3 13 30 60 Minuten eigenen – erfolglosen – Tüftelns will man jetzt den Dozenten um Hilfe fragen.
Man schreibt also: “Lieber Herr Süß, R läuft nicht, was soll ich tun?</description>
    </item>
    
    <item>
      <title>Mean of the upper half of a Gaussian</title>
      <link>https://data-se.netlify.app/2020/07/22/mean-of-the-upper-half-of-a-gaussian/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/07/22/mean-of-the-upper-half-of-a-gaussian/</guid>
      <description>Load packages library(tidyverse) library(lsr) Motivation Recently, I listened to the great Paul Meehl in the audioscripts of some lectures of him. There, he asked the students
what’s the mean value of the upper half of a Gaussian distribution?
Let’s explore that using simulation techniques.
Simulation time Let’s draw some instances from a standard Normal distribution, \(X\).
n &amp;lt;- 1e05 x &amp;lt;- rnorm(n) Mean and SD in our sample are quite close to what can be expected:</description>
    </item>
    
    <item>
      <title>Randomization in presence of an interaction effect</title>
      <link>https://data-se.netlify.app/2020/07/07/randomization-in-presence-of-an-interaction-effect/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/07/07/randomization-in-presence-of-an-interaction-effect/</guid>
      <description>Load packages library(tidyverse) library(rockchalk) library(MASS) library(ggdag) Problem statement Assume that \(X\) and \(Y\) are correlated contingent on some third variable, \(Z\). For simplicity, assume that, if \(z=0\), \(_0=0.7\), and if \(z=1\), then \(r_1=-0.7\). This is not a causal statement.
Simulate data Let the sample size amount to \(n=1000\).
n &amp;lt;- 1e03 Group A, \(z=0\):
myR &amp;lt;- lazyCor(X = 0.7, d = 2) mySD &amp;lt;- c(1, 1) myCov &amp;lt;- lazyCov(Rho = myR, Sd = mySD) set.</description>
    </item>
    
    <item>
      <title>First grade math exercise</title>
      <link>https://data-se.netlify.app/2020/07/03/first-grade-math-exercise/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/07/03/first-grade-math-exercise/</guid>
      <description>Problem statement My son, being a first grader, recently struggled with this piece of math:
Consider this system of equations:
\[ a + b + c = 20\\ d + e + f = 14\\ g + h + i = 11\\ a + d + g = 15\\ b + e + h = 10\\ c + f + i = 20\\ a + e + i = 20\\ g + e + c = 10\]</description>
    </item>
    
    <item>
      <title>How to sort the labels of the legend in a ggplot-diagram</title>
      <link>https://data-se.netlify.app/2020/06/26/how-to-sort-the-labels-of-the-legend-in-a-ggplot-diagram/</link>
      <pubDate>Fri, 26 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/26/how-to-sort-the-labels-of-the-legend-in-a-ggplot-diagram/</guid>
      <description>Load packages library(tidyverse) library(forcats) library(hrbrthemes) What we want to achieve: barplot ggplot2-diagram where bars and legend labels are sorted Say we would like to plot frequencies, and would like to use ggplot2 for that purpose. How can we get a decent graph? This post shows some ways.
Some data data(diamonds) A glimpse to the data glimpse(diamonds) #&amp;gt; Rows: 53,940 #&amp;gt; Columns: 10 #&amp;gt; $ carat &amp;lt;dbl&amp;gt; 0.23, 0.21, 0.23, 0.</description>
    </item>
    
    <item>
      <title>Simulating data for a Gamma regression </title>
      <link>https://data-se.netlify.app/2020/06/17/simulating-data-for-a-gamma-regression/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/17/simulating-data-for-a-gamma-regression/</guid>
      <description>Load packages library(tidyverse) Intro A Gamma distribution is useful for modeling positive, right skewed data such as waiting times; it is a continuous function.
In this post, we’ll illustrate some properties of the Gamma distribution by simulating a toy example.
Simulate data and define structural model Let \(X\) be a discrete variable following uniform distribution, and \(x_i \in \{1,2,3\}\).
set.seed(42) n &amp;lt;- 1000 X &amp;lt;- sample(x = c(1,2,3), size = n, replace = TRUE) hist(X) Let \(y_i = 0.</description>
    </item>
    
    <item>
      <title>Absolute vs. relative Covid cases in modelling</title>
      <link>https://data-se.netlify.app/2020/06/10/absolute-vs-relative-covid-cases-in-modelling/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/10/absolute-vs-relative-covid-cases-in-modelling/</guid>
      <description>Load packages library(tidyverse) library(mosaic) require(scales) library(directlabels) library(ggrepel) library(ggthemes) library(hrbrthemes) options(scipen = 8) Covid-19 growth rate We are in the decline midst wake onset SOMEHWERE in the Corona crisis. A lot of hasty more or less useful research is being conducted.
One of the circulating claims is: “There Corona growth rate in country X is higher than in country Y!”
Let’s assume some doubling (growth) rate:
double_rates &amp;lt;- 5 double_rate_chosen &amp;lt;- 5 # sample(double_rates, size = 1) Two countries with equal Covid-19 growth rate Consider two countries, A und B, with the same Covid-19 growth rate.</description>
    </item>
    
    <item>
      <title>Spell out your model explicitly</title>
      <link>https://data-se.netlify.app/2020/06/10/spell-out-your-model-explicitly/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/10/spell-out-your-model-explicitly/</guid>
      <description>Load packages library(tidyverse) library(hrbrthemes) library(MASS) library(moments) Why you should spell out your model explicitly Often, assumptions of widely used models, such as linear models, appear opaque. Why is heteroscedasticity important? Where is a list of the model assumptions I need to consider?
As it turns out, there are straight forward answers to these (and similar) questions. The solution is to explicitly spell out your model. All “assumptions” can easily read off from these model specifications.</description>
    </item>
    
    <item>
      <title>Distribution of residuals is of interest for linear models, not the distribution of y</title>
      <link>https://data-se.netlify.app/2020/06/09/distribution-of-residuals-is-of-interest-for-linear-models-not-the-distribution-of-y/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/09/distribution-of-residuals-is-of-interest-for-linear-models-not-the-distribution-of-y/</guid>
      <description>Load packages library(tidyverse) library(e1071) My \(y\) is not distributed according to my wishes! Let \(Y\) be a variable that we would like to model, for instance, Covid-19 cases.
Now, there’s a widely hold belief that my \(Y\) must be distributed normally, or, in some cases, following some other assumed distribution (maybe some long-tailed distribution).
However, this belief is not (strictly) true. What a linear model assumes is that the residuals are distributed normally, not the \(Y\) distribution.</description>
    </item>
    
    <item>
      <title>On a confidence interval myth</title>
      <link>https://data-se.netlify.app/2020/06/05/on-a-confidence-interval-myth/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/05/on-a-confidence-interval-myth/</guid>
      <description>Load packages library(tidyverse) library(mosaic) Setup data(flights, package = &amp;quot;nycflights13&amp;quot;) A story about data Say we have a decent sample of \(n=100\), and we would like to compute a standard, plain vanilla confidence interval (95% CI).
For the sake of having a story, assume you are the boss of the NYC airports and you are investigating the 2013 “typical” arrival delays.
OK, here we go.
Get the sample:
set.seed(42) flights_sample &amp;lt;- sample_n(drop_na(flights, arr_delay), size = 30) Compute the descriptives:</description>
    </item>
    
    <item>
      <title>Simulating values according to some distribution</title>
      <link>https://data-se.netlify.app/2020/06/05/simulating-values-according-to-some-distribution/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/05/simulating-values-according-to-some-distribution/</guid>
      <description>Load packages library(tidyverse) library(mosaic) What’s a Monte Carlo simulation? A Monte Carlo Simulation is a numeric approach to solving difficult problems. Instead of having an analytic way of solving the problem, one just says “ok, let’s try it out and see what happens”.
Coin flip distribution Simalatin a single coin flip (Bernoulli) distribution can be achieved like this:
rflip() #&amp;gt; #&amp;gt; Flipping 1 coin [ Prob(Heads) = 0.5 ] .</description>
    </item>
    
    <item>
      <title>Simulation based inference for non-parametric tests, and a trick</title>
      <link>https://data-se.netlify.app/2020/06/05/sbi-nonparametric/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/05/sbi-nonparametric/</guid>
      <description>Load packages library(tidyverse) library(mosaic) Data data(&amp;quot;tips&amp;quot;, package = &amp;quot;reshape2&amp;quot;) Non-parametric tests and simulation based inference Simulation-based inference (SBI) is an old tool that has seen a surge in research interest in recent years probably due to the large amount of computational powers at the hands of researchers.
SBI is less prone to violations of assumptions, particularly with distributional assumptions. This is because inference is not based on the idea that some variable follows a – for example – normal distribution.</description>
    </item>
    
    <item>
      <title>Chi-squared test using simulation based inference</title>
      <link>https://data-se.netlify.app/2020/06/04/chi-squared-test-using-simulation-based-inference/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/04/chi-squared-test-using-simulation-based-inference/</guid>
      <description>Load packages library(tidyverse) Simulation based inference Simulation based inference (SBI) is an elegant way of subsuming a wide array of statistical (inference) methods under one umbrella. In addition, its simple thereby helping learners getting to the grips.
Here’s a summary of the central ideas.
However, this post does not aim at explaining simulation based inference, which is done elsewhere.
Testing the association of two categorical variables One application of statistical tests – simulation based or classical – is testing the association of two categorical variables.</description>
    </item>
    
    <item>
      <title>When adding variable hurts – The collider bias</title>
      <link>https://data-se.netlify.app/2020/06/04/when-adding-variable-hurts-the-collider-bias/</link>
      <pubDate>Thu, 04 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/04/when-adding-variable-hurts-the-collider-bias/</guid>
      <description>Load packages library(tidyverse) library(conflicted) library(ggdag) library(broom) library(GGally) Motivation Assume there is some scientist with some theory. Her theory holds that X and Z are causes of Y. dag1 shows her DAG (ie., her theory depicted as a causal diagram). Our scientist is concerned with the causal effect of X on Y, where X is a treatment variable (exposure) and Y is the dependent variable under scrutiny (outcome).
See e.g,. here or here for intros to DAGs and causality.</description>
    </item>
    
    <item>
      <title>Plot for mean comparison</title>
      <link>https://data-se.netlify.app/2020/06/02/plot-for-mean-comparison/</link>
      <pubDate>Tue, 02 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/06/02/plot-for-mean-comparison/</guid>
      <description>Load packages library(tidyverse) library(reshape2) # for data library(mosaic) library(sjmisc) library(skimr) Data setup data(tips) Aggregate data per group tips_aggr &amp;lt;- tips %&amp;gt;% group_by(smoker) %&amp;gt;% summarise(tip_avg = mean(tip), tip_md = median(tip), tip_sd = sd(tip), tip_iqr = IQR(tip)) tips_aggr #&amp;gt; # A tibble: 2 x 5 #&amp;gt; smoker tip_avg tip_md tip_sd tip_iqr #&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 No 2.99 2.74 1.38 1.50 #&amp;gt; 2 Yes 3.01 3 1.40 1.68 The same lines, more concisely:</description>
    </item>
    
    <item>
      <title>Plotting a correlated bivariate Gaussian</title>
      <link>https://data-se.netlify.app/2020/05/30/plotting-a-correlated-bivariate-gaussian/</link>
      <pubDate>Sat, 30 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/05/30/plotting-a-correlated-bivariate-gaussian/</guid>
      <description>Load packages library(tidyverse) library(rockchalk) library(MASS) Defining the data myR &amp;lt;- lazyCor(X = 0.7, d = 2) mySD &amp;lt;- c(1, 1) myCov &amp;lt;- lazyCov(Rho = myR, Sd = mySD) myR #&amp;gt; [,1] [,2] #&amp;gt; [1,] 1.0 0.7 #&amp;gt; [2,] 0.7 1.0 mySD #&amp;gt; [1] 1 1 myCov #&amp;gt; [,1] [,2] #&amp;gt; [1,] 1.0 0.7 #&amp;gt; [2,] 0.7 1.0 Drawing from the multivariate normal Let’s draw 1000 cases. Met \(\mu\) be zero.</description>
    </item>
    
    <item>
      <title>How to find the package of a R function</title>
      <link>https://data-se.netlify.app/2020/05/15/how-to-find-the-package-of-a-r-function/</link>
      <pubDate>Fri, 15 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/05/15/how-to-find-the-package-of-a-r-function/</guid>
      <description>Load packages library(tidyverse) Where does my function reside? Finding the package of a given R function is some hassle. I am not aware of a quick built-in way in R to find the package of a function.
That’s why I came up with my own function, check it out:
Install package Speaking of packages of function, that’s the package where this function stays:
library(devtools) install_github(&amp;quot;sebastiansauer/prada&amp;quot;) Example library(prada) find_funs(&amp;quot;select&amp;quot;) #&amp;gt; # A tibble: 11 x 3 #&amp;gt; package_name builtin_pckage loaded #&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; #&amp;gt; 1 BDgraph FALSE FALSE #&amp;gt; 2 dplyr FALSE TRUE #&amp;gt; 3 jmvcore FALSE FALSE #&amp;gt; 4 jqr FALSE FALSE #&amp;gt; 5 MASS TRUE FALSE #&amp;gt; 6 plotly FALSE FALSE #&amp;gt; 7 raster FALSE FALSE #&amp;gt; 8 rstatix FALSE FALSE #&amp;gt; 9 tidygraph FALSE FALSE #&amp;gt; 10 tidylog FALSE FALSE #&amp;gt; 11 VGAM FALSE FALSE find_funs(&amp;quot;tidy&amp;quot;) #&amp;gt; # A tibble: 14 x 3 #&amp;gt; package_name builtin_pckage loaded #&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; #&amp;gt; 1 broom FALSE FALSE #&amp;gt; 2 broom.</description>
    </item>
    
    <item>
      <title>Simulating Berkson&#39;s paradox</title>
      <link>https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/04/16/simulation-berkson-s-paradox/</guid>
      <description>This post was inspired by this paper of Karsten Luebke and coauthors.
library(ggdag) library(ggthemes) library(mosaic) We’ll stratify our sample into two groups: students (Studium) and non-students (kein Studium).
Structural causal model First, we define the structure of our causal model.
set.seed(42) # reproducibilty N &amp;lt;- 1e03 IQ = rnorm(N) Fleiss = rnorm(N) Eignung = 1/2 * IQ + 1/2 * Fleiss + rnorm(N, 0, .1) That is, aptitude (Eignung) is a function of intelligence (IQ) and dilligence (Fleiss), where the input variables have the same impact on the outcome variable (aptitude).</description>
    </item>
    
    <item>
      <title>Folien für den Workshop zur simulationsbasierten Inferenz, 2020-02-05</title>
      <link>https://data-se.netlify.app/2020/02/02/folien-f%C3%BCr-den-workshop-zur-simulationsbasierten-inferenz-2020-02-05/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/02/02/folien-f%C3%BCr-den-workshop-zur-simulationsbasierten-inferenz-2020-02-05/</guid>
      <description>Workshop zu simulationsbasierter Inferenz Die Folien für meinen Workshop zur simulationsbasierten Inferenz finden sich hier.
Die PDF-Version findet sich hier.
Der Quellcode liegt hier.
Die Folien sind unter CC-BY 4.0 De lizensiert.</description>
    </item>
    
    <item>
      <title>Cluster analysis and image size reduction</title>
      <link>https://data-se.netlify.app/2020/01/10/cluster-analysis-and-image-size-reduction/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2020/01/10/cluster-analysis-and-image-size-reduction/</guid>
      <description>Idea This post is a remake of this casestudy: https://fallstudien.netlify.com/fallstudie_bildanalyse/bildanalyse
brought to you by Karsten Lübke.
The main purpose is to replace the base R command that Karsten used with a more tidyverse-friendly style. I think that’s easier (for me).
We will compute a cluster analysis to find the typical RGB color per cluster.
WARNING There’s still a bug in the code. That’s why the image at the end appear blurred.</description>
    </item>
    
    <item>
      <title>Correlation cannot be more extreme than &#43;1/-1, proof using Cauchy-Schwarz inequality</title>
      <link>https://data-se.netlify.app/2019/11/19/correlation-cannot-be-more-extreme-than-1-1-proof-using-cauchy-schwartz-inequality/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/11/19/correlation-cannot-be-more-extreme-than-1-1-proof-using-cauchy-schwartz-inequality/</guid>
      <description>Load packages library(tidyverse) The correlation coefficient cannot exceed an absolute value of 1 This is well-known. But why is that the case? How can we proof it? This post gives one explanation using the Cauchy-Schwarz inequality.
Here’s one version of the definition of correlation:
\[ r = \frac{\sum(\Delta x \Delta y)}{\sqrt{\sum \Delta x^2} \sqrt{\sum \Delta y^2}} \]
where \(\Delta x\) and \(\Delta y\) are the differences of \(x_i\) and \(\bar{x}\), that is: \(\Delta x_i = x_i - \bar{x}\), and similarly for \(\Delta y_i\).</description>
    </item>
    
    <item>
      <title>Plotting functions in 3d</title>
      <link>https://data-se.netlify.app/2019/11/19/plotting-functions-in-3d/</link>
      <pubDate>Tue, 19 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/11/19/plotting-functions-in-3d/</guid>
      <description>Load packages library(tidyverse) library(mosaic) library(plotly) Gimme a function Say, you have some function such as
\[ f(x) = x^2+z^2 \]
In more R-ish:
f &amp;lt;- makeFun(x^2 + z^2 ~ x &amp;amp; z) And you would like to plot it.
Observe that this function has two input (independent) variables, \(x\) and \(z\), plus one output (dependent) variables, \(y\).
The thing is, you’ll need to define the values for a number of output values for \(y\), as defined by the function.</description>
    </item>
    
    <item>
      <title>Some notes on data transformations for regression</title>
      <link>https://data-se.netlify.app/2019/11/11/some-notes-on-data-transformations-for-regression/</link>
      <pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/11/11/some-notes-on-data-transformations-for-regression/</guid>
      <description>Load packages library(tidyverse) library(mosaic) Motivation What are data transformation good for? Why do we bother to transform variables for regression analysis? This post explores some nuances around these themes.
Simulate an exponentially distributed assocation len &amp;lt;- 42 # 42 x values x &amp;lt;- rep(runif(len), 30) # each x value repeated 30 times y &amp;lt;- dexp(x) + rnorm(length(x), mean = 0, sd = .01) # add some noise Plot it:</description>
    </item>
    
    <item>
      <title>Some ways for plotting 3D linear models</title>
      <link>https://data-se.netlify.app/2019/10/21/some-ways-for-plotting-3d-linear-models/</link>
      <pubDate>Mon, 21 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/10/21/some-ways-for-plotting-3d-linear-models/</guid>
      <description>Load packages library(tidyverse) # data wrangling library(mosaic) # funplot library(plotly) # interactive plots library(scatterplot3d) # nomen est omen library(rsm) # 3d scatterplots Motivation Linear models are a standard way of predicting or explaining some data. Visualizing data is not only of didactical value but provides heuristical value too, as demonstrated by Anscombe’s Quartet.
Visualizing linear models in 2D is straightforward, but visualizing linear models with more than one predictor is much less so.</description>
    </item>
    
    <item>
      <title>Looping over function arguments using purrr</title>
      <link>https://data-se.netlify.app/2019/09/28/looping-over-function-arguments-using-purrr/</link>
      <pubDate>Sat, 28 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/09/28/looping-over-function-arguments-using-purrr/</guid>
      <description>Load packages library(tidyverse) Problem statement Assume you have to call a function multiple times, but each with (possibly) different argument. Given enough repitioons, you will not want to repeat yourself.
In other words, we would like to loop over function arguments, each round in the loop giving the respective argument’value(s) to the function.
One example would be to generate many random values but each with different mean and/or sd:</description>
    </item>
    
    <item>
      <title>Computing rater accuracy across multiple raters and multiple criteria</title>
      <link>https://data-se.netlify.app/2019/08/27/computing-rater-accuracy-across-multiple-raters-and-multiple-criteria/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/08/27/computing-rater-accuracy-across-multiple-raters-and-multiple-criteria/</guid>
      <description>Load packages library(tidyverse) Background Computing inter-rater reliability is a well-known, albeit maybe not very frequent task in data analysis. If there’s only one criteria and two raters, the proceeding is straigt forward; Cohen’s Kappa is the most widely used coefficient for that purpose. It is more challenging to compare multiple raters on one criterion; Fleiss’ Kappa is one way to get a coefficient. If there are multiple criteria, one way is to compute the mean of multiple Fleiss’ coefficients.</description>
    </item>
    
    <item>
      <title>Performance measures for `caret` and `lm()`</title>
      <link>https://data-se.netlify.app/2019/08/02/performance-measures-for-caret-and-lm-r/</link>
      <pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/08/02/performance-measures-for-caret-and-lm-r/</guid>
      <description>Recently, I run into performance issue when fitting a linear model together with a resampling scheme and a tuning grid (via caret). The dataset was recently large - some 200k rows and approx. 20 columns (nycflights13 train). Still, I was suprised that my machine got stuck during the computation. Now I wonder whether I ran into memory constraints (16BG on my machine), or whether some other stuff went wrong.</description>
    </item>
    
    <item>
      <title>Geoplotting - update to my MODAR-book</title>
      <link>https://data-se.netlify.app/2019/07/29/geoplotting-update-to-my-modar-book/</link>
      <pubDate>Mon, 29 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/29/geoplotting-update-to-my-modar-book/</guid>
      <description>In my book on modern data analyisis using R, I show some basics of geoplotting. It seems that some software update for the package simple features broke my code. So, here ’s some update.
Load packages and data library(tidyverse) library(viridis) library(sf) data(socec, package = &amp;quot;pradadata&amp;quot;) data(wahlkreise_shp, package = &amp;quot;pradadata&amp;quot;) Check data glimpse(socec) #&amp;gt; Observations: 316 #&amp;gt; Variables: 51 #&amp;gt; $ V01 &amp;lt;chr&amp;gt; &amp;quot;Schleswig-Holstein&amp;quot;, &amp;quot;Schleswig-Holstein&amp;quot;, &amp;quot;Schleswig-Holst… #&amp;gt; $ V02 &amp;lt;int&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 901, 12, 13, 14, 15, 16, … #&amp;gt; $ V03 &amp;lt;chr&amp;gt; &amp;quot;Flensburg – Schleswig&amp;quot;, &amp;quot;Nordfriesland – Dithmarschen Nord&amp;quot;… #&amp;gt; $ V04 &amp;lt;int&amp;gt; 130, 197, 178, 163, 3, 92, 49, 95, 49, 126, 28, 1110, 132, 1… #&amp;gt; $ V05 &amp;lt;dbl&amp;gt; 2128.</description>
    </item>
    
    <item>
      <title>Slides (in German) for my talk on &#34;Datenkompetenz für alle&#34; at the R-User-Group Nürnberg July 2019</title>
      <link>https://data-se.netlify.app/2019/07/17/slides-in-german-for-my-talk-on-datenkompetenz-f%C3%BCr-alle-at-the-r-user-group-n%C3%BCrnberg-july-2019/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/17/slides-in-german-for-my-talk-on-datenkompetenz-f%C3%BCr-alle-at-the-r-user-group-n%C3%BCrnberg-july-2019/</guid>
      <description>The slides (pdf) of my talk “Datenkompetenz für alle – Ein Werkstattbericht zum FOM-Statistik-Curriculum” can be found here.</description>
    </item>
    
    <item>
      <title>Collapse rows to eliminate NAs</title>
      <link>https://data-se.netlify.app/2019/07/03/collapse-rows-to-eliminate-nas/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/03/collapse-rows-to-eliminate-nas/</guid>
      <description>Load packages library(tidyverse) Starters Assume you have this data frame:
x &amp;lt;- tribble( ~ colA, ~colB, ~colC, NA, 1, NA, 1, NA, 1 ) x #&amp;gt; # A tibble: 2 x 3 #&amp;gt; colA colB colC #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 NA 1 NA #&amp;gt; 2 1 NA 1 But you want this one:
y &amp;lt;- tribble( ~ colA, ~colB, ~colC, 1, 1, 1 ) y #&amp;gt; # A tibble: 1 x 3 #&amp;gt; colA colB colC #&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; #&amp;gt; 1 1 1 1 That is, you’d like to collapse rows so that if there’s a NA in a column it is replaced by the value found in some other line.</description>
    </item>
    
    <item>
      <title>Generalized rowwise operations using purrr::pmap</title>
      <link>https://data-se.netlify.app/2019/07/03/generalized-rowwise-operations-using-purrr-pmap/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/03/generalized-rowwise-operations-using-purrr-pmap/</guid>
      <description>Load packages library(tidyverse) Rowwwise operations are a quite frequent operations in data analysis. The R language environment is particularly strong in column wise operations. This is due to technical reasons, as data frames are internally built as column-by-column structures, hence column wise operations are simple, rowwise more difficult.
This post looks at some rather general way to comput rowwise statistics. Of course, numerous ways exist and there are quite a few tutorials around, notably by Jenny Bryant, and by Emil Hvitfeldt to name a few.</description>
    </item>
    
    <item>
      <title>Testing for equality rowwise</title>
      <link>https://data-se.netlify.app/2019/07/03/testing-for-equality-rowwise/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/03/testing-for-equality-rowwise/</guid>
      <description>Load packages library(tidyverse) Basic testing for equality Testing for equality in a kind of very basic function in computer (and data) science. There is a straightforward function in R to test for equality:
identical(1, 1) #&amp;gt; [1] TRUE identical(&amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;) #&amp;gt; [1] TRUE identical(1, 2) #&amp;gt; [1] FALSE identical(1, NA) #&amp;gt; [1] FALSE However this get more complicated if we want to compare more than two elements. One way to achieve this is to compute the number of the different items.</description>
    </item>
    
    <item>
      <title>Testing multiple vectors for equality</title>
      <link>https://data-se.netlify.app/2019/07/03/testing-multiple-vectors-for-equality/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/07/03/testing-multiple-vectors-for-equality/</guid>
      <description>Load packages library(tidyverse) Problem statement Assume we have some vectors (eg, 3), and we want to check if they are equal (the same elements in each vector). Assume further we do not in advance the number of vectors to check.
Here’s some toy data.
a&amp;lt;- c(1,2,3,4) b&amp;lt;- c(1,2,3,5) c&amp;lt;- c(1,3,4,5) The gist This soluation is based on the code of Akrun from this SO post (slightly adapted).
sum(reduce(map2(list(a,b,c), list(a), `==`), `&amp;amp;`)) #&amp;gt; [1] 1 Explanation Let’s break that in handy pieces to get a grip on it.</description>
    </item>
    
    <item>
      <title>How to convert raw scores to different types of standardized scores</title>
      <link>https://data-se.netlify.app/2019/04/11/how-to-convert-raw-scores-to-different-types-of-standardized-scores/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/04/11/how-to-convert-raw-scores-to-different-types-of-standardized-scores/</guid>
      <description>A common undertaking in applied research settings such as in some areas of psychology is to convert a raw score into some type of standardized score such as z-scores.
This post shows a way how to accomplish that.
Load packages library(tidyverse) Load some psychometric data data(&amp;quot;extra&amp;quot;, package = &amp;quot;pradadata&amp;quot;) The data can be downloaded here.
The dataset shows some data on extraversion (the personality trait) items along with some correlates of extraversion.</description>
    </item>
    
    <item>
      <title>Reducing residual variance in modeling</title>
      <link>https://data-se.netlify.app/2019/03/26/reducing-residual-variance-in-modeling/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/03/26/reducing-residual-variance-in-modeling/</guid>
      <description>Modeling is a central part not only of statistical inquiry, but also of everyday human sense-making. We use models as metaphors for the world, in a broader sense. Of course, a model that explains the world better (than some other model) is to be preferred, all other things being equal. In this post, we demonstrate that a more “clever” statistical model reduces the residual variance. It should be noted that this “noise reduction” comes at a cost, however: The model gets more complex; there a more parameters in the model.</description>
    </item>
    
    <item>
      <title>Beispiel für eine logistische Regression</title>
      <link>https://data-se.netlify.app/2019/03/20/beispiel-f%C3%BCr-eine-logistische-regression/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/03/20/beispiel-f%C3%BCr-eine-logistische-regression/</guid>
      <description>Wozu ist das gut? Kurz gesagt ist die logistische Regression ein Werkzeug, um dichotome (zweiwertige) Ereignisse vorherzusagen (auf Basis eines Datensatzes mit einigen Prädiktoren).
Was sagt uns die logistische Regression? Möchte man z.B. vorhersagen, ob eine E-Mail Spam ist oder nicht, so ist es nützlich, für jede zu prüfende Mail eine Wahrscheinlichkeit zu bekommen. So könnte uns die logistische Regression sagen: “Eine Mail mit diesen Ausprägungen in den Prädiktoren hat eine Wahrschenlichkeit von X Prozent, dass es sich um Spam handelt”.</description>
    </item>
    
    <item>
      <title>How to mutate all columns of a data frame</title>
      <link>https://data-se.netlify.app/2019/03/13/how-to-mutate-all-columns-of-a-data-frame/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/03/13/how-to-mutate-all-columns-of-a-data-frame/</guid>
      <description>Say, you have a data frame with a number of columns, and you need to change every column in a similar way. A common example might be to standardize all (numeric) variables. How to do that in R? This post shows and explains an example using mutate_all() from the tidyverse.
Let’s stick to the question “how to z-standardize all columns” for the sake of simplicity (and neglect that there are precooked solutions, for example from the superb package sjmisc by strengejacke.</description>
    </item>
    
    <item>
      <title>Ornaments with ggformula</title>
      <link>https://data-se.netlify.app/2019/02/12/ornaments-with-gformula/</link>
      <pubDate>Tue, 12 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/02/12/ornaments-with-gformula/</guid>
      <description>Since some time, there’s a wrapper for ggplot2 available, bundled in the package ggformula. One nice thing is that in that it plays nicely with the popular R package mosaic. mosaic provides some useful functions for modeling along with a tamed and consistent syntax. In this post, we will discuss some “ornaments”, that is, some details of beautification of a plot. I confess that every one will deem it central, but in some cases in comes in handy to know how to “refine” a plot using ggformula.</description>
    </item>
    
    <item>
      <title>Reading text files and Umlaute hassle</title>
      <link>https://data-se.netlify.app/2019/01/25/reading-text-files-and-umlaute-hassle/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/01/25/reading-text-files-and-umlaute-hassle/</guid>
      <description>Data is often stored as plain text file. That’s good because it is a simple format. However, simplicity comes with a cost: Not all questions may have definite answers. The most common hassle when reading/importing text files is that the encoding scheme is unknown, aka wrong. This problem mostly occurs when, say, a Mac user stores a text file, where per default UTF8 text encoding is applied. In contrast, on a Windows machine, Windows-encoding (often dubbed “latin1”,“Windows 1252” or “ISO-8859-1”) is the default.</description>
    </item>
    
    <item>
      <title>An illustration of tidyverse’ gather/spread</title>
      <link>https://data-se.netlify.app/2019/01/15/an-illustration-of-tidyverse-gather-spread/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/01/15/an-illustration-of-tidyverse-gather-spread/</guid>
      <description>Frequently, datasets have to be reshaped before further analysis. One particular important step is to transform a data frame from “wide” to “long” format. This is illustrated by the following diagram, taken from by new book on data analysis (Image licence: CC-BY-NC).</description>
    </item>
    
    <item>
      <title>A clean sessionInfo page</title>
      <link>https://data-se.netlify.app/2019/01/14/a-clean-sessioninfo-page/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/01/14/a-clean-sessioninfo-page/</guid>
      <description>Writing a technical or academic report, or even a presentation, it is sensible to render the (R) code in such a writing reproducible. Same thing applies when asking for help at StackOverflow: you’ll be asked for a reprex.
One aspect for rendering a report reproducible is to include details on the version of packages needed. The well-known command sessionInf() provides the building blocks for that. However, the output of that function can feel verbose, and it consumes a lot of space.</description>
    </item>
    
    <item>
      <title>A short tutorial for the logistic regression</title>
      <link>https://data-se.netlify.app/2019/01/07/a-short-tutorial-for-the-logistic-regression/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/01/07/a-short-tutorial-for-the-logistic-regression/</guid>
      <description>Here’s q quick walk-through for a logistic regression in R.
Setup library(tidyverse) library(reshape2) # dataset &amp;quot;tips&amp;quot; library(caret) library(mosaic) We’ll use the tips dataset:
data(tips) Research question Assume we would like to predict if a person is female based on some predictor such as the amount of tip she/he give.
How many instances of each type of the outcome variable are in the data set?
tally(~ sex, data = tips, format = &amp;quot;proportion&amp;quot;) #&amp;gt; sex #&amp;gt; Female Male #&amp;gt; 0.</description>
    </item>
    
    <item>
      <title>Why standard regression is not (so) adequate for regressing proportions</title>
      <link>https://data-se.netlify.app/2019/01/03/why-standard-regression-is-not-so-adequate-for-regressing-proportions/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2019/01/03/why-standard-regression-is-not-so-adequate-for-regressing-proportions/</guid>
      <description>Intro Professor Sweet is conducting some research to investigate the risk factor and drivers of student exam success. In a recent analysis he considers the variable “exam successfully passed” (vs. not passed) as the criterion (output) and the amount of time spent for preparation (aka study time) as predictor.
Setup Please make sure that all packages are installed before proceeding. Except pradadata, all packages are on CRAN. [ Here’s] (https://github.</description>
    </item>
    
    <item>
      <title>Force bibtex to show the exact date</title>
      <link>https://data-se.netlify.app/2018/12/29/force-bibtex-to-show-the-exact-date/</link>
      <pubDate>Sat, 29 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/29/force-bibtex-to-show-the-exact-date/</guid>
      <description>Citing (aka scientific citation) is quite straight forward in RMarkdown. However, there are some shortcomings. Primarily, as citations are rendered via Pandoc’s reference engine, bibtex is used as a standard. Though is quite commonly used, bibtex has been, over and above, replaced by biblatex. biblatex is much more straight forward than bibtex (as text is formatted using latex and not bibtex, still making use of bibtex for the collection of references).</description>
    </item>
    
    <item>
      <title>Using BibLaTeX instead of Bibtex in Rmarkdown for finer control</title>
      <link>https://data-se.netlify.app/2018/12/28/using-biblatex-instead-of-bibtex-in-rmarkdown-for-finer-control/</link>
      <pubDate>Fri, 28 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/28/using-biblatex-instead-of-bibtex-in-rmarkdown-for-finer-control/</guid>
      <description>As a standard, bibtex is used as a citation-renderer in Pandoc’s Markdown, that is, in RMarkdown as well. bibtex is useful for a fair amount of citation task, but biblatex allows for a finer control. For instance, multiple bibliographies for one document are possible.
For instance, citing a newspaper article using bibtex left me scratching my head, as I wanted to have the exact day of the date (not only the year) cited.</description>
    </item>
    
    <item>
      <title>Generating mass reports using Rmarkdown in R</title>
      <link>https://data-se.netlify.app/2018/12/19/generating-mass-reports/</link>
      <pubDate>Wed, 19 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/19/generating-mass-reports/</guid>
      <description>Sometimes, one document must be recreated in similar fashions a lot of times. For instance, invoices to customers, grading schemes for students, progress reports in projects, and so on. In this post, I demonstrate one way to do that in R using RMarkdown.
Specifically, it is assumed that there’s a tabular data set, where each row refers to a document instance (eg., a mail or report to one given person), and each column holds the variables to appear in each reports (see examples below).</description>
    </item>
    
    <item>
      <title>Visualizing a multivariate normal distribution</title>
      <link>https://data-se.netlify.app/2018/12/13/visualizing-a-multivariate-normal-distribution/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/13/visualizing-a-multivariate-normal-distribution/</guid>
      <description>In R, it is quite straight forward to plot a normal distribution, eg., using the package ggplot2 or plotly.
Setup library(tidyverse) library(mvtnorm) library(plotly) library(MASS) Simulate multivariate normal data First, let’s define a covariance matrix \(\Sigma\):
sigma &amp;lt;- matrix(c(4,2,2,3), ncol = 2) sigma ## [,1] [,2] ## [1,] 4 2 ## [2,] 2 3 Then, simulate observations n = n from these covariance matrix; the means need be defined, too. As the rank of our covariance matrix is 2, we need two means:</description>
    </item>
    
    <item>
      <title>Visualizing a regression plane (two predictors)</title>
      <link>https://data-se.netlify.app/2018/12/13/visualizing-a-regression-plane-two-predictors/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/13/visualizing-a-regression-plane-two-predictors/</guid>
      <description>Plotting a “simple” regression (one regression) is pretty straight forward in R.
Setup library(tidyverse) data(mtcars) library(mosaic) library(modelr) library(plotly) Define model lm1 &amp;lt;- lm(mpg ~ hp, data = mtcars) mtcars &amp;lt;- mtcars %&amp;gt;% mutate(lm1_pred = predict(lm1)) Plot One way:
ggplot(mtcars) + aes(y = mpg, x = hp) + geom_point() + geom_lm() Another way:
ggplot(mtcars) + aes(x = hp) + geom_point(aes(y = mpg)) + geom_point(aes(y = lm1_pred), color = &amp;quot;blue&amp;quot;) + geom_line(aes(y = lm1_pred), color = &amp;quot;blue&amp;quot;) Using the ggformula interface to ggplot2:</description>
    </item>
    
    <item>
      <title>New split-apply-combine variant in dplyr: group_split()</title>
      <link>https://data-se.netlify.app/2018/12/10/new-split-apply-combine-variant-in-dplyr-group-split/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/10/new-split-apply-combine-variant-in-dplyr-group-split/</guid>
      <description>UPDATE 2018-12-11 - I’m talking about the package DPLYR, not PURRR, as I had mistakenly written.
There are many approaches for what is called the “split-apply-combine” approach (see this paper by Hadley Wickham).
I recently thought about the best approach to use split-apply-combine approaches in R (see tweet, and this post).
And I retweeted some criticism on the “present era” tidyverse approach (see this tweet), and check out the mentioned post by @coolbutuseless.</description>
    </item>
    
    <item>
      <title>Applying a function to each row of a data frame</title>
      <link>https://data-se.netlify.app/2018/12/07/applying-a-function-to-each-row-of-a-data-frame/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/07/applying-a-function-to-each-row-of-a-data-frame/</guid>
      <description>A typical and quite straight forward operation in R and the tidyverse is to apply a function on each column of a data frame (or on each element of a list, which is the same for that regard).
However, the orthogonal question of “how to apply a function on each row” is much less labored. We will look at this question in this post, and explore some (of many) answers to this question.</description>
    </item>
    
    <item>
      <title>Coercing an index over a character vector</title>
      <link>https://data-se.netlify.app/2018/12/06/coercing-an-index-over-a-character-vector/</link>
      <pubDate>Thu, 06 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/06/coercing-an-index-over-a-character-vector/</guid>
      <description>Assume we have a vector (of type character) such as countries, names, or products. Each element is allowed to show up multiple times. Further assume that there is a rather large number of unique (different) elements. What we would like to achieve is to give each element a unique ID, where the ID ranges from 1 to k (k is the number of different elements).
Of course there are different ways to achieve this goal, we’ll explore one or two.</description>
    </item>
    
    <item>
      <title>What are the names of the cars with 4 cylinders?</title>
      <link>https://data-se.netlify.app/2018/12/03/what-are-the-names-of-the-cars-with-4-cylinders/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/12/03/what-are-the-names-of-the-cars-with-4-cylinders/</guid>
      <description>Recently, some one asked me in a workshop this question: “What are the names of the cars with 4 (6,8) cylinders?” (he referred to the mtcars data set). That was a workshop on the tidyverse, so the question is how to answer this question using tidyverse techniques.
First, let’s load the usual culprits.
library(tidyverse) library(purrrlyr) library(knitr) library(stringr) data(mtcars) d &amp;lt;- as_tibble(mtcars) %&amp;gt;% rownames_to_column(var = &amp;quot;car_names&amp;quot;) d %&amp;gt;% head() %&amp;gt;% kable() car_names mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.</description>
    </item>
    
    <item>
      <title>Image paths in Hugo/blogdown</title>
      <link>https://data-se.netlify.app/2018/11/28/image-paths-in-hugo-blogdown/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/11/28/image-paths-in-hugo-blogdown/</guid>
      <description>Images from R are instantly included into (R) markdown files, and the same applies for blogdown posts.
See:
x &amp;lt;- 1:10 plot(x) However, for external images - such as photos - things are more complicated. First, all is still fine, if an image is found on some URL/server on the internet:
knitr::include_graphics(&amp;quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/310px-R_logo.svg.png&amp;quot;) Of course, one can apply direct markdown syntax for including external images:
![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/R_logo.svg/310px-R_logo.svg.png){width=20%} Now assume we are in an R project that gives the base for a blogdown blog.</description>
    </item>
    
    <item>
      <title>Compute all pairwise differences in matrix</title>
      <link>https://data-se.netlify.app/2018/11/21/compute-all-pairwise-differences-in-matrix/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/11/21/compute-all-pairwise-differences-in-matrix/</guid>
      <description>A quite frequent task in many fields of applied math is to compute pairwise differences of elements in a matrix. Actually, it need not be a difference; a product is frequent, too. In this post, we explore some (base) R ways to achieve this.
library(mosaic) library(gdata) library(tidyverse) Using outer() An elegant approach, using base R, is applying outer(). That’s useful if one has two vectors, and wants to compute the outer product:</description>
    </item>
    
    <item>
      <title>Slides for the „hands-on data exploration workshop&#34;</title>
      <link>https://data-se.netlify.app/2018/11/12/slides-for-the-hands-on-data-exploration-workshop/</link>
      <pubDate>Mon, 12 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/11/12/slides-for-the-hands-on-data-exploration-workshop/</guid>
      <description>Find the slides for my workshop “hands-on data exploration using R” here: http://data-se.netlify.com/slides/hands-on-data-exploration/handson-data-workshop_2018-11-21.html.
Note that the slides need access to the internet, in order to be rendered correctly.
: Get PDF of slides here
: Get Rmd source code of slides here
The workshop is delivered at the Data Natives Conference 2018 Berlin.</description>
    </item>
    
    <item>
      <title>Simple Examples with DiagrammeR</title>
      <link>https://data-se.netlify.app/2018/11/07/simple-examples-with-diagrammer/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/11/07/simple-examples-with-diagrammer/</guid>
      <description>UPDATE 2018-12-13: Based on a comment from @nmarkgraf, I added a section on how to export diagrammeR diagrams.
Here are some examples of diagrams build with DiagrammeR:
Setup library(tidyverse) library(DiagrammeR) library(DiagrammeRsvg) library(magick) DiagrammeR using grViz() Define the graph:
g1 &amp;lt;- &amp;quot;digraph boxes_and_circles { graph [layout = circo, overlap = true] node [shape = circle, fixedsize = true, fontname = Helvetica, width = 1] Problem; Plan; Data; Analysis; Conclusion edge [color = grey] Problem -&amp;gt; Plan Plan -&amp;gt; Data Data -&amp;gt; Analysis Analysis -&amp;gt; Conclusion Conclusion -&amp;gt; Problem }&amp;quot; Print it to the screen:</description>
    </item>
    
    <item>
      <title>Plot columns repeatedly</title>
      <link>https://data-se.netlify.app/2018/11/02/plot-columns-repeatedly/</link>
      <pubDate>Fri, 02 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/11/02/plot-columns-repeatedly/</guid>
      <description>Suppose you have a large number of columns of a dataframe, and you want to plot each column – say a histogram for each column.
This post shows some ways of achieving this.
Let’s take the mtcars dataset as an example.
data(mtcars) We will use the tidyverse approach:
library(tidyverse) Way 1 mtcars %&amp;gt;% select_if(is_numeric) %&amp;gt;% map2(., names(.), ~ {ggplot(data = data_frame(.x), aes(x = .x)) + geom_histogram() + labs(x= .y)}) #&amp;gt; $mpg #&amp;gt; #&amp;gt; $cyl #&amp;gt; #&amp;gt; $disp #&amp;gt; #&amp;gt; $hp #&amp;gt; #&amp;gt; $drat #&amp;gt; #&amp;gt; $wt #&amp;gt; #&amp;gt; $qsec #&amp;gt; #&amp;gt; $vs #&amp;gt; #&amp;gt; $am #&amp;gt; #&amp;gt; $gear #&amp;gt; #&amp;gt; $carb Some explanations:</description>
    </item>
    
    <item>
      <title>OECD Wellbeing - Explorative Analyse</title>
      <link>https://data-se.netlify.app/2018/10/16/oecd-wellbeing-explorative-analyse/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/10/16/oecd-wellbeing-explorative-analyse/</guid>
      <description>In diesem Post untersuchen wir einige Aspekte der explorativen Datenanalyse für den Datensatz oecd wellbeing aus dem Jahr 2016.
Hinweis: Als Vertiefung gekennzeichnete Abschnitt sind nicht prüfungsrelevant.
Benötigte Pakete Ein Standard-Paket zur grundlegenden Datenanalyse:
library(mosaic) Datensatz laden Der Datensatz kann hier bezogen werden.
Doi: https://doi.org/10.1787/data-00707-en.
Falls der Datensatz lokal (auf Ihrem Rechner) vorliegt, können Sie ihn in gewohnter Manier laden. Geben Sie dazu den Pfad zum Datensatz ein:
oecd &amp;lt;- read.</description>
    </item>
    
    <item>
      <title>OECD Wellbeing dataset (2016)</title>
      <link>https://data-se.netlify.app/2018/10/16/oecd-wellbeing-dataset-2016/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/10/16/oecd-wellbeing-dataset-2016/</guid>
      <description>Packages We will need the following packages in this post:
library(mosaic) library(knitr) library(DT) The OECD wellbeing study series The OECD keeps measuring the wellbeing (and associated variables) among its members states.
On the project website, the OECD states:
In recent years, concerns have emerged regarding the fact that macro-economic statistics, such as GDP, don’t provide a sufficiently detailed picture of the living conditions that ordinary people experience. While these concerns were already evident during the years of strong growth and good economic performance that characterised the early part of the decade, the financial and economic crisis has further amplified them.</description>
    </item>
    
    <item>
      <title>Change standard theme of ggplot</title>
      <link>https://data-se.netlify.app/2018/10/10/change-standard-theme-of-ggplot/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/10/10/change-standard-theme-of-ggplot/</guid>
      <description>ggplot2 is customizeable. Frankly, one can change a heap of details - not everything probably, but a lot. Of course, one can add a theme to the ggplot call, in order to change the theme. However, a more catch-it-all approach would be to change the standard theme of ggplot itself. In this post, we’ll investigate this option.
Load some data and the right packages:
data(mtcars) library(tidyverse) Here’s the standard theme of ggplot, let’s have a look at it</description>
    </item>
    
    <item>
      <title>DataExploR: Typische Businessfragen mit R analysieren</title>
      <link>https://data-se.netlify.app/2018/09/12/dataexplor-typische-businessfragen-mit-r-analysieren/</link>
      <pubDate>Wed, 12 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/09/12/dataexplor-typische-businessfragen-mit-r-analysieren/</guid>
      <description>In diesem Post untersuchen wir eine recht häufige Fragestellung im Bereich der Datenanalyse – die Auswertung von Umfragedaten. Umfragen sind eine gängige Angelegenheit in vielen Organisationen: man möchte wissen, ob die Kunden zufrieden sind oder was die Mitarbeiter vom Management denken. Wir werden nicht alle Aspekte der Analyse betrachten – da gibt es viel zu tun –, sondern ein paar zentrale Aspekte herausgreifen.
Laden wir zuerst ein paar nützliche Pakete:</description>
    </item>
    
    <item>
      <title>Wenn Excel aufgibt: Datenvisualisierung kann zu komplex für Excel werden</title>
      <link>https://data-se.netlify.app/2018/09/11/wenn-excel-aufgibt-datenvisualisierung-kann-zu-komplex-f%C3%BCr-excel-werden/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/09/11/wenn-excel-aufgibt-datenvisualisierung-kann-zu-komplex-f%C3%BCr-excel-werden/</guid>
      <description>Ms Excel ist ein beliebtes Werkzeug der Datenanalyse, auch für Datenvisualisierung. Es gibt einige Beispiele, dass andere Werkzeuge, wie R, zu ansehnlicheren Diagrammen führen können, s. diesen Post. In diesem Post geht es um eine verwandte Frage: Gibt es Diagramme, die nicht – oder nur sehr aufwendig – mit Excel zu erstellen sind?
Die Meine Antwort lautet: Ja, die gibt es. Betrachten wir ein Beispiel.
Bayesianische Modelle visualisieren Als Hintergrund dient uns eine Analyse (s.</description>
    </item>
    
    <item>
      <title>Reproducible academic writing with RMarkdown - Talk at DGPs 2018</title>
      <link>https://data-se.netlify.app/2018/09/03/reproducible-academic-writing-with-rmarkdown-talk-at-dgps-2018/</link>
      <pubDate>Mon, 03 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/09/03/reproducible-academic-writing-with-rmarkdown-talk-at-dgps-2018/</guid>
      <description>Talk at DGPs 2018.
Get slides here: http://data-se.netlify.com/slides/rmd-writing/rmd-writing_dgps2018.html.</description>
    </item>
    
    <item>
      <title>Bayesian modeling of populist party success in German federal elections - A notebook from the lab</title>
      <link>https://data-se.netlify.app/2018/08/25/bayesian-modeling-of-populist-party-success-in-german-federal-elections/</link>
      <pubDate>Sat, 25 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/08/25/bayesian-modeling-of-populist-party-success-in-german-federal-elections/</guid>
      <description>Following up on an earlier post, we will model the voting success of the (most prominent) populist party, AfD, in the recent federal elections. This time, Bayesian modeling techniques will be used, drawing on the excellent textbook my McElreath.
Note that this post is rather a notebook of my thinking, doing, and erring. I’ve made no efforts to hide scaffolding. I think it will be confusing to the uniniate and the initiate as well …</description>
    </item>
    
    <item>
      <title>Binning and recoding with R - some recommendations</title>
      <link>https://data-se.netlify.app/2018/08/09/binning-and-recoding-with-r-some-recommendations/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/08/09/binning-and-recoding-with-r-some-recommendations/</guid>
      <description>Recoding means changing the levels of a variable, for instance changing “1” to “woman” and “2” to “man”. Binning means aggregating several variable levels to one, for instance aggregating the values From “1.00 meter” to “1.60 meter” to “small_size”.
Both operations are frequently necessary in practical data analysis. In this post, we review some methods to accomplish these two tasks.
Let’s load some example data:
data(tips, package = &amp;quot;reshape2&amp;quot;) Some packages:</description>
    </item>
    
    <item>
      <title>Finding NAs in multiples columns (per row)</title>
      <link>https://data-se.netlify.app/2018/08/09/finding-nas-in-multiples-columns-per-rows/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/08/09/finding-nas-in-multiples-columns-per-rows/</guid>
      <description>Assume you would like to check for missing data, but not for one column only but for several columns.
First, data and some packages:
data(mtcars) library(tidyverse) Then, let’s introduce some missing data:
mtcars[c(1,2), 1] &amp;lt;- NA mtcars[c(1, 3:4), 2] &amp;lt;- NA Don’t check columns individually Of course, you do not want to repeat yourself, and check each column individually, like this:
sum(is.na(mtcars[[1]])) #&amp;gt; [1] 2 sum(is.na(mtcars[, 1])) # same #&amp;gt; [1] 2 Neither one would like to check each row individually:</description>
    </item>
    
    <item>
      <title>Power calculation for the general linear model</title>
      <link>https://data-se.netlify.app/2018/07/24/power-calculation-for-the-general-linear-model/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/07/24/power-calculation-for-the-general-linear-model/</guid>
      <description>Before conducting an experiment, one should compute the power - or, preferably, estimate the precision of the expected results. There are numerous way to achieve this, here’s one using the R package pwr.
Package pwr library(pwr) The workhorse function here is pwr.f2.test. Note that f2 refers to the effect size \(f^2\) (see here), defined as:
\[f^2 = \frac{R^2}{1-R^2}\].
See for details of the function its help page:
help(&amp;quot;pwr.f2.test&amp;quot;) pwr.f2.test(u = NULL, v = NULL, f2 = NULL, sig.</description>
    </item>
    
    <item>
      <title>How to prepare data for a gantt diagram</title>
      <link>https://data-se.netlify.app/2018/07/05/how-to-prepare-data-for-a-gantt-diagram/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/07/05/how-to-prepare-data-for-a-gantt-diagram/</guid>
      <description>There’s the new cool world of project management - agile, scrumbling, cool. There’s the old sluggish way of project management using stuff like gantt diagrams. Let’s stick to the old world and come up with a gantt diagram.
The gant diagram itself is no big deal. Just some horizontal lines referring to dates. Somewhat more interesting is to populate a raw data frame in a way that allows for convenient plotting.</description>
    </item>
    
    <item>
      <title>Work with bibtex bib files like a pro</title>
      <link>https://data-se.netlify.app/2018/07/05/work-with-bibtex-bib-files-like-a-pro/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/07/05/work-with-bibtex-bib-files-like-a-pro/</guid>
      <description>Recently, I had to curate a list of publications for our institution. Where’s the point? One might ask. Let’s leave aside that a number of colleagues do not use citation management software to work with their publications. They just hack the citation, if and when needed, in some word files. Done. Fair enough, unless someone tries to come up with a list of all the publication of that institution. In that case, the curator will need some structured data, otherwise he or she will end up copy-pasting the rest of the day.</description>
    </item>
    
    <item>
      <title>Some musings on the logistic map</title>
      <link>https://data-se.netlify.app/2018/06/19/some-musings-on-the-logistic-map/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/06/19/some-musings-on-the-logistic-map/</guid>
      <description>The logistic map is a well-known and simple growth model that is defined by the iterative equation
\[x_{t+1} = 4rx_t(1-t_t)\],
where \(r\) is a parameter that can be thought of as a fertility and reproduction rate of the population. The allowed values of \(x\) range between 0 an 1 inclusively, where 0 means the population is extinct. The maximum of 1 can be interpreted as the ecological carrying capacity of the system.</description>
    </item>
    
    <item>
      <title>Visualizing mean values between two groups  - the tidyverse way</title>
      <link>https://data-se.netlify.app/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</link>
      <pubDate>Sun, 10 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/06/10/visualizing-summary-statistics-the-tidyverse-way/</guid>
      <description>A frequent job in data visualizing is to present summary statistics. In this post, I show one way to plot mean values between groups using the tidyverse approach in comparison to the mosaic way.
library(tidyverse) data(mtcars) library(mosaic) library(knitr) library(sjmisc) library(sjPlot) Visualizing mean values between two groups First, let’s compute the mean hp for automatic cars (am == 0) vs. manual cars (am == 1).
mtcars %&amp;gt;% group_by(am) %&amp;gt;% summarise(hp_am = mean(hp)) -&amp;gt; hp_am Now just hand over this data frame of summarized data to ggplot:</description>
    </item>
    
    <item>
      <title>Playing around with geo mapping: combining demographic data with spatial data</title>
      <link>https://data-se.netlify.app/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</link>
      <pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/05/28/playing-around-with-geo-mapping-combining-demographic-data-with-spatial-data/</guid>
      <description>In this post, we will play around with some basic geo mapping. More preciseyl, we will explore some easy ways to plot a choropleth map.
First, let’s load some geo data from Bundeswahlleiter, and combine it with some socio demographic data from the same source.
Preparation Let’s load some packages:
library(tidyverse) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 library(sf) library(viridis) suppressPackageStartupMessages(library(googleVis)) Geo data:
my_path_wahlkreise &amp;lt;- &amp;quot;~/Documents/datasets/geo_maps/btw17_geometrie_wahlkreise_shp/Geometrie_Wahlkreise_19DBT.shp&amp;quot; file.</description>
    </item>
    
    <item>
      <title>Why is the sample mean a good point estimator of the population mean? A simulation and some thoughts.</title>
      <link>https://data-se.netlify.app/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/05/18/why-is-the-sample-mean-a-good-point-estimator-of-the-population-mean-a-simulation-and-some-thoughts/</guid>
      <description>It is frequently stated that the sample mean is a good or even the best point estimator of the according population value. But why is that? In this post we are trying to get an intuition by using simulation inference methods.
Assume you played throwing coins with some one at some dark corner. “Some one” throws the coin 10 times, and wins 8 times (the guy was betting on heads, but that’s only for the sake of the story).</description>
    </item>
    
    <item>
      <title>One-way ANOVA power analysis</title>
      <link>https://data-se.netlify.app/2018/04/11/one-way-anova-power-analysis/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/04/11/one-way-anova-power-analysis/</guid>
      <description>Computing or estimating power is a very useful procedure in order to weigh the reliability of study results.
One frequent procedure in inferential statistics is the ANOVA, with the simplest form being the one-way ANOVA. This post shows how to compute power for this test.
What’s the effect size? The first thing to not is that there is no such thing as “power” - in the sense that a sample or a test would have “its power”.</description>
    </item>
    
    <item>
      <title>Parse libraries from R project</title>
      <link>https://data-se.netlify.app/2018/04/11/parse-libraries-from-r-project/</link>
      <pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/04/11/parse-libraries-from-r-project/</guid>
      <description>Having written a larger R project is may be of interest which packages have been used. As I did not find a read-to-use package, a colleague of mine - Norman Markgraf - came up with a nice solution. In this post, I build on his solution to provide a function that suits my needs of today:
@Norman: Thanks for your great idea!
First, some libraries:
library(tidyverse) library(bibtex) library(testthat) Then, here is some path of an R project where we want to parse all rmd files:</description>
    </item>
    
    <item>
      <title>Visualisation of interaction for the logistic regression</title>
      <link>https://data-se.netlify.app/2018/04/02/visualisation-of-interaction-for-logistic-regression/</link>
      <pubDate>Mon, 02 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/04/02/visualisation-of-interaction-for-logistic-regression/</guid>
      <description>In this post we are plotting an interaction for a logistic regression. Interaction per se is a concept difficult to grasp; for a GLM it may be even more difficult especially for continuous variables’ interaction. Plotting helps to better or more easy grasp what a model tries to tell us.
First, load some packages.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.</description>
    </item>
    
    <item>
      <title>Why &#34;n-1&#34; in empirical variance? A simulation.</title>
      <link>https://data-se.netlify.app/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</link>
      <pubDate>Sat, 24 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/03/24/why-n-1-in-empirical-variance-a-simulation/</guid>
      <description>It is well-known that the empirical variance underestimates the population variance. Specifically, the empirical variance is defined as: \(var_{emp} = \frac{\sum_i (x_i - \bar{x})^2}{n-1}\). But why \(n-1\), why not just \(n\), as intuition (of some) dictates? Put shortly, as the variance of a sample tends to underestimate the population variance we have to inflate it artificially, to enlarge it, that’s why we do put a smaller number (the “n-1”) in the denominator, resulting in a larger value of the whole fraction.</description>
    </item>
    
    <item>
      <title>Tangible data of normal distributed data</title>
      <link>https://data-se.netlify.app/2018/03/16/tangible-data-of-normal-distributed-data/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/03/16/tangible-data-of-normal-distributed-data/</guid>
      <description>A classical example for a normally distributed variable is height. However, I kept on looking for data as to the mean and sd for some populations, such as Germany. Now I found some reliably looking data here.
We will not question whether the assumption of normality holds, we just assume it.
In the source, we can read that in Germany, the adult men population has the following parameters:
mean: 174cm</description>
    </item>
    
    <item>
      <title>Map students to presentation slots</title>
      <link>https://data-se.netlify.app/2018/03/11/map-students-to-presentation-slots/</link>
      <pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/03/11/map-students-to-presentation-slots/</guid>
      <description>As a teacher, I not only teach but also assess the achievements of students. One example of a typical student assignments is a presentation. You know, powerpoint slides and stuff.
For that purpose, I often need to map students to one of several time slots. Here’s the R code I use for that purpose.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.</description>
    </item>
    
    <item>
      <title>How to create columns in a dataframe in R</title>
      <link>https://data-se.netlify.app/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/03/07/how-to-create-columns-in-a-dataframe-in-r/</guid>
      <description>Note that we will use this library for this post:
library(dplyr) ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 ## ## Attaching package: &amp;#39;dplyr&amp;#39; ## The following objects are masked from &amp;#39;package:stats&amp;#39;: ## ## filter, lag ## The following objects are masked from &amp;#39;package:base&amp;#39;: ## ## intersect, setdiff, setequal, union By the way, loading mosaic, will load dplyr too.
One of the major data wrangling activities (in R and elsewhere) is to create a new column in a data frame.</description>
    </item>
    
    <item>
      <title>Simulate p-hacking - adding observations</title>
      <link>https://data-se.netlify.app/2018/01/24/simulate-p-hacking-adding-observations/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2018/01/24/simulate-p-hacking-adding-observations/</guid>
      <description>Let’s simulate p-values as a funtion of sample size. We assume that some researcher collects one data point, computes the p-value, and repeats until p-value falls below some arbitrary threshold. Oh and yes, there is no real effect. For the sake of spending the budget, assume that our researcher collects a sample size of \(n=100\).
This idea stems from this great article False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant; cf.</description>
    </item>
    
    <item>
      <title>Zusammenhang von Lernen und Noten im Statistikunterricht</title>
      <link>https://data-se.netlify.app/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</link>
      <pubDate>Wed, 20 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/12/20/zusammenhang-von-lernen-und-noten-im-statistikunterricht/</guid>
      <description>Führt Lernen zu besseren Noten? Eigene Erfahrung und allgemeiner Konsens stimmen dem zu; zumindest schadet Lernen des Stoffes nicht und hilft oft, gute Noten bei einer Prüfung zu diesem Stoff zu erzielen. Aber welche Belege, wissenschaftliche Belege gibt es dazu? An unserer Hochschule, die FOM, haben wir eine kleine Untersuchung zu dieser Frage durchgeführt. Genauer gesagt haben wir unseren Studierenden einen Statistik-Test vorlegt und gefagt, wie sehr sie sich für diesen Test vorbereitet hätten.</description>
    </item>
    
    <item>
      <title>A p-value picture</title>
      <link>https://data-se.netlify.app/2017/11/29/a-p-value-picture/</link>
      <pubDate>Wed, 29 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/11/29/a-p-value-picture/</guid>
      <description>Much ado and to say about the p-value. Let me add one more point; actually not really from myself, but from Diez, Barr, and Cetinkaya-Rundel (2012), p. 189; good book in one is looking for “orthodox” statistics.
library(tidyverse) ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.6 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R</title>
      <link>https://data-se.netlify.app/2017/11/28/textmining-grundlagen/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/11/28/textmining-grundlagen/</guid>
      <description>Lernziele:
- Sie kennen zentrale Ziele und Begriffe des Textminings. - Sie wissen, was ein &amp;#39;tidy text dataframe&amp;#39; ist. - Sie können Worthäufigkeiten auszählen. - Sie können Worthäufigkeiten anhand einer Wordcloud visualisieren. In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages &amp;gt; Install.</description>
    </item>
    
    <item>
      <title>Grundlagen des Textminings mit R - Teil 2</title>
      <link>https://data-se.netlify.app/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/11/28/grundlagen-des-textminings-mit-r-teil-2/</guid>
      <description>In dieser Übung benötigte R-Pakete:
library(tidyverse) # Datenjudo library(stringr) # Textverarbeitung library(tidytext) # Textmining library(lsa) # Stopwörter library(SnowballC) # Wörter trunkieren library(wordcloud) # Wordcloud anzeigen library(skimr) # Überblicksstatistiken Bitte installieren Sie rechtzeitig alle Pakete, z.B. in RStudio über den Reiter Packages … Install.
Aus dem letzten Post Daten einlesen:
osf_link &amp;lt;- paste0(&amp;quot;https://osf.io/b35r7/?action=download&amp;quot;) afd &amp;lt;- read_csv(osf_link) ## Rows: 96 Columns: 2 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &amp;quot;,&amp;quot; ## chr (1): content ## dbl (1): page ## ## ℹ Use `spec()` to retrieve the full column specification for this data.</description>
    </item>
    
    <item>
      <title>Interactive diagrams in lieu of shiny?</title>
      <link>https://data-se.netlify.app/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/11/27/interactive-diagrams-in-lieu-of-shiny/</guid>
      <description>One frequent use of the Shiny server software is displaying interactive data diagrams. The pro of using Shiny is the great flexibility; much more than “just graphics” can be done. Basically Shiny provides a flexible GUI for your R program. But if you simply aiming at displaying or exploring some data interactively, a much simplor approach may do it for you; there are some nice libraries available in R for that.</description>
    </item>
    
    <item>
      <title>My favorite stats text book</title>
      <link>https://data-se.netlify.app/2017/11/27/my-favorite-stats-text-book/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://data-se.netlify.app/2017/11/27/my-favorite-stats-text-book/</guid>
      <description>Some thoughts how my favorite applied stats text book would look like. I am looking at eg., business fields such as MBA as consumers.
My ideal applied stats text book is case study oriented (“Assume you would like to predict which movie will score highest next year based on some movie characteristics you know”)
makes use of recent data analytics techniques such as tree based methods (Random Forests) or Shrinkage models (Lasso)</description>
    </item>
    
  </channel>
</rss>
