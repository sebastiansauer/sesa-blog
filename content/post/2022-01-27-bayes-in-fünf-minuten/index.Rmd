---
title: Bayes in fünf Minuten
author: Sebastian Sauer
date: '2022-01-27'
slug: bayes-in-fünf-minuten
categories:
  - rstats
tags:
  - Bayes
  - modelling
editor_options: 
  chunk_output_type: console
---


```{r global-knitr-options, include=FALSE}
  knitr::opts_chunk$set(
  fig.pos = 'H',
  fig.asp = 0.618,
  fig.align='center',
  fig.width = 5,
  out.width = "100%",
  fig.cap = "", 
  fig.path = "chunk-img/",
  dpi = 300,
  # tidy = TRUE,
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  fig.show = "hold")
```


# Das ist ein Fünf-Minuten-Bayes-Kurs

Sie würden gerne Bayes lernen und dafür zwischen 1-3 Wochen Zeit investieren?
Dann sind Sie hier falsch.
Dieser Post zeigt einen Kurzüberblick in Bayes-Statistik in fünf Minuten.
Naja, ich probiere es jedenfalls.



# Forschungsfrage

Sagen wir, uns interessiert folgende Forschungsfrage, die mit Methoden der Inferenz-Statistik untersucht werden soll.
In diesem Fall Bayes-Inferenz (nicht Frequentistische Statistik).


>   Verbrauchen Autos mit Automatik-Getriebe im Durchschnitt mehr Sprit als Autos mit manuellem Getriebe?

- AV: mpg (miles per gallone)
- UV: am (automatic vs. manual)


Die AV ist metrisch. Die UV ist binär. Wir vergleichen also zwei Gruppen, 
das ist ähnlich zum t-Test.

# Vorbereitung

```{r}
data("mtcars")  #
library(rstanarm)  # Bayes
library(tidyverse)  # Datenjudo
```

Der Datensatz `mtcars` ist "fest eingebaut" in R, so dass wir ihn nicht irgendwo herunterladen müsstenn.


Hilfe zum Datensatz bekommt man so:
```{r eval = FALSE}
help(mtcars) # Hilfe/Codebook zum Datensatz 
# Output hier nicht dargestellt
```


# Visualisierung

Zwar nicht Gegenstand dieses Posts,
aber hilfreich, 
daher hier nur kurz ein Bild ohne Syntax:


```{r echo = FALSE}
lm1 <- lm(mpg ~ am, data = mtcars)

preds <- c(
    predict(lm1, data.frame(am = 0)) %>% round(),
    predict(lm1, data.frame(am = 1)) %>% round()
)
```


```{r echo = FALSE}
mtcars %>% 
  ggplot() +
  aes(x = am, y = mpg) +
  geom_jitter(width=0.1) +
  geom_smooth(method = "lm") +
  annotate("point", x = 0, y = predict(lm1, data.frame(am = 0)),
           color = "red", size = 5, alpha = .7) +
  annotate("point", x = 1, y = predict(lm1, data.frame(am = 1)),
           color = "red", size = 5, alpha = .7) +
  scale_y_continuous(
    breaks = preds,
    labels = preds)
```



# Zur Interpretation der Regression

Die einfache Regression (also mit 1 UV) hat zwei Koeffizienten:
Achsenabschnitt und Steigung.

Bei einer binären (zweistufigen) UV bedeutet das:

- Der Achsenabschnitt zeigt den vorhergesagten Wert (der Mittelwert) der 1. Gruppe.
- Die Steigung zeigt den (vorhergesagten) Unterschied der zweiten Gruppe (im Vergleich zur 1. Gruppe).

Der vorhergesagte Wert der zweiten Gruppe ergibt sich also als Summe von Achsenabschnitt plus Steigung.


# Modell berechnen

Nutzen wir das allgemeine (oder verallgemeinerte) lineare Modell,
um unsere Forschungsfrage zu beantworten.
Anders gesagt: Wir berechnen einen Regression.
Das schöne an einer Regression ist,
sie passt^[Oft ist sie nur eine Näherung und manchmal eine schlechte, aber man kann erstaunlich viel mit der Regression machen, auch nicht-lineare wie polynombasierte oder exponentielle Zusammenhänge modellieren.] auf die meisten Probleme,
so ähnlich wie ein Schweizer Taschenmesser.


```{r results='hide'}
m1 <- stan_glm(mpg ~ am, data = mtcars)
```

Schön oder: Die Syntax von `stan_glm()` entspricht der Syntax von `lm()`. 


# Unterschied zwischen den zwei Gruppen


```{r}
coef(m1)
```

Was wir bekommen, 
sind Punktschätzer für die Population:

Der Achsenabschnitt  wird auf ca. 17 geschätzt.
Die Steigung (Unterschied zwischen den Gruppen) wird auf ca. 7 geschätzt.



# Aber ist der Unterschied zwischen den Gruppen "signifikant"?

In Bayes gibt es das Wort "signifikant" nicht.
Formulieren wir die Frage doch so um:

>   Liegt der Wert "Null" innerhalb oder außerhalb des 90%-Konfidenzintervalls (KI?


```{r}
posterior_interval(m1)
```

Das 90%-KI wird auf den Bereich von ca. 4 bis 10 geschätzt.
Die Null liegt *nicht* in diesem Intervall.

Folglich verwerfen wir die Nullhypothese.


# Ich hätte aber lieber ein 89% oder ein 95%-KI!

Also gut...


```{r}
posterior_interval(m1, prob = .89)  # oder auch prob = .95 etc.
```


# Warum eigentlich 89%?

Richard McElreath begründet die 89 so: Es ist die kleinste Primzahl kleiner als 95.
Noch Fragen? :smile



# Fertig


Ich fasse zusammen. Wir haben gerade Bayes-Statistik betrieben.
Und zwar haben wir ein einfaches Regressionsmodell, analog zum t-Test, berechnet.
Dann haben wir ein Bayes-Analog zur Nullhypothese und zum Konfidenzintervall uns ausgeben lassen.



# Interpretation der Ergebnisse

Im Frequentismus sind die zentralen Statistiken schwierig zu interpretieren.

In der Bayes-Statistik ist es einfach. 
Wir können sagen, dass (laut Modell!) der (mittlere) Gruppenunterschie mit 90% Wahrscheinlichkeit zwischen 4 und 10 Gallonen Sprit liegt.







