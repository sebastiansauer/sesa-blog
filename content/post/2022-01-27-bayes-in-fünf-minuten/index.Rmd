---
title: Bayes in f√ºnf Minuten
author: Sebastian Sauer
date: '2022-01-27'
slug: bayes-in-f√ºnf-minuten
categories:
  - rstats
tags:
  - Bayes
  - modelling
editor_options: 
  chunk_output_type: console
---


```{r global-knitr-options, include=FALSE}
  knitr::opts_chunk$set(
  fig.pos = 'H',
  fig.asp = 0.618,
  fig.align='center',
  fig.width = 5,
  out.width = "100%",
  fig.cap = "", 
  fig.path = "chunk-img/",
  dpi = 300,
  # tidy = TRUE,
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  fig.show = "hold")
```


# Das ist ein F√ºnf-Minuten-Bayes-Kurs

Sie w√ºrden gerne Bayes lernen und daf√ºr zwischen 1-3 Wochen Zeit investieren?
Dann sind Sie hier falsch.
Dieser Post zeigt einen Kurz√ºberblick in Bayes-Statistik in f√ºnf Minuten.
Naja, ich probiere es jedenfalls.



# Forschungsfrage

Sagen wir, uns interessiert folgende Forschungsfrage, die mit Methoden der Inferenz-Statistik untersucht werden soll.
In diesem Fall Bayes-Inferenz (nicht Frequentistische Statistik).


>   Verbrauchen Autos mit Automatik-Getriebe im Durchschnitt mehr Sprit als Autos mit manuellem Getriebe?

- AV: mpg (miles per gallone)
- UV: am (automatic vs. manual)


Die AV ist metrisch. Die UV ist bin√§r. Wir vergleichen also zwei Gruppen, 
das ist √§hnlich zum t-Test.

# Vorbereitung

```{r}
data("mtcars")  # Datensatz laden
library(rstanarm)  # Funktionen f√ºr Bayes-Statistik laden
library(tidyverse)  # F√ºr Datenjudo
```

Der Datensatz `mtcars` ist "fest eingebaut" in R, so dass wir ihn nicht irgendwo herunterladen m√ºssen.


Hilfe zum Datensatz bekommt man so:
```{r eval = FALSE}
help(mtcars) # Hilfe/Codebook zum Datensatz 
# Output hier nicht dargestellt
```


# Visualisierung

Zwar nicht Gegenstand dieses Posts,
aber hilfreich, 
daher hier nur kurz ein Bild ohne Syntax:


```{r echo = FALSE}
lm1 <- lm(mpg ~ am, data = mtcars)

preds <- c(
    predict(lm1, data.frame(am = 0)) %>% round(),
    predict(lm1, data.frame(am = 1)) %>% round()
)
```


```{r echo = FALSE}
mtcars %>% 
  ggplot() +
  aes(x = am, y = mpg) +
  geom_jitter(width=0.1) +
  geom_smooth(method = "lm") +
  annotate("point", x = 0, y = predict(lm1, data.frame(am = 0)),
           color = "red", size = 5, alpha = .7) +
  annotate("point", x = 1, y = predict(lm1, data.frame(am = 1)),
           color = "red", size = 5, alpha = .7) +
  scale_y_continuous(
    breaks = preds,
    labels = preds) +
  scale_x_continuous(breaks = c(0,1))
```

Jeder (leicht verwackelte) Punkt stellt ein Auto dar. 
Die Line ist die Regressionsgerade.
Die roten Punkte sind die Mittelwerte der beiden Gruppen.


# Zur Interpretation der Regression

Die einfache Regression (also mit nur einer UV) hat zwei Koeffizienten:
Achsenabschnitt und Steigung.

Bei einer bin√§ren (zweistufigen) UV bedeutet das:

- Der Achsenabschnitt zeigt den vorhergesagten Wert (der Mittelwert) der 1. Gruppe.
- Die Steigung zeigt den (vorhergesagten) Unterschied der zweiten Gruppe (im Vergleich zur 1. Gruppe).

Der vorhergesagte Wert der zweiten Gruppe ergibt sich also als Summe von Achsenabschnitt plus Steigung.


# Modell berechnen

Nutzen wir das allgemeine (oder verallgemeinerte) lineare Modell,
um unsere Forschungsfrage zu beantworten.
Anders gesagt: Wir berechnen einen Regression.
Das sch√∂ne an einer Regression ist,
sie passt^[Oft ist sie nur eine N√§herung und manchmal eine schlechte, aber man kann erstaunlich viel mit der Regression machen, auch nicht-lineare wie polynombasierte oder exponentielle Zusammenh√§nge modellieren.] auf die meisten Probleme,
so √§hnlich wie ein Schweizer Taschenmesser.


```{r results='hide'}
m1 <- stan_glm(mpg ~ am, data = mtcars)
```

Sch√∂n oder: Die Syntax von `stan_glm()` entspricht der Syntax von `lm()`. 


# Unterschied zwischen den zwei Gruppen


```{r}
coef(m1)
```

Was wir bekommen, 
sind Punktsch√§tzer f√ºr die Population:

Der Achsenabschnitt  wird auf ca. 17 gesch√§tzt.
Die Steigung (Unterschied zwischen den Gruppen) wird auf ca. 7 gesch√§tzt.



# Aber ist der Unterschied zwischen den Gruppen "signifikant"?

In Bayes gibt es das Wort "signifikant" nicht.
Formulieren wir die Frage doch so um:

>   Liegt der Wert "Null" innerhalb oder au√üerhalb des 90%-Konfidenzintervalls (KI)?


```{r}
posterior_interval(m1)
```

Das 90%-KI wird auf den Bereich von ca. 4 bis 10 gesch√§tzt.
Die Null liegt *nicht* in diesem Intervall.

Folglich verwerfen wir die Nullhypothese.


# Ich h√§tte aber lieber ein 89% oder ein 95%-KI!

Also gut...


```{r}
posterior_interval(m1, prob = .89)  # oder auch prob = .95 etc.
```


# Warum eigentlich 89%?

Richard McElreath begr√ºndet die 89 so: Es ist die kleinste Primzahl kleiner als 95.
Noch Fragen? üòÑ


# Mit welcher Wahrscheinlichkeit ist der Unterschied gr√∂√üer als Null?

Eine interessante Variante der Forschungsfrage ist zu fragen,
mit welcher Wahrscheinlichkeit - basierend auf den Daten und dem Modell - 
man mit einem Unterschied gr√∂√üer als Null zwischen Gruppen rechnen kann?


Wandeln wir das Modellobjekt in eine Tabelle um:

```{r}
m1_stipros <-
  m1 %>% 
  as_tibble()   # Modellergebnis m1 in Tabelle (tibble) umwandeln
```

```{r echo = FALSE}

(m1_stipros)
```


Wie man sieht,
findet das Modell in allen 4000 Stichproben (4000 ist der Defaultwert)
einen Unterschied gr√∂√üer Null.

Wir res√ºmieren also:

>   Laut Modell betr√§gt die Wahrscheinlichkeit praktisch 100%, dass wir einen Unterschied gr√∂√üer Null zwischen den Gruppenmittelwerten finden.




# Fertig


Ich fasse zusammen. Wir haben gerade Bayes-Statistik betrieben.
Und zwar haben wir ein einfaches Regressionsmodell, analog zum t-Test, berechnet.
Dann haben wir ein Bayes-Analog zur Nullhypothese und zum Konfidenzintervall uns ausgeben lassen.



# Interpretation der Ergebnisse

Im Frequentismus sind die zentralen Statistiken schwierig zu interpretieren.

In der Bayes-Statistik ist es einfach. 
Wir k√∂nnen sagen, dass (laut Modell!) der (mittlere) Gruppenunterschie mit 90% Wahrscheinlichkeit zwischen 4 und 10 Gallonen Sprit liegt.







