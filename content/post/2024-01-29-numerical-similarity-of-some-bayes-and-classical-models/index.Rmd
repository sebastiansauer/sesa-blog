---
title: Numerical similarity of some Bayes and Classical models
author: Sebastian Sauer
date: '2024-01-29'
slug: numerical-similarity-of-some-bayes-and-classical-models
categories:
  - rstats
tags:
  - regression
  - Bayes
output:
  blogdown::html_page:
    toc: yes
    number_sections: yes
---



```{r knitr-setup, echo = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  collapse = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  out.width = "100%",
  fig.align = 'center',
  fig.width = 6,
  fig.asp = 0.618,  # 1 / phi
  fig.show = "hold",
  size = "tiny"
)
```




# Load packages

```{r load-libs, message = FALSE, warning = FALSE}
library(tidyverse)  # data wrangling
library(rstanarm)  # Bayes modelling
library(palmerpenguins)  # data
library(easystats)  # unified API
library(tictoc)  # measure computation time
```






# Motivation

## Bayes and Frequentis

Bayes inference comforts its user with an interpretation that many practitioners seem to prefer (and to understand more quickly), ie., Bayes posterior distribution provides the probability of the hypothesis given the data at hand, $Pr(H|D)$. Classical Frequentist inference does not provide this probability, but rather the long-run probability of finding an at least as extreme empirical result, given that the Null hypothesis is true. This is all well-known. 

To be clear, both approaches have their appeal and may be optimal in different sitaution.

## Technical setup for Bayes analysis provides a barrier

However, a disadvantage of Bayes analysis, at least at its current state, is that it has higher technical and computational demands. For beginners in particular, this may present  a substantial (entry) burden. Teaching statistics, I have found that students (and many colleagues) have had difficulties installing Stan (particularly the C++ compiler needed in order to run Stan); Stan is the probabilistic programming language which many front-end Bayes engines use such as `brms` in R.

Thus, the installation process being not so user-friendly, a burden is placed for beginners which may prevent using Bayes methods.

In that light, this post explores the numerical simarilities of Bayes regression models and Frequentis models. The idea is to use a Frequentist regression model as a proxi for a full Bayesian analysis. The value added is the quick computation and the simple technical setup.


# Numerical convergence of Bayes and Frequentist approaches

To be clear, the philosophical differences and, consequently, the interpretation of Bayes and Frequentist models are very different.



However, under *some* instances, the *numerical* results (for point estimates) may be very similar comparing Bayesian and Frequentist models, and the Frequentist results may thus be interpreted in a Bayesian way (see for a proof https://arxiv.org/abs/1411.5018; for an example, see [this paper](https://nsojournals.onlinelibrary.wiley.com/doi/pdf/10.1111/oik.05985)).


More precisely, a linear regression model will provide the same *numerical* results as a Bayesian model (ceteris paribus) given that

- the likelihood is normal
- the priors are flat
- data are informative

Note: Flat priors are not non-informative in general.

It is *not* generally advisable to use flat priors as explained in [this post](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html).


In `rstanarm`, an R package for applied Bayes regression modelling, flat priors (for the regression coefficient) can be specified in this following way:

```{r results="hide"}
flat_prior_test <- stan_glm(mpg ~ hp, data = mtcars, prior = NULL, refresh = 0)
```

Check:

```{r}
prior_summary(flat_prior_test)
```



# Example 1: `mctcars`

Let's use `mtcars` to compute the following linear model: `mpg ~ hp`.


## Frequentist model

```{r}
lm_mtcars_freq <- lm(mpg ~ hp, data = mtcars)
parameters(lm_mtcars_freq)
```

## Bayesian numerically equivalent model

```{r}
lm_mtcars_bayes <- stan_glm(mpg ~ hp, data = mtcars, prior = NULL, refresh = 0)
parameters(lm_mtcars_bayes)
```


## Conclusion

There's a small difference due to the fact that the Bayes model involves random numbers. Beside that, the numerical results (of the point estimates) are (virtually) identical.

We have not put flat priors on the intercept and on sigma, hence those parameters may differ from the frequentist ones.


# Example 2: `penguins`


```{r}
data(penguins)
```


## Frequentist model

```{r}
lm_penguins_freq <- lm(body_mass_g ~ bill_length_mm, data = penguins)
parameters(lm_penguins_freq)
```

## Bayesian numerically equivalent model



```{r}
lm_penguins_bayes <- stan_glm(body_mass_g ~ bill_length_mm, data = penguins, prior = NULL, refresh = 0)
parameters(lm_penguins_bayes)
```

## Conclusion

Again, the numerical results are very similar.


# Example 3: `diamonds`

```{r}
data(diamonds)
```

## Frequentist model

```{r}
lm_diamonds_freq <- lm(price ~ carat, data = diamonds)
parameters(lm_diamonds_freq)
```

## Bayesian numerically equivalent model


```{r}
tic()
lm_diamonds_bayes <- stan_glm(price ~ carat, data = diamonds, prior = NULL, refresh = 0)
toc()
parameters(lm_diamonds_bayes)
```

## Conclusion

Note the prolonged computation time for the Bayes model due to the larger sample size (and possibly due to the unconstrained, ie., flat, prior).

Again, the regression coefficients are very similar.


# Caveats

The less data you have, the more the Posterior distribution will depend on your priors. In other words, make sure that your sample size is "large enough". [This post](https://stats.stackexchange.com/questions/200982/do-bayesian-priors-become-irrelevant-with-large-sample-size/201059#201059) provides some deeper insights.

We have not specified the `prior_intercept` in our Stan models, as we were not interested in that. However, using the same argument as above, we could set the intercept prior to a flat prior, too. Read [here](https://cran.r-project.org/web/packages/rstanarm/vignettes/priors.html) more about setting priors in `rstanarm`.




# Concluding remarks

As can be seen (and as it is stated in the literature), the point estimates of Bayesian and Frequentist models converge given that a flat prior is used and that the likelihood is normal. Furthermore, the data must be informative enough to "convince" the posterior distribution.

Hence, using `lm` can be seen as second-best option for computing simple Bayesian models. 

Remember that the idea of this post was to provide a simple soluttion practitioners who do not want to install additional softare (such as Stan). 
Of course, using a second-best option is not optimal by definition.





# Further reading

[This post](https://stats.stackexchange.com/questions/296220/why-i-should-use-bayesian-inference-with-uninformative-prior) comments on the numerical equivalence of flat prior Bayesian models with Frquentis models.



# Reproducibility

```{r reproducibility, echo = FALSE}
## Reproducibility info
options(width = 120)
devtools::session_info()

```


